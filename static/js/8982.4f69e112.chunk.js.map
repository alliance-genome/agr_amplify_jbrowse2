{"version":3,"file":"static/js/8982.4f69e112.chunk.js","mappings":"iUAEM,SAAUA,EAAMC,GACpB,OAAOC,EAAOC,MAAKC,EAAAA,EAAAA,SAAQH,I,wBCGRI,EAAAA,WAGnB,WAAmBC,EAAWC,IAAU,eACtCC,KAAKC,OACkB,IAArBC,UAAUC,OACN,CAAC,CAAEC,IAAKN,EAAMO,IAAKN,IACnB,KAAKD,EACLQ,OAAOC,OAAO,GAAIT,GAClB,CAACA,G,kCAGF,WACL,OAAOE,KAAKC,OAAO,GAAGG,M,iBAGjB,WACL,OAAOJ,KAAKC,OAAOD,KAAKC,OAAOE,OAAS,GAAGE,M,sBAGtC,SAASG,GACd,IAAK,IAAIC,EAAI,EAAGA,EAAIT,KAAKC,OAAOE,OAAQM,GAAK,EAAG,CAC9C,IAAMC,EAAIV,KAAKC,OAAOQ,GACtB,GAAIC,EAAEN,KAAOI,GAAOE,EAAEL,KAAOG,EAC3B,OAAO,EAGX,OAAO,I,0BAGF,WACL,OAAOR,KAAKC,OAAOE,OAAS,I,uBAGvB,WACL,OAAOH,KAAKC,OAAOU,KAAI,SAACD,GAAD,OAAc,IAAIb,EAAMa,EAAEN,IAAKM,EAAEL,U,sBAGnD,WACL,OAAOL,KAAKC,OAAOU,KAAI,SAACD,GAAD,iBAAkBA,EAAEN,IAApB,YAA2BM,EAAEL,IAA7B,QAAqCO,KAAK,O,mBAG5D,SAAMC,GAKX,IAJA,IAAMZ,EAASD,KAAKc,YAAYC,OAAOF,EAAGC,aAAaE,KAAKhB,KAAKiB,YAC3DC,EAAU,GACZC,EAAUlB,EAAO,GAEZmB,EAAI,EAAGA,EAAInB,EAAOE,OAAQiB,GAAK,EAAG,CACzC,IAAMC,EAAMpB,EAAOmB,GACfC,EAAIjB,MAAQe,EAAQd,MAAQ,GAC9Ba,EAAQI,KAAKH,GACbA,EAAUE,GACDA,EAAIhB,MAAQc,EAAQd,QAC7Bc,EAAU,IAAItB,EAAMsB,EAAQf,MAAOiB,EAAIhB,QAK3C,OAFAa,EAAQI,KAAKH,GAEU,IAAnBD,EAAQf,OACHe,EAAQ,GAEV,IAAIrB,EAAMqB,K,0BAGZ,SAAaK,GAclB,IAZA,IAAIC,EAAKxB,KACLa,EAAKU,EACHE,EAAKzB,KAAKC,SACVyB,EAAKb,EAAGZ,SACR0B,EAAKF,EAAGtB,OAERyB,EAAKF,EAAGvB,OACV0B,EAAK,EAELC,EAAK,EACHC,EAAK,GAEJF,EAAKF,GAAMG,EAAKF,GAAI,CACzBJ,EAAKC,EAAGI,GACRhB,EAAKa,EAAGI,GACR,IAAME,EAASC,KAAK5B,IAAImB,EAAGpB,MAAOS,EAAGT,OAC/B8B,EAASD,KAAK7B,IAAIoB,EAAGnB,MAAOQ,EAAGR,OACjC6B,GAAUF,GACZD,EAAGT,KAAK,IAAIzB,EAAMmC,EAAQE,IAExBV,EAAGnB,MAAQQ,EAAGR,MAChByB,GAAM,EAEND,GAAM,EAIV,GAAkB,IAAdE,EAAG5B,OACL,MAAM,IAAIgC,MAAM,2BAElB,OAAkB,IAAdJ,EAAG5B,OACE4B,EAAG,GAEL,IAAIlC,EAAMkC,K,sBAGZ,WAGL,IAFA,IAAIK,EAAM,EACJC,EAAKrC,KAAKC,SACPqC,EAAK,EAAGA,EAAKD,EAAGlC,OAAQmC,GAAM,EAAG,CACxC,IAAM5B,EAAI2B,EAAGC,GACbF,GAAO1B,EAAEL,MAAQK,EAAEN,MAAQ,EAE7B,OAAOgC,I,wBAGF,SAAWG,EAAaC,GAC7B,IAAIC,EAAIF,EACJG,EAAIF,EAOR,OANItC,UAAUC,OAAS,IACrBuC,EAAID,EAEJA,EAAIzC,MAGFyC,EAAErC,MAAQsC,EAAEtC,OACN,EAENqC,EAAErC,MAAQsC,EAAEtC,MACP,EAELqC,EAAEpC,MAAQqC,EAAErC,OACN,EAENqC,EAAErC,MAAQoC,EAAEpC,MACP,EAEF,M,EArIUR,GCLR8C,EAAb,0CAGE,WAAmBC,GAAe,6BAChC,cAAMA,IACDC,KAAO,cAFoB,EAHpC,qB,SAAA,GAAgCV,QAU1B,SAAUW,EAAYC,GAC1BA,EAAO/B,MAAK,SAACgC,EAAIC,GAAL,OAAyB,EAAZD,EAAGE,SAA2B,EAAZD,EAAGC,WAK9C,IAHA,IACIC,EACAC,EAFEC,EAAc,GAGXjC,EAAI,EAAGA,EAAI2B,EAAO5C,OAAQiB,GAAK,EAClC+B,GAAaJ,EAAO3B,GAAG8B,OAASE,GAAgB,KAClDD,EAAUhD,QAAU4C,EAAO3B,GAAGjB,OAASiD,EAAeL,EAAO3B,GAAG8B,OAChEC,EAAUJ,OAAOzB,KAAKyB,EAAO3B,KAE7BiC,EAAY/B,KACT6B,EAAY,CACXJ,OAAQ,CAACA,EAAO3B,IAChBjB,OAAQ4C,EAAO3B,GAAGjB,OAClB+C,OAAQH,EAAO3B,GAAG8B,SAIxBE,EAAeD,EAAUD,OAASC,EAAUhD,OAG9C,OAAOkD,EAcH,SAAUC,EAAiBC,GAC/B,GAAKA,GAIDA,EAAOC,QAAS,CAElB,GAA4B,qBAAjBC,aACT,MAAM,IAAIA,aAAa,UAAW,cAElC,IAAMC,EAAI,IAAIf,EAAW,WAEzB,MADAe,EAAEb,KAAO,cACHa,G,sBCsFL,IAAMC,EAAb,WAyCE,WACEC,EACAC,EACAC,EACAC,EACAC,EACAC,EACAC,GAAiB,WAEjB,IAFiB,eA/BX,KAAAC,aAAe,IAAIC,IAAJ,CAA0B,CAC/CC,MAAO,IAAIC,IAAJ,CAAa,CAAEC,QAAS,MAE/BC,KAAM,WAAF,8BAAE,WAAOC,EAAuBlB,GAA9B,yFACIpD,EAAmBsE,EAAnBtE,OAAQ+C,EAAWuB,EAAXvB,OADZ,SAEqB,EAAKU,IAAIc,KAChChF,EAAOiF,MAAMxE,GACb,EACAA,EACA+C,EACA,CAAEK,OAAAA,IAPA,uBAEIqB,EAFJ,EAEIA,OAFJ,kBASGA,GATH,2CAAF,qDAAE,OA8BAd,GAAiB,GACrB,MAAM,IAAI3B,MAAM,0BAElB,KAAM4B,EAAgB,GACpB,MAAM,IAAI5B,MAAM,0BAGlBnC,KAAK8D,cAAgBA,EACrB9D,KAAK+D,cAAgBA,EACrB/D,KAAKiE,aAAeA,EACpBjE,KAAK6D,WAAaA,EAClB7D,KAAKgE,YAAcA,EACnBhE,KAAK4D,IAAMA,EACX5D,KAAKkE,UAAYA,EACjB5D,OAAOC,OAAOP,KA9JlB,SAAoBgE,GAAoB,MAChCa,EAAKb,EAAc,MAAQ,SAC3Bc,GAAgB,IAAIC,EAAAA,GACvBC,UAAUH,GACVI,OAAO,WACPA,OAAO,SACPA,OAAO,OACPA,OAAO,YACPC,MAAM,YACNA,MAAM,YACNA,MAAM,WACNA,MAAM,aAEHC,GAAa,IAAIJ,EAAAA,GACpBC,UAAUH,GACVO,MAAM,UACNC,KAAK,GACLC,OAAO,OACPC,OAAO,CACNC,IAAK,SACLC,QAAS,CACP,GAAG,IAAIV,EAAAA,GAASW,MAAM,gBAAiB,CACrCvF,OAAQ,MACRwF,MAAM,IAAIZ,EAAAA,GACPE,OAAO,cACPA,OAAO,aACPA,OAAO,YACPA,OAAO,WACPW,OAAO,eACPA,OAAO,eAEZ,GAAG,IAAIb,EAAAA,GAASW,MAAM,eAAgB,CACpCvF,OAAQ,MACRwF,MAAM,IAAIZ,EAAAA,GACPE,OAAO,cACPA,OAAO,aACPA,OAAO,YACPA,OAAO,WACPW,OAAO,oBAIZC,GAAe,IAAId,EAAAA,GACtBC,UAAUH,GACVI,OAAO,WACPa,MAAM,SACNA,MAAM,OACNC,OAAO,OAAQ,CACdC,gBAAgB,IA8BpB,MAAO,CACLC,cA5BmB,IAAIlB,EAAAA,GACtBC,UAAUH,GACVQ,KAAK,GACLS,MAAM,cACNT,KAAK,GACLJ,OAAO,YACPA,OAAO,YACPG,MAAM,aACNC,KAAK,GACLC,OAAO,aACPC,OAAO,CACNC,IAAK,YACLC,SAAO,eAjEc,GAkEG,IAAIV,EAAAA,GAASW,MAAM,QAAS,CAChDvF,OAAQ,YACRwF,MAAM,IAAIZ,EAAAA,GAASG,MAAM,aAHtB,SAlEc,GAuEG,IAAIH,EAAAA,GAASW,MAAM,QAAS,CAChDvF,OAAQ,YACRwF,MAAM,IAAIZ,EAAAA,GAASe,MAAM,SAASZ,MAAM,aAPrC,SAnEc,GA4EG,IAAIH,EAAAA,GAASW,MAAM,QAAS,CAChDvF,OAAQ,YACRwF,MAAM,IAAIZ,EAAAA,GAASe,MAAM,SAASA,MAAM,OAAOZ,MAAM,YAXlD,KAiBTW,aAAAA,EACAf,cAAAA,EACAK,WAAAA,GA4EoBe,CAAWlC,IAhEnC,mFAmES,WACLmC,EACAC,EACAC,EACAC,EACAC,GALK,iIAQK1C,EAAgD7D,KAAhD6D,WAAYD,EAAoC5D,KAApC4D,IAAKE,EAA+B9D,KAA/B8D,cAAeE,EAAgBhE,KAAhBgE,YAChCT,EAAWgD,EAAXhD,YAEMiD,KADRC,EAAQ5C,EAAWsC,KAEvBG,EAASI,WAELC,EAAU,CAAEF,MAAAA,EAAOL,MAAAA,EAAOC,IAAAA,GAC3BrG,KAAK4G,iBACR5G,KAAK4G,eAAiBhD,EAAIc,KAAKhF,EAAOiF,MAAM,IAAK,EAAG,GAAIb,EAAe,CACrEP,OAAAA,KAjBD,SAoBsBvD,KAAK4G,eApB3B,uBAoBKhC,EApBL,EAoBKA,OACFiC,EAAe7C,EACjBY,EAAOkC,aAAa,GACpBlC,EAAOmC,aAAa,GACpBC,EAAuB,GACvBC,EAAc,EAEZC,EAAe,SACnBC,EACAjE,EACAkE,GAEA,IACE,IAAMC,EAAOF,EAAaG,MAAMpE,GAE1BqE,EAAI,EAAKpC,WAAWqC,MAAMH,GAAMI,OAStC,GARIF,EAAEP,gBACJA,EAAgBA,EAAcjG,OAC5BwG,EAAEP,cAAcU,OAAOC,GAAahH,KAAI,SAACiH,GAAD,MAAkB,CACxD1E,OAAQ0E,EAAEC,YACV1H,OAAQyH,EAAEE,gBAIZP,EAAEQ,aAAc,CAClB,IAAMA,EAAeR,EAAEQ,aACpBL,OAAOC,GACPhH,KAAI,SAACiH,GAAD,OAAiBA,EAAEC,eACtBE,EAAa5H,OAAS,GACxB6H,EAAYD,EAAcX,EAAQ,IAGtC,MAAO1D,GACP4C,EAAS2B,MAAMvE,KAIbiE,EAAc,SAACjF,GACnB,IAAQwF,EAA6CxF,EAA7CwF,WAAYC,EAAiCzF,EAAjCyF,UAAWC,EAAsB1F,EAAtB0F,SAAUC,EAAY3F,EAAZ2F,QACzC,OACGH,EAAazB,GAAUyB,IAAezB,GAAS0B,GAAa9B,KAC5D+B,EAAW3B,GAAU2B,IAAa3B,GAAS4B,GAAWjC,IAIrDkC,EAjEH,yCAiEsB,WAAOC,EAAUC,EAASpB,GAA1B,kGAEfjH,EAASqI,EAAGnI,MAAQmI,EAAGpI,MACvB8C,EAASsF,EAAGpI,MAHG,SAIM,EAAK+D,aAAasE,IAAlB,UACtBtI,EADsB,YACZ+C,GACb,CAAE/C,OAAAA,EAAQ+C,OAAAA,GACVK,GAPmB,OASrB,IALMmF,EAJe,OASZtH,EAAI,EAAGA,EAAImH,EAAIpI,OAAQiB,GAAK,EAC/BoH,EAAGG,SAASJ,EAAInH,MAClB8F,EAAawB,EAAcH,EAAInH,GAAK8B,EAAQkE,GAExB,KADpBH,GAAe,IAEb,EAAK2B,aAAatC,EAAUU,GAA5B,kBAAgDT,GAAhD,IAAsDI,QAAAA,MAdvC,gDAmBrBL,EAAS2B,MAAT,MAnBqB,yDAjEtB,0DAuFGD,EAAc,SAAC9E,EAAakE,GAChC,IACEH,GAAe/D,EAAO/C,OAItB,IAFA,IAAM0I,EAAkB,EAAmB,GAAfhC,EACxBiC,EAAQ,IAAIjJ,EAAMqD,EAAO,GAAIA,EAAO,GAAK2F,GACpCzH,EAAI,EAAGA,EAAI8B,EAAO/C,OAAQiB,GAAK,EAAG,CACzC,IAAM2H,EAAY,IAAIlJ,EAAMqD,EAAO9B,GAAI8B,EAAO9B,GAAKyH,GACnDC,EAAQA,EAAME,MAAMD,GAEtBD,EAAMhI,YAAYH,KAAI,SAAA6H,GAAE,OAAIF,EAAiBpF,EAAQsF,EAAIpB,MACzD,MAAO1D,GACP4C,EAAS2B,MAAMvE,KAnGhB,kBAuGIsE,EAAY,CAAClE,EAAgB,IAAK,IAvGtC,kCAyGHwC,EAAS2B,MAAT,MAzGG,0DAnET,8FAgLU,SACNZ,EACA4B,EACAtC,GAIA,IAFA,IAAMuC,EAAW,GACbC,EAAaF,EACVE,EAAa9B,EAAK+B,YAAY,CACnC,IAAMC,EAAMrJ,KAAK8E,cAAc0C,MAAMH,EAAKC,MAAM6B,IAChDD,EAAS5H,KAAK+H,EAAI5B,QAClB0B,GAAcE,EAAInG,OAEpB,IAAIoG,EAAQJ,EACRvC,IACF2C,EAAQA,EAAM5B,QAAO,SAAA6B,GAAG,OAAIA,EAAIC,UAAY7C,EAAQF,UAEtD,IAAMgD,EAAQH,EAAM3I,KAClB,SAAC4I,GAAD,MAAiC,CAC/BnD,MAAOmD,EAAInD,MACXC,IAAKkD,EAAIlD,IACTqD,SAAUH,EAAIG,SACdC,SAAUJ,EAAII,SACdC,MAAOL,EAAIM,SAAWN,EAAIO,UAAY,GACtCC,SAAS,MAGb,OAAOpD,EACH8C,EAAM/B,QAAO,SAAAsC,GAAC,OAAIrG,EAAUsG,YAAYD,EAAGrD,MAC3C8C,IA5MR,8BA+MU,SACNpC,EACA4B,EACA/F,EACAyD,GAIA,IAFA,IAAM2C,EAAQ,GACVH,EAAaF,EACVE,EAAa9B,EAAK+B,YAAY,CACnC,IAAMC,EAAMrJ,KAAK6F,aAAa2B,MAAMH,EAAKC,MAAM6B,IAC/CE,EAAI5B,OAAOyC,SAAX,aAA4BhH,EAASiG,GACrCG,EAAMhI,KAAK+H,EAAI5B,QACf0B,GAAcE,EAAInG,OAGpB,OAAOyD,EACH2C,EAAM5B,QAAO,SAACsC,GAAD,OAAYrG,EAAUsG,YAAYD,EAAGrD,MAClD2C,IAhOR,8BAmOU,SACNa,EACAlB,EACAtC,GAEA,IAAMU,EAAO8C,EAAM7C,MAAM2B,GACnBmB,EAAUpK,KAAKiG,aAAauB,MAAMH,GAAMI,OACtC6B,EAAqDc,EAArDd,MAAOe,EAA8CD,EAA9CC,SAAUC,EAAoCF,EAApCE,SAAUC,EAA0BH,EAA1BG,WAAYrG,EAAckG,EAAdlG,UAC/C,GA3UuB,IA2UnBA,EACF,IAAK,IAAI9C,EAAI,EAAGA,EAAIkI,EAAMnJ,OAAQiB,IAChCkI,EAAMlI,GAAGgF,MAAQmE,EAAanJ,EAAIkJ,EAClChB,EAAMlI,GAAGiF,IAAMkE,EAAanJ,EAAIkJ,EAAWD,OAExC,GAjVgB,IAiVZnG,EACT,IAAK,IAAI9C,EAAI,EAAGA,EAAIkI,EAAMnJ,OAAQiB,IAChCkI,EAAMlI,GAAGiF,IAAMiD,EAAMlI,GAAGgF,MAAQiE,EAGpC,OAAO1D,EACH2C,EAAM5B,QAAO,SAACsC,GAAD,OAAYrG,EAAUsG,YAAYD,EAAGrD,MAClD2C,IAvPR,mEA8PS,WACLhD,EACAvD,GAFK,gHAGLwD,EAHK,+BAGW,GAHX,SAMKrC,EAA4BlE,KAA5BkE,UAAWD,EAAiBjE,KAAjBiE,aACXV,EAAoBgD,EAApBhD,OAAQoD,EAAYJ,EAAZI,QACV6D,EAAqB1H,EAAYC,GACvCO,EAAiBC,GATd,SAUGkH,QAAQC,IACZF,EAAmB7J,IAAnB,yCAAuB,WAAOgK,GAAP,uFACrBrH,EAAiBC,GACTpD,EAAmBwK,EAAnBxK,OAAQ+C,EAAWyH,EAAXzH,OAFK,SAGF,EAAKiB,aAAasE,IAAlB,UACdtI,EADc,YACJ+C,GACbyH,EACApH,GANmB,OAGf8D,EAHe,OAQrBsD,EAAW5H,OAAO6H,SAAQ,SAACC,GACzBvH,EAAiBC,GACjB,IAAIsE,EAAcgD,EAAM3H,OAASyH,EAAWzH,OACxC4H,EAAazD,EAOjB,OANIpD,IACF6G,EAAatL,EAAM6H,EAAKC,MAAMO,IAC9BA,EAAc,GAEhBvE,EAAiBC,GAETW,GACN,IAAK,UACHoC,EAASyE,KACP,EAAKC,kBAAkBF,EAAYjD,EAAalB,IAElD,MACF,IAAK,SACHL,EAASyE,KACP,EAAKE,iBAAiBH,EAAYjD,EAAalB,IAEjD,MACF,IAAK,SACHL,EAASyE,KACP,EAAKG,iBACHJ,EACAjD,EAEA,IAAAgD,EAAM3H,OACNyD,IAGJ,MACF,QACEwE,QAAQC,KAAR,qCAA2ClH,QAzC5B,2CAAvB,wDAXC,OAyDHoC,EAASI,WAzDN,kDA2DHJ,EAAS2B,MAAT,MA3DG,0DA9PT,oFA0PU,SAAmB+B,EAAYqB,GACrC,OAAOrB,EAAE5D,MAAQiF,EAAMhF,KAAO2D,EAAE3D,KAAOgF,EAAMjF,UA3PjD,K,iDCzIMkF,GAAiB,WACjBC,GAAiB,WA8CvB,SAASrF,EAAWsF,GAClB,IAAM3G,EAAK2G,EAAO,MAAQ,SACpBC,GAAe,IAAI1G,EAAAA,GACtBC,UAAUH,GACViB,MAAM,SACNR,OAAO,WACPA,OAAO,iBACPM,OAAO,mBACPA,OAAO,sBACPA,OAAO,uBACPN,OAAO,cACPA,OAAO,qBACPM,OAAO,YACPA,OAAO,sBACPX,OAAO,qBACPW,OAAO,mBACPF,MAAM,aAAc,CACnBvF,OAAQ,gBACRwF,MAAM,IAAIZ,EAAAA,GACPE,OAAO,kBACPA,OAAO,YACPW,OAAO,cACPA,OAAO,iBAGR8F,GAAqB,IAAI3G,EAAAA,GAC5BC,UAAUH,GACVe,OAAO,gBACP+F,OAAO,YACPA,OAAO,YACPA,OAAO,YACPA,OAAO,mBAgBV,MAAO,CACLC,iBAfsB,IAAI7G,EAAAA,GACzBC,UAAUH,GACVI,OAAO,SACPA,OAAO,aACPA,OAAO,WACPA,OAAO,WACPW,OAAO,aAUR8F,mBAAAA,EACAD,aAAAA,EACAI,YAViB,IAAI9G,EAAAA,GACpBC,UAAUH,GACVO,MAAM,cACNC,KAAK,GACLC,OAAO,QAgBL,IAAewG,EAAtB,WA+BE,aAMQ,WALNC,EAKM,uDAAF,IAAE,eAlCE,KAAAC,YAAc,IAAI5H,IAAJ,CAA0B,CAChDC,MAAO,IAAIC,IAAJ,CAAa,CAAEC,QAAS,IAC/BC,KAAM,WAAF,8BAAE,WAAOyH,EAAa1I,GAApB,+FACG,EAAK2I,YAAL,kBAAqBD,GAArB,IAA6B1I,OAAAA,MADhC,2CAAF,qDAAE,KAkCN,IAAQ4I,EAAyCJ,EAAzCI,WAAYC,EAA6BL,EAA7BK,cAAeC,EAAcN,EAAdM,KAAMC,EAAQP,EAARO,IAEzC,GADAtM,KAAKoM,cAAgBA,GAAkB,SAAC3L,GAAD,OAAuBA,GAC1D0L,EACFnM,KAAK4D,IAAMuI,OACN,GAAIG,EACTtM,KAAK4D,IAAM,IAAI2I,EAAAA,GAAWD,OACrB,KAAID,EAGT,MAAM,IAAIlK,MAAM,iBAFhBnC,KAAK4D,IAAM,IAAI4I,EAAAA,GAAUH,IA9C/B,wCAgBS,WAAiD,IAAvC9F,EAAuC,uDAAF,GAC9CwF,EAAU,YAAaxF,EAAO,CAAEhD,OAAQgD,GAASA,EACvD,OAAOvG,KAAKgM,YAAYvD,IACtBgE,KAAKC,UAAUX,GACfA,EACAA,EAAQxI,UArBd,iEAoDU,WAAiBgD,GAAjB,8FACevG,KAAK2M,eAAepG,GADnC,cACAqG,EADA,gBAEe5M,KAAK6M,eAAeD,EAAQrG,GAF3C,cAEAuG,EAFA,4CAGMF,GAAWE,IAHjB,gDApDV,4HA0DU,WACNvG,GADM,2GAENwG,EAFM,+BAEQ,IAFR,SAImB/M,KAAK4D,IAAIc,KAChChF,EAAOiF,MAAMoI,GACb,EACAA,EACA,EACAxG,GATI,mBAIE3B,EAJF,EAIEA,OAOFZ,EAAchE,KAAKgN,aAAapI,GAChCqI,EAAM/G,EAAWlC,IACjB4I,EAASK,EAAIxB,aAAajE,MAAM5C,GAAQ6C,QACvCyF,SAAWN,EAAOO,QAAU5B,EAAgB,SAAW,WAE5DqB,EAAOQ,SAAWL,GAClBH,EAAOS,mBAAqBN,GAjBxB,0CAmBG/M,KAAK2M,eAAepG,EAAoB,EAAdwG,IAnB7B,WAqBFH,EAAOQ,WACTR,EAAOU,QAAU1I,EACd0C,MAAMsF,EAAOQ,SAAUxI,EAAO2I,QAAQ,EAAGX,EAAOQ,WAChDI,SAAS,WAEVZ,EAAOS,mBAAqBN,GA1B1B,0CA2BG/M,KAAK2M,eAAepG,EAAoB,EAAdwG,IA3B7B,eA6BFH,EAAOS,qBACHI,EAAO7I,EAAO0C,MAAMsF,EAAOS,oBACjCT,EAAOc,aAAeT,EAAIvB,mBAAmBlE,MAAMiG,GAAMhG,QA/BrD,qCAiCMmF,GAjCN,IAiCc5I,YAAAA,KAjCd,iDA1DV,iFA8FU,SAAaY,GACnB,IAAIqI,EAAMrI,EAAO+I,YAAY,GAC7B,GAAIV,IAAQ3B,GAAiB2B,IAAQ1B,EACnC,OAAO,EAGT,IADA0B,EAAMrI,EAAOgJ,YAAY,MACbtC,GAAiB2B,IAAQ1B,EACnC,OAAO,EAET,MAAM,IAAIpJ,MAAM,8BAvGpB,qEA2GU,WAAqByK,EAAgBrG,GAArC,2GAUN,IATMiF,EAAOoB,EAAO5I,YACda,EAAK2G,EAAO,MAAQ,SACpBqC,EAEF,GACEhK,EAAwC,GACtCiK,EAAoBlB,EAApBkB,gBACFC,EAAuBnB,EAAvBmB,mBAECA,EAAqB,IAAM,GAChCA,GAAsB,EAXlB,gBAcyB/N,KAAK4D,IAAIc,KACtChF,EAAOiF,MAAMoJ,EAAqBD,GAClC,EACAC,EAAqBD,EACrBA,EACAvH,GAnBI,uBAcUc,EAdV,EAcEzC,OAQF2C,EAAIrB,EAAWsF,GACbwC,EAAYzG,EAAEqE,gBAAgBpE,MAAMH,GAAMI,OAA1CuG,QACFC,GAAiB,IAAIlJ,EAAAA,GACxBC,UAAUH,GACVkB,OAAO,MAAO,CAAEmI,WAAW,EAAM/N,OAAQ6N,IACzC/I,OAAO,SACPA,OAAO,WACJkJ,GAAoB,IAAIpJ,EAAAA,GAC3BC,UAAUH,GACVQ,KAAK2I,GACLpI,OAAO,eACa,GACjBwI,EAlCA,yCAkCc,WAAOC,GAAP,gHACdnL,EAASmL,IACChH,EAAKlH,QAFD,sBAGV,IAAIgC,MAAM,gCAHA,UAKZ8K,EAAM1F,EAAEsE,WAAWrE,MAAMH,EAAKC,MAAMpE,IALxB,EAMU+J,EAAIxF,OAAxBoE,EANU,EAMVA,WAAYyC,EANF,EAMEA,IACpBpL,GAAU+J,EAAI/J,QACV2I,EARc,iBAShB,IAAS0C,EAAI,EAAGA,EAAID,EAAKC,GAAK,EACtBC,EAAUP,EAAezG,MAAMH,EAAKC,MAAMpE,IAChDA,GAAUsL,EAAQtL,OAFa,EAGCsL,EAAQ/G,OAAhCgH,EAHuB,EAGvBA,IAAKC,EAHkB,EAGlBA,MAAOC,EAHW,EAGXA,QACdC,EAAS,CAAEC,KAAMJ,EAAKK,GAAIJ,EAAOvO,OAAQwO,GAC/C9K,EAAW,EAAKuI,cAAcqC,IAAQC,EACtCb,EAAaa,GAASE,EAfR,wBAoBhB,IADMG,EAAY,GACTR,EAAI,EAAGA,EAAID,EAAKC,GAAK,EACtBS,EAAab,EAAkB3G,MAAMH,EAAKC,MAAMpE,IAChD+L,EAAgBD,EAAWvH,OAA3BwH,YACN/L,GAAU8L,EAAW9L,OACrB+L,GAAenB,EACfiB,EAAUzN,KAAK8M,EAAYa,IAzBb,iBA2BVxE,QAAQC,IAAIqE,GA3BF,4CAlCd,gEAgEAX,EA/BiB,IAjCjB,iCAiEC,CACLvK,WAAAA,EACAgK,aAAAA,IAnEI,iDA3GV,+HAsLY,WAAsBtH,GAAtB,4GAQEvG,KAAKkP,UAAU3I,GARjB,uBAEN4I,EAFM,EAENA,oBACAC,EAHM,EAGNA,WACAvL,EAJM,EAINA,WACAwL,EALM,EAKNA,kBACArL,EANM,EAMNA,YACAkJ,EAPM,EAONA,SAEIoC,EAAMF,EAAW,GACjBG,EAASD,EAAMA,EAAIE,WAAaL,EAAsB,IAVpD,kBAWD,IAAIxL,EACT3D,KAAK4D,IACLC,EACAsL,EACAI,EACAvL,EACAqL,EAAoB,EACpBnC,IAlBM,iDAtLZ,8HA4NS,WACLuC,EACArJ,EACAC,GAHK,mGAILE,EAJK,+BAI8D,CACjEmJ,MAAO,GALJ,SAQC1P,KAAKkP,UAAU3I,GARhB,UASCJ,EAAUnG,KAAKoM,cAAcqD,IAG/BlJ,EAAKoJ,aAZJ,iCAaU3P,KAAK4P,QAAQ,EAAIrJ,EAAKoJ,aAAcpJ,GAb9C,OAaHsJ,EAbG,mCAcMtJ,EAAKmJ,MAdX,kCAeU1P,KAAK4P,QAAQrJ,EAAKmJ,MAAOnJ,GAfnC,QAeHsJ,EAfG,gDAiBU7P,KAAK4P,QAAQ,EAAGrJ,GAjB1B,QAiBHsJ,EAjBG,kBAoBAA,EApBA,uBAqBG,IAAI1N,MAAM,qCArBb,iCAuBE,IAAI2N,EAAAA,GAAW,SAACxJ,GACrBuJ,EAAKE,YAAY5J,EAASC,EAAOC,EAAKC,EAAUC,OAxB7C,iDA5NT,6HAwPS,WACLkJ,EACArJ,EACAC,GAHK,mGAILE,EAJK,+BAI8D,CACjEmJ,MAAO,GALJ,SAQY1P,KAAKgQ,iBAAiBP,EAASrJ,EAAOC,EAAKE,GARvD,cAQC0J,EARD,gBAUaA,EACfC,MAAKC,EAAAA,EAAAA,IAAO,SAACC,EAAKC,GAAN,OAAeD,EAAIrP,OAAOsP,OACtCC,YAZE,cAUCrD,EAVD,yBAaEA,GAAO,IAbT,gDAxPT,kECjHasD,EAAb,oLASY,WACRb,EACAnJ,GAFQ,gHAKAvG,KAAKkP,UAAU3I,GALf,gBAIA6I,EAJA,EAIAA,WAAYvL,EAJZ,EAIYA,WAAY2M,EAJxB,EAIwBA,SAAUxM,EAJlC,EAIkCA,YAAaqL,EAJ/C,EAI+CA,kBAEjDoB,EAAa,EAAIf,EACnBgB,EAAWtB,EAAWjP,OACrBqQ,IAEHE,GAAY,GAGLtP,EAAIsP,EAbL,aAaetP,GAAK,GAbpB,uBAcAuP,EAAKvB,EAAWhO,KACZuP,EAAGC,gBAAkB,EAAIH,GAf7B,wBAgBEI,EACJzP,EAAIgO,EAAWjP,OAAS,EACpBiP,EAAWhO,EAAI,GAAGoO,WAAamB,EAAGG,YAClCN,EAAW,EAAIG,EAAGG,YAnBpB,kBAoBG,IAAInN,EACT3D,KAAK4D,IACLC,EACA8M,EAAGG,YACHD,EACA7M,EACAqL,EAAoB,EACpB,YA3BE,QAauBjO,GAAK,EAb5B,iDA+BDpB,KAAK+Q,gBAAgBxK,IA/BpB,iDATZ,8DAA4BuF,G,mDCoBtB,SAAUkF,EAAeC,GAC7B,OAAOA,EAAGvJ,QAAO,SAACwJ,GAAD,QAAgCA,KAG5C,IAAMC,EAAb,0CAQE,WAAmB5K,GAAU,6BAC3B,cAAMA,IARD6K,iBAAmB,IAAIhN,IAAJ,CAA0B,CAClDC,MAAO,IAAIC,IAAJ,CAAa,CAAEC,QAAS,IAC/BC,KAAM,WAAF,8BAAE,WAAO6M,EAAW9N,GAAlB,+FACG,EAAK+N,cAAL,kBAAuBD,GAAvB,IAA6B9N,OAAAA,MADhC,2CAAF,qDAAE,KAKqB,EAR/B,0CAYS,WAAmD,IAAvCgD,EAAuC,uDAAF,GAChDwF,EAAU,YAAaxF,EAAO,CAAEhD,OAAQgD,GAASA,EACvD,OAAOvG,KAAKoR,iBAAiB3I,IAC3BgE,KAAKC,UAAUX,GACfA,EACAA,EAAQxI,UAjBd,8DA2BY,WACRmM,EACAnJ,GAFQ,+FAIDvG,KAAK+Q,gBAAgBxK,IAJpB,gDA3BZ,4HAuCU,WAAmBA,GAAnB,0HACyCvG,KAAKkP,UAAU3I,GADxD,uBACEgL,EADF,EACEA,gBAAiBvN,EADnB,EACmBA,YADnB,SAEyBhE,KAAK4D,IAAIc,KACtChF,EAAOiF,MAAM,IACb,EACA,GACA4M,GANI,mBAEUlK,EAFV,EAEEzC,OAMFC,EAAKb,EAAc,MAAQ,SAC3BiJ,GAAM,IAAIlI,EAAAA,GACbC,UAAUH,GACVS,OAAO,QACPA,OAAO,SACPM,OAAO,UACP4B,MAAMH,GAAMI,OACP+J,EAAkBvE,EAAlBuE,MAAOtO,EAAW+J,EAAX/J,OAGD,IAAVsO,EAlBE,0CAmBG,IAnBH,eAuBAC,GADAC,EAAW,IACMF,EAvBjB,UAwBmBxR,KAAK4D,IAAIc,KAAKhF,EAAOiF,MAAM8M,GAAM,EAAGA,EAAKvO,GAxB5D,QAkCN,IAlCM,SAwBE0B,EAxBF,EAwBEA,OACF+M,GAAY,IAAI5M,EAAAA,GACnBC,UAAUH,GACV+M,MAAM,QACNA,MAAM,cACNhM,OAAO,UACPP,KAAK,GACLuM,MAAM,SACHC,EAAU,GAEPzQ,EAAI,EAAGA,EAAIoQ,EAAOpQ,GAAK,EAC9ByQ,EAAQvQ,KAAKqQ,EAAUnK,MAAM5C,EAAO0C,MAAMlG,EAAIsQ,IAAWjK,QAnCrD,yBAqCCoK,GArCD,iDAvCV,oIAuFU,WACNhD,GADM,8GAENtI,EAFM,+BAEiB,GAFjB,SAIwBvG,KAAKkP,UAAU3I,GAJvC,uBAIEvC,EAJF,EAIEA,YAJF,SAKgBhE,KAAK8R,YAAYvL,GALjC,WAKAsL,EALA,QAMO1R,OANP,0CAOG,IAPH,eASA4R,EAAOF,EAAQlR,IAAR,yCAAY,WAAOqR,GAAP,uGACf9O,EAAkB8O,EAAlB9O,OAAQ+O,EAAUD,EAAVC,MADO,SAEQ,EAAKrO,IAAIc,KACtChF,EAAOiF,MAAM,IACb,EACA,GACAzB,EACAqD,GAPqB,uBAEPc,EAFO,EAEfzC,OAOF2C,GAAI,IAAIxC,EAAAA,GACXC,UAAUhB,EAAc,MAAQ,UAChC8B,MAAM,SACNA,MAAM,aACNA,MAAM,WACNA,MAAM,WACNF,OAAO,aAfa,EAiBiB2B,EAAEC,MAAMH,GAAMI,OAA9CK,EAjBe,EAiBfA,UAAWkG,EAjBI,EAiBJA,QAASkE,EAjBL,EAiBKA,QACtBC,GAAM,IAAIpN,EAAAA,GACbC,UAAUhB,EAAc,MAAQ,UAChCoO,KAAK,YACL/M,KAAK,GACLuM,MAAM,OACNrM,OAAO,CACNC,IAAK,WACLC,QAAS,CACP,GAAG,IAAIV,EAAAA,GAASW,MAAM,WAAY,CAChCvF,OAAQ,MACRwF,MAAM,IAAIZ,EAAAA,GACPgB,OAAO,MAAO,CAAE5F,OAAQ6N,EAASE,WAAW,IAC5CtI,OAAO,YAEZ,GAAG,IAAIb,EAAAA,GAASW,MAAM,OAAQ,CAC5BvF,OAAQ,MACRwF,MAAM,IAAIZ,EAAAA,GACPgB,OAAO,MAAO,CAAE5F,OAAQ6N,EAASE,WAAW,IAC5CtI,OAAO,UACPX,OAAO,UACPA,OAAO,iBAKZmJ,EA3CiB,yCA2CH,WAClBiE,GADkB,iGAGZZ,EAAM,EAAI3J,GAAakG,EAAUkE,GAHrB,SAIO,EAAKtO,IAAIc,KAChChF,EAAOiF,MAAM8M,GACb,EACAA,EACAY,EACA9L,GATgB,mBAIV3B,EAJU,EAIVA,SAOF0N,EAAOH,EAAI3K,MAAM5C,GAAQ6C,QACtB8K,SAZS,iBAcPnR,EAAI,EAdG,YAcAA,EAAIkR,EAAKC,SAASpS,QAdlB,oBAeNsO,EAAQ6D,EAAKC,SAASnR,GAAtBqN,MACJI,EAAK2D,cAAc/D,GAAO,GAAKgE,GAhBrB,0CAiBLrE,EAAYqE,IAjBP,QAmBdA,EAAaH,EAAKC,SAASnR,GAAG8B,OAnBhB,QAc0B9B,GAAK,EAd/B,gDAqBTgN,EAAYqE,IArBH,QAuBTrR,EAAI,EAvBK,aAuBFA,EAAIkR,EAAKI,KAAKvS,QAvBZ,oBAwBZmS,EAAKI,KAAKtR,GAAGqN,MAAQI,EAxBT,6DAyBFyD,EAAKI,KAAKtR,IAzBR,IAyBY6Q,MAAAA,KAzBZ,QAuBoB7Q,GAAK,EAvBzB,sDA6BXoF,GA7BW,4CA3CG,sDA0EA,GA1EA,kBA2EhB4H,EAAYlL,EADI,KA1EA,4CAAZ,uDATP,KAsFC8N,EAtFD,UAsFmBvG,QAAQC,IAAIqH,GAtF/B,8GAvFV,8HAwLS,WACLlD,GADK,uGAELtI,EAFK,+BAEkB,GAFlB,SAIgBvG,KAAK2S,uBAAuB9D,EAAMtI,GAJlD,WAICxD,EAJD,QAKO5C,OALP,yCAMI,IANJ,uBAQcH,KAAK+Q,gBAAgBxK,GARnC,cAQCsJ,EARD,OASCxG,EAAMtG,EAAOpC,KAAI,SAAAkK,GACrB,OAAO,IAAIiF,EAAAA,GAAW,SAACxJ,GACrBuJ,EAAKjH,aAAatC,EAAU,CAACuE,GAAQtE,MACpC2J,MACDC,EAAAA,EAAAA,IAAO,SAACC,EAAKC,GAAN,OAAeD,EAAIrP,OAAOsP,OACjC1P,EAAAA,EAAAA,IAAI,SAAAiS,GACF,IAAK,IAAIxR,EAAI,EAAGA,EAAIwR,EAAEzS,OAAQiB,GAAK,EACjCwR,EAAExR,GAAG6Q,MAAQpH,EAAMoH,MAErB,OAAOW,SAlBR,UAsBaC,EAAAA,EAAAA,WAAA,UAASxJ,IAAKiH,YAtB3B,eAsBCrD,EAtBD,yBAuBEA,EAAIvF,QAAO,SAACsC,GACjB,OAAOA,EAAE8I,KAAKC,MAAM,MAAM/I,EAAEiI,MAAQ,KAAOpD,MAxBxC,iDAxLT,4DAA4B/C","sources":["../../../node_modules/@gmod/bbi/src/unzip-pako.ts","../../../node_modules/@gmod/bbi/src/range.ts","../../../node_modules/@gmod/bbi/src/util.ts","../../../node_modules/@gmod/bbi/src/blockView.ts","../../../node_modules/@gmod/bbi/src/bbi.ts","../../../node_modules/@gmod/bbi/src/bigwig.ts","../../../node_modules/@gmod/bbi/src/bigbed.ts"],"sourcesContent":["import { inflate } from 'pako'\n\nexport function unzip(input: Buffer) {\n  return Buffer.from(inflate(input))\n}\n","/* eslint prefer-rest-params:0, no-nested-ternary:0 */\n\n/**\n * Adapted from a combination of Range and _Compound in the\n * Dalliance Genome Explorer, (c) Thomas Down 2006-2010.\n */\nexport default class Range {\n  public ranges: any\n\n  public constructor(arg1: any, arg2?: any) {\n    this.ranges =\n      arguments.length === 2\n        ? [{ min: arg1, max: arg2 }]\n        : 0 in arg1\n        ? Object.assign({}, arg1)\n        : [arg1]\n  }\n\n  public min(): number {\n    return this.ranges[0].min\n  }\n\n  public max(): number {\n    return this.ranges[this.ranges.length - 1].max\n  }\n\n  public contains(pos: number): boolean {\n    for (let s = 0; s < this.ranges.length; s += 1) {\n      const r = this.ranges[s]\n      if (r.min <= pos && r.max >= pos) {\n        return true\n      }\n    }\n    return false\n  }\n\n  public isContiguous(): boolean {\n    return this.ranges.length > 1\n  }\n\n  public getRanges(): Range[] {\n    return this.ranges.map((r: Range) => new Range(r.min, r.max))\n  }\n\n  public toString(): string {\n    return this.ranges.map((r: Range) => `[${r.min}-${r.max}]`).join(',')\n  }\n\n  public union(s1: Range): Range {\n    const ranges = this.getRanges().concat(s1.getRanges()).sort(this.rangeOrder)\n    const oranges = []\n    let current = ranges[0]\n\n    for (let i = 1; i < ranges.length; i += 1) {\n      const nxt = ranges[i]\n      if (nxt.min() > current.max() + 1) {\n        oranges.push(current)\n        current = nxt\n      } else if (nxt.max() > current.max()) {\n        current = new Range(current.min(), nxt.max())\n      }\n    }\n    oranges.push(current)\n\n    if (oranges.length === 1) {\n      return oranges[0]\n    }\n    return new Range(oranges)\n  }\n\n  public intersection(arg: Range): Range {\n    // eslint-disable-next-line @typescript-eslint/no-this-alias\n    let s0 = this\n    let s1 = arg\n    const r0 = this.ranges()\n    const r1 = s1.ranges()\n    const l0 = r0.length\n\n    const l1 = r1.length\n    let i0 = 0\n\n    let i1 = 0\n    const or = []\n\n    while (i0 < l0 && i1 < l1) {\n      s0 = r0[i0]\n      s1 = r1[i1]\n      const lapMin = Math.max(s0.min(), s1.min())\n      const lapMax = Math.min(s0.max(), s1.max())\n      if (lapMax >= lapMin) {\n        or.push(new Range(lapMin, lapMax))\n      }\n      if (s0.max() > s1.max()) {\n        i1 += 1\n      } else {\n        i0 += 1\n      }\n    }\n\n    if (or.length === 0) {\n      throw new Error('found range of length 0')\n    }\n    if (or.length === 1) {\n      return or[0]\n    }\n    return new Range(or)\n  }\n\n  public coverage(): number {\n    let tot = 0\n    const rl = this.ranges()\n    for (let ri = 0; ri < rl.length; ri += 1) {\n      const r = rl[ri]\n      tot += r.max() - r.min() + 1\n    }\n    return tot\n  }\n\n  public rangeOrder(tmpa: Range, tmpb: Range): number {\n    let a = tmpa\n    let b = tmpb\n    if (arguments.length < 2) {\n      b = a\n      // eslint-disable-next-line @typescript-eslint/no-this-alias\n      a = this\n    }\n\n    if (a.min() < b.min()) {\n      return -1\n    }\n    if (a.min() > b.min()) {\n      return 1\n    }\n    if (a.max() < b.max()) {\n      return -1\n    }\n    if (b.max() > a.max()) {\n      return 1\n    }\n    return 0\n  }\n}\n","/* eslint no-bitwise: [\"error\", { \"allow\": [\"|\"] }] */\nexport class AbortError extends Error {\n  public code: string\n\n  public constructor(message: string) {\n    super(message)\n    this.code = 'ERR_ABORTED'\n  }\n}\n// sort blocks by file offset and\n// group blocks that are within 2KB of eachother\nexport function groupBlocks(blocks: any[]): any[] {\n  blocks.sort((b0, b1) => (b0.offset | 0) - (b1.offset | 0))\n\n  const blockGroups = []\n  let lastBlock\n  let lastBlockEnd\n  for (let i = 0; i < blocks.length; i += 1) {\n    if (lastBlock && blocks[i].offset - lastBlockEnd <= 2000) {\n      lastBlock.length += blocks[i].length - lastBlockEnd + blocks[i].offset\n      lastBlock.blocks.push(blocks[i])\n    } else {\n      blockGroups.push(\n        (lastBlock = {\n          blocks: [blocks[i]],\n          length: blocks[i].length,\n          offset: blocks[i].offset,\n        }),\n      )\n    }\n    lastBlockEnd = lastBlock.offset + lastBlock.length\n  }\n\n  return blockGroups\n}\n\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal?: AbortSignal): void {\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    // console.log('bam aborted!')\n    if (typeof DOMException !== 'undefined') {\n      throw new DOMException('aborted', 'AbortError')\n    } else {\n      const e = new AbortError('aborted')\n      e.code = 'ERR_ABORTED'\n      throw e\n    }\n  }\n}\n\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal?: AbortSignal): Promise<void> {\n  await Promise.resolve()\n  checkAbortSignal(signal)\n}\n","/* eslint no-bitwise: [\"error\", { \"allow\": [\"|\"] }] */\nimport { Observer } from 'rxjs'\nimport { Parser } from '@gmod/binary-parser'\nimport AbortablePromiseCache from 'abortable-promise-cache'\nimport { GenericFilehandle } from 'generic-filehandle'\nimport { unzip } from './unzip'\nimport QuickLRU from 'quick-lru'\nimport { Feature } from './bbi'\nimport Range from './range'\nimport { groupBlocks, checkAbortSignal } from './util'\n\ninterface CoordRequest {\n  chrId: number\n  start: number\n  end: number\n}\ninterface DataBlock {\n  startChrom: number\n  endChrom: number\n  startBase: number\n  endBase: number\n  validCnt: number\n  minVal: number\n  maxVal: number\n  sumData: number\n  sumSqData: number\n}\ninterface ReadData {\n  offset: number\n  length: number\n}\n\ninterface SummaryBlock {\n  chromId: number\n  start: number\n  end: number\n  validCnt: number\n  minScore: number\n  maxScore: number\n  sumData: number\n  sumSqData: number\n}\ninterface Options {\n  signal?: AbortSignal\n  request?: CoordRequest\n}\n\nconst BIG_WIG_TYPE_GRAPH = 1\nconst BIG_WIG_TYPE_VSTEP = 2\nconst BIG_WIG_TYPE_FSTEP = 3\n\nfunction getParsers(isBigEndian: boolean): any {\n  const le = isBigEndian ? 'big' : 'little'\n  const summaryParser = new Parser()\n    .endianess(le)\n    .uint32('chromId')\n    .uint32('start')\n    .uint32('end')\n    .uint32('validCnt')\n    .float('minScore')\n    .float('maxScore')\n    .float('sumData')\n    .float('sumSqData')\n\n  const leafParser = new Parser()\n    .endianess(le)\n    .uint8('isLeaf')\n    .skip(1)\n    .uint16('cnt')\n    .choice({\n      tag: 'isLeaf',\n      choices: {\n        1: new Parser().array('blocksToFetch', {\n          length: 'cnt',\n          type: new Parser()\n            .uint32('startChrom')\n            .uint32('startBase')\n            .uint32('endChrom')\n            .uint32('endBase')\n            .uint64('blockOffset')\n            .uint64('blockSize'),\n        }),\n        0: new Parser().array('recurOffsets', {\n          length: 'cnt',\n          type: new Parser()\n            .uint32('startChrom')\n            .uint32('startBase')\n            .uint32('endChrom')\n            .uint32('endBase')\n            .uint64('blockOffset'),\n        }),\n      },\n    })\n  const bigBedParser = new Parser()\n    .endianess(le)\n    .uint32('chromId')\n    .int32('start')\n    .int32('end')\n    .string('rest', {\n      zeroTerminated: true,\n    })\n\n  const bigWigParser = new Parser()\n    .endianess(le)\n    .skip(4)\n    .int32('blockStart')\n    .skip(4)\n    .uint32('itemStep')\n    .uint32('itemSpan')\n    .uint8('blockType')\n    .skip(1)\n    .uint16('itemCount')\n    .choice({\n      tag: 'blockType',\n      choices: {\n        [BIG_WIG_TYPE_FSTEP]: new Parser().array('items', {\n          length: 'itemCount',\n          type: new Parser().float('score'),\n        }),\n        [BIG_WIG_TYPE_VSTEP]: new Parser().array('items', {\n          length: 'itemCount',\n          type: new Parser().int32('start').float('score'),\n        }),\n        [BIG_WIG_TYPE_GRAPH]: new Parser().array('items', {\n          length: 'itemCount',\n          type: new Parser().int32('start').int32('end').float('score'),\n        }),\n      },\n    })\n  return {\n    bigWigParser,\n    bigBedParser,\n    summaryParser,\n    leafParser,\n  }\n}\n\n/**\n * View into a subset of the data in a BigWig file.\n *\n * Adapted by Robert Buels and Colin Diesh from bigwig.js in the Dalliance Genome\n * Explorer by Thomas Down.\n * @constructs\n */\n\nexport class BlockView {\n  private cirTreeOffset: number\n\n  private cirTreeLength: number\n\n  private bbi: GenericFilehandle\n\n  private isCompressed: boolean\n\n  private isBigEndian: boolean\n\n  private refsByName: any\n\n  private blockType: string\n\n  private cirTreePromise?: Promise<{ bytesRead: number; buffer: Buffer }>\n\n  private featureCache = new AbortablePromiseCache({\n    cache: new QuickLRU({ maxSize: 1000 }),\n\n    fill: async (requestData: ReadData, signal: AbortSignal) => {\n      const { length, offset } = requestData\n      const { buffer } = await this.bbi.read(\n        Buffer.alloc(length),\n        0,\n        length,\n        offset,\n        { signal },\n      )\n      return buffer\n    },\n  })\n\n  private leafParser: any\n\n  private bigWigParser: any\n\n  private bigBedParser: any\n\n  private summaryParser: any\n\n  public constructor(\n    bbi: GenericFilehandle,\n    refsByName: any,\n    cirTreeOffset: number,\n    cirTreeLength: number,\n    isBigEndian: boolean,\n    isCompressed: boolean,\n    blockType: string,\n  ) {\n    if (!(cirTreeOffset >= 0)) {\n      throw new Error('invalid cirTreeOffset!')\n    }\n    if (!(cirTreeLength > 0)) {\n      throw new Error('invalid cirTreeLength!')\n    }\n\n    this.cirTreeOffset = cirTreeOffset\n    this.cirTreeLength = cirTreeLength\n    this.isCompressed = isCompressed\n    this.refsByName = refsByName\n    this.isBigEndian = isBigEndian\n    this.bbi = bbi\n    this.blockType = blockType\n    Object.assign(this, getParsers(isBigEndian))\n  }\n\n  public async readWigData(\n    chrName: string,\n    start: number,\n    end: number,\n    observer: Observer<Feature[]>,\n    opts: Options,\n  ) {\n    try {\n      const { refsByName, bbi, cirTreeOffset, isBigEndian } = this\n      const { signal } = opts\n      const chrId = refsByName[chrName]\n      if (chrId === undefined) {\n        observer.complete()\n      }\n      const request = { chrId, start, end }\n      if (!this.cirTreePromise) {\n        this.cirTreePromise = bbi.read(Buffer.alloc(48), 0, 48, cirTreeOffset, {\n          signal,\n        })\n      }\n      const { buffer } = await this.cirTreePromise\n      const cirBlockSize = isBigEndian\n        ? buffer.readUInt32BE(4)\n        : buffer.readUInt32LE(4)\n      let blocksToFetch: any[] = []\n      let outstanding = 0\n\n      const cirFobRecur2 = (\n        cirBlockData: Buffer,\n        offset: number,\n        level: number,\n      ) => {\n        try {\n          const data = cirBlockData.slice(offset)\n\n          const p = this.leafParser.parse(data).result\n          if (p.blocksToFetch) {\n            blocksToFetch = blocksToFetch.concat(\n              p.blocksToFetch.filter(filterFeats).map((l: any): any => ({\n                offset: l.blockOffset,\n                length: l.blockSize,\n              })),\n            )\n          }\n          if (p.recurOffsets) {\n            const recurOffsets = p.recurOffsets\n              .filter(filterFeats)\n              .map((l: any): any => l.blockOffset)\n            if (recurOffsets.length > 0) {\n              cirFobRecur(recurOffsets, level + 1)\n            }\n          }\n        } catch (e) {\n          observer.error(e)\n        }\n      }\n\n      const filterFeats = (b: DataBlock) => {\n        const { startChrom, startBase, endChrom, endBase } = b\n        return (\n          (startChrom < chrId || (startChrom === chrId && startBase <= end)) &&\n          (endChrom > chrId || (endChrom === chrId && endBase >= start))\n        )\n      }\n\n      const cirFobStartFetch = async (off: any, fr: any, level: number) => {\n        try {\n          const length = fr.max() - fr.min()\n          const offset = fr.min()\n          const resultBuffer = await this.featureCache.get(\n            `${length}_${offset}`,\n            { length, offset },\n            signal,\n          )\n          for (let i = 0; i < off.length; i += 1) {\n            if (fr.contains(off[i])) {\n              cirFobRecur2(resultBuffer, off[i] - offset, level)\n              outstanding -= 1\n              if (outstanding === 0) {\n                this.readFeatures(observer, blocksToFetch, { ...opts, request })\n              }\n            }\n          }\n        } catch (e) {\n          observer.error(e)\n        }\n      }\n      const cirFobRecur = (offset: any, level: number) => {\n        try {\n          outstanding += offset.length\n\n          const maxCirBlockSpan = 4 + cirBlockSize * 32 // Upper bound on size, based on a completely full leaf node.\n          let spans = new Range(offset[0], offset[0] + maxCirBlockSpan)\n          for (let i = 1; i < offset.length; i += 1) {\n            const blockSpan = new Range(offset[i], offset[i] + maxCirBlockSpan)\n            spans = spans.union(blockSpan)\n          }\n          spans.getRanges().map(fr => cirFobStartFetch(offset, fr, level))\n        } catch (e) {\n          observer.error(e)\n        }\n      }\n\n      return cirFobRecur([cirTreeOffset + 48], 1)\n    } catch (e) {\n      observer.error(e)\n    }\n  }\n\n  private parseSummaryBlock(\n    data: Buffer,\n    startOffset: number,\n    request?: CoordRequest,\n  ) {\n    const features = [] as SummaryBlock[]\n    let currOffset = startOffset\n    while (currOffset < data.byteLength) {\n      const res = this.summaryParser.parse(data.slice(currOffset))\n      features.push(res.result)\n      currOffset += res.offset\n    }\n    let items = features\n    if (request) {\n      items = items.filter(elt => elt.chromId === request.chrId)\n    }\n    const feats = items.map(\n      (elt: SummaryBlock): Feature => ({\n        start: elt.start,\n        end: elt.end,\n        maxScore: elt.maxScore,\n        minScore: elt.minScore,\n        score: elt.sumData / (elt.validCnt || 1),\n        summary: true,\n      }),\n    )\n    return request\n      ? feats.filter(f => BlockView.coordFilter(f, request))\n      : feats\n  }\n\n  private parseBigBedBlock(\n    data: Buffer,\n    startOffset: number,\n    offset: number,\n    request?: CoordRequest,\n  ) {\n    const items = [] as Feature[]\n    let currOffset = startOffset\n    while (currOffset < data.byteLength) {\n      const res = this.bigBedParser.parse(data.slice(currOffset))\n      res.result.uniqueId = `bb-${offset + currOffset}`\n      items.push(res.result)\n      currOffset += res.offset\n    }\n\n    return request\n      ? items.filter((f: any) => BlockView.coordFilter(f, request))\n      : items\n  }\n\n  private parseBigWigBlock(\n    bytes: Buffer,\n    startOffset: number,\n    request?: CoordRequest,\n  ): Feature[] {\n    const data = bytes.slice(startOffset)\n    const results = this.bigWigParser.parse(data).result\n    const { items, itemSpan, itemStep, blockStart, blockType } = results\n    if (blockType === BIG_WIG_TYPE_FSTEP) {\n      for (let i = 0; i < items.length; i++) {\n        items[i].start = blockStart + i * itemStep\n        items[i].end = blockStart + i * itemStep + itemSpan\n      }\n    } else if (blockType === BIG_WIG_TYPE_VSTEP) {\n      for (let i = 0; i < items.length; i++) {\n        items[i].end = items[i].start + itemSpan\n      }\n    }\n    return request\n      ? items.filter((f: any) => BlockView.coordFilter(f, request))\n      : items\n  }\n\n  private static coordFilter(f: Feature, range: CoordRequest): boolean {\n    return f.start < range.end && f.end >= range.start\n  }\n\n  public async readFeatures(\n    observer: Observer<Feature[]>,\n    blocks: any,\n    opts: Options = {},\n  ): Promise<void> {\n    try {\n      const { blockType, isCompressed } = this\n      const { signal, request } = opts\n      const blockGroupsToFetch = groupBlocks(blocks)\n      checkAbortSignal(signal)\n      await Promise.all(\n        blockGroupsToFetch.map(async (blockGroup: any) => {\n          checkAbortSignal(signal)\n          const { length, offset } = blockGroup\n          const data = await this.featureCache.get(\n            `${length}_${offset}`,\n            blockGroup,\n            signal,\n          )\n          blockGroup.blocks.forEach((block: any) => {\n            checkAbortSignal(signal)\n            let blockOffset = block.offset - blockGroup.offset\n            let resultData = data\n            if (isCompressed) {\n              resultData = unzip(data.slice(blockOffset))\n              blockOffset = 0\n            }\n            checkAbortSignal(signal)\n\n            switch (blockType) {\n              case 'summary':\n                observer.next(\n                  this.parseSummaryBlock(resultData, blockOffset, request),\n                )\n                break\n              case 'bigwig':\n                observer.next(\n                  this.parseBigWigBlock(resultData, blockOffset, request),\n                )\n                break\n              case 'bigbed':\n                observer.next(\n                  this.parseBigBedBlock(\n                    resultData,\n                    blockOffset,\n                    // eslint-disable-next-line no-bitwise\n                    block.offset * (1 << 8),\n                    request,\n                  ),\n                )\n                break\n              default:\n                console.warn(`Don't know what to do with ${blockType}`)\n            }\n          })\n        }),\n      )\n      observer.complete()\n    } catch (e) {\n      observer.error(e)\n    }\n  }\n}\n","import { Parser } from '@gmod/binary-parser'\nimport { LocalFile, RemoteFile, GenericFilehandle } from 'generic-filehandle'\nimport { Observable, Observer } from 'rxjs'\nimport { reduce } from 'rxjs/operators'\nimport AbortablePromiseCache from 'abortable-promise-cache'\nimport QuickLRU from 'quick-lru'\nimport { BlockView } from './blockView'\n\nconst BIG_WIG_MAGIC = -2003829722\nconst BIG_BED_MAGIC = -2021002517\n\nexport interface Feature {\n  start: number\n  end: number\n  score: number\n  rest?: string // for bigbed line\n  minScore?: number // for summary line\n  maxScore?: number // for summary line\n  summary?: boolean // is summary line\n  uniqueId?: string // for bigbed contains uniqueId calculated from file offset\n  field?: number // used in bigbed searching\n}\ninterface Statistics {\n  scoreSum: number\n  basesCovered: number\n  scoreSumSquares: number\n}\n\ninterface RefInfo {\n  name: string\n  id: number\n  length: number\n}\nexport interface Header {\n  autoSql: string\n  totalSummary: Statistics\n  zoomLevels: any\n  unzoomedIndexOffset: number\n  unzoomedDataOffset: number\n  definedFieldCount: number\n  uncompressBufSize: number\n  chromTreeOffset: number\n  fileSize: number\n  extHeaderOffset: number\n  isBigEndian: boolean\n  fileType: string\n  refsByName: { [key: string]: number }\n  refsByNumber: { [key: number]: RefInfo }\n}\n\n/* get the compiled parsers for different sections of the bigwig file\n *\n * @param isBE - is big endian, typically false\n * @return an object with compiled parsers\n */\nfunction getParsers(isBE: boolean): any {\n  const le = isBE ? 'big' : 'little'\n  const headerParser = new Parser()\n    .endianess(le)\n    .int32('magic')\n    .uint16('version')\n    .uint16('numZoomLevels')\n    .uint64('chromTreeOffset')\n    .uint64('unzoomedDataOffset')\n    .uint64('unzoomedIndexOffset')\n    .uint16('fieldCount')\n    .uint16('definedFieldCount')\n    .uint64('asOffset') // autoSql offset, used in bigbed\n    .uint64('totalSummaryOffset')\n    .uint32('uncompressBufSize')\n    .uint64('extHeaderOffset') // name index offset, used in bigbed\n    .array('zoomLevels', {\n      length: 'numZoomLevels',\n      type: new Parser()\n        .uint32('reductionLevel')\n        .uint32('reserved')\n        .uint64('dataOffset')\n        .uint64('indexOffset'),\n    })\n\n  const totalSummaryParser = new Parser()\n    .endianess(le)\n    .uint64('basesCovered')\n    .double('scoreMin')\n    .double('scoreMax')\n    .double('scoreSum')\n    .double('scoreSumSquares')\n\n  const chromTreeParser = new Parser()\n    .endianess(le)\n    .uint32('magic')\n    .uint32('blockSize')\n    .uint32('keySize')\n    .uint32('valSize')\n    .uint64('itemCount')\n\n  const isLeafNode = new Parser()\n    .endianess(le)\n    .uint8('isLeafNode')\n    .skip(1)\n    .uint16('cnt')\n\n  return {\n    chromTreeParser,\n    totalSummaryParser,\n    headerParser,\n    isLeafNode,\n  }\n}\n\nexport interface RequestOptions {\n  signal?: AbortSignal\n  headers?: Record<string, string>\n  [key: string]: unknown\n}\n\nexport abstract class BBI {\n  protected bbi: GenericFilehandle\n\n  protected headerCache = new AbortablePromiseCache({\n    cache: new QuickLRU({ maxSize: 1 }),\n    fill: async (params: any, signal?: AbortSignal) => {\n      return this._getHeader({ ...params, signal })\n    },\n  })\n\n  protected renameRefSeqs: (a: string) => string\n\n  /* fetch and parse header information from a bigwig or bigbed file\n   * @param abortSignal - abort the operation, can be null\n   * @return a Header object\n   */\n  public getHeader(opts: RequestOptions | AbortSignal = {}) {\n    const options = 'aborted' in opts ? { signal: opts } : opts\n    return this.headerCache.get(\n      JSON.stringify(options),\n      options,\n      options.signal,\n    )\n  }\n\n  /*\n   * @param filehandle - a filehandle from generic-filehandle or implementing something similar to the node10 fs.promises API\n   * @param path - a Local file path as a string\n   * @param url - a URL string\n   * @param renameRefSeqs - an optional method to rename the internal reference sequences using a mapping function\n   */\n  public constructor(\n    options: {\n      filehandle?: GenericFilehandle\n      path?: string\n      url?: string\n      renameRefSeqs?: (a: string) => string\n    } = {},\n  ) {\n    const { filehandle, renameRefSeqs, path, url } = options\n    this.renameRefSeqs = renameRefSeqs || ((s: string): string => s)\n    if (filehandle) {\n      this.bbi = filehandle\n    } else if (url) {\n      this.bbi = new RemoteFile(url)\n    } else if (path) {\n      this.bbi = new LocalFile(path)\n    } else {\n      throw new Error('no file given')\n    }\n  }\n\n  private async _getHeader(opts: RequestOptions) {\n    const header = await this._getMainHeader(opts)\n    const chroms = await this._readChromTree(header, opts)\n    return { ...header, ...chroms }\n  }\n\n  private async _getMainHeader(\n    opts: RequestOptions,\n    requestSize = 2000,\n  ): Promise<Header> {\n    const { buffer } = await this.bbi.read(\n      Buffer.alloc(requestSize),\n      0,\n      requestSize,\n      0,\n      opts,\n    )\n    const isBigEndian = this._isBigEndian(buffer)\n    const ret = getParsers(isBigEndian)\n    const header = ret.headerParser.parse(buffer).result\n    header.fileType = header.magic === BIG_BED_MAGIC ? 'bigbed' : 'bigwig'\n    if (\n      header.asOffset > requestSize ||\n      header.totalSummaryOffset > requestSize\n    ) {\n      return this._getMainHeader(opts, requestSize * 2)\n    }\n    if (header.asOffset) {\n      header.autoSql = buffer\n        .slice(header.asOffset, buffer.indexOf(0, header.asOffset))\n        .toString('utf8')\n    }\n    if (header.totalSummaryOffset > requestSize) {\n      return this._getMainHeader(opts, requestSize * 2)\n    }\n    if (header.totalSummaryOffset) {\n      const tail = buffer.slice(header.totalSummaryOffset)\n      header.totalSummary = ret.totalSummaryParser.parse(tail).result\n    }\n    return { ...header, isBigEndian }\n  }\n\n  private _isBigEndian(buffer: Buffer): boolean {\n    let ret = buffer.readInt32LE(0)\n    if (ret === BIG_WIG_MAGIC || ret === BIG_BED_MAGIC) {\n      return false\n    }\n    ret = buffer.readInt32BE(0)\n    if (ret === BIG_WIG_MAGIC || ret === BIG_BED_MAGIC) {\n      return true\n    }\n    throw new Error('not a BigWig/BigBed file')\n  }\n\n  // todo: add progress if long running\n  private async _readChromTree(header: Header, opts: { signal?: AbortSignal }) {\n    const isBE = header.isBigEndian\n    const le = isBE ? 'big' : 'little'\n    const refsByNumber: {\n      [key: number]: { name: string; id: number; length: number }\n    } = []\n    const refsByName: { [key: string]: number } = {}\n    const { chromTreeOffset } = header\n    let { unzoomedDataOffset } = header\n\n    while (unzoomedDataOffset % 4 !== 0) {\n      unzoomedDataOffset += 1\n    }\n\n    const { buffer: data } = await this.bbi.read(\n      Buffer.alloc(unzoomedDataOffset - chromTreeOffset),\n      0,\n      unzoomedDataOffset - chromTreeOffset,\n      chromTreeOffset,\n      opts,\n    )\n\n    const p = getParsers(isBE)\n    const { keySize } = p.chromTreeParser.parse(data).result\n    const leafNodeParser = new Parser()\n      .endianess(le)\n      .string('key', { stripNull: true, length: keySize })\n      .uint32('refId')\n      .uint32('refSize')\n    const nonleafNodeParser = new Parser()\n      .endianess(le)\n      .skip(keySize)\n      .uint64('childOffset')\n    const rootNodeOffset = 32\n    const bptReadNode = async (currentOffset: number): Promise<void> => {\n      let offset = currentOffset\n      if (offset >= data.length) {\n        throw new Error('reading beyond end of buffer')\n      }\n      const ret = p.isLeafNode.parse(data.slice(offset))\n      const { isLeafNode, cnt } = ret.result\n      offset += ret.offset\n      if (isLeafNode) {\n        for (let n = 0; n < cnt; n += 1) {\n          const leafRet = leafNodeParser.parse(data.slice(offset))\n          offset += leafRet.offset\n          const { key, refId, refSize } = leafRet.result\n          const refRec = { name: key, id: refId, length: refSize }\n          refsByName[this.renameRefSeqs(key)] = refId\n          refsByNumber[refId] = refRec\n        }\n      } else {\n        // parse index node\n        const nextNodes = []\n        for (let n = 0; n < cnt; n += 1) {\n          const nonleafRet = nonleafNodeParser.parse(data.slice(offset))\n          let { childOffset } = nonleafRet.result\n          offset += nonleafRet.offset\n          childOffset -= chromTreeOffset\n          nextNodes.push(bptReadNode(childOffset))\n        }\n        await Promise.all(nextNodes)\n      }\n    }\n    await bptReadNode(rootNodeOffset)\n    return {\n      refsByName,\n      refsByNumber,\n    }\n  }\n\n  /*\n   * fetches the \"unzoomed\" view of the bigwig data. this is the default for bigbed\n   * @param abortSignal - a signal to optionally abort this operation\n   */\n  protected async getUnzoomedView(opts: RequestOptions): Promise<BlockView> {\n    const {\n      unzoomedIndexOffset,\n      zoomLevels,\n      refsByName,\n      uncompressBufSize,\n      isBigEndian,\n      fileType,\n    } = await this.getHeader(opts)\n    const nzl = zoomLevels[0]\n    const cirLen = nzl ? nzl.dataOffset - unzoomedIndexOffset : 4000\n    return new BlockView(\n      this.bbi,\n      refsByName,\n      unzoomedIndexOffset,\n      cirLen,\n      isBigEndian,\n      uncompressBufSize > 0,\n      fileType,\n    )\n  }\n\n  /*\n   * abstract method - get the view for a given scale\n   */\n  protected abstract getView(\n    scale: number,\n    opts: RequestOptions,\n  ): Promise<BlockView>\n\n  /**\n   * Gets features from a BigWig file\n   *\n   * @param refName - The chromosome name\n   * @param start - The start of a region\n   * @param end - The end of a region\n   * @param opts - An object containing basesPerSpan (e.g. pixels per basepair) or scale used to infer the zoomLevel to use\n   */\n  public async getFeatureStream(\n    refName: string,\n    start: number,\n    end: number,\n    opts: RequestOptions & { scale?: number; basesPerSpan?: number } = {\n      scale: 1,\n    },\n  ): Promise<Observable<Feature[]>> {\n    await this.getHeader(opts)\n    const chrName = this.renameRefSeqs(refName)\n    let view: BlockView\n\n    if (opts.basesPerSpan) {\n      view = await this.getView(1 / opts.basesPerSpan, opts)\n    } else if (opts.scale) {\n      view = await this.getView(opts.scale, opts)\n    } else {\n      view = await this.getView(1, opts)\n    }\n\n    if (!view) {\n      throw new Error('unable to get block view for data')\n    }\n    return new Observable((observer: Observer<Feature[]>): void => {\n      view.readWigData(chrName, start, end, observer, opts)\n    })\n  }\n\n  public async getFeatures(\n    refName: string,\n    start: number,\n    end: number,\n    opts: RequestOptions & { scale?: number; basesPerSpan?: number } = {\n      scale: 1,\n    },\n  ): Promise<Feature[]> {\n    const ob = await this.getFeatureStream(refName, start, end, opts)\n\n    const ret = await ob\n      .pipe(reduce((acc, curr) => acc.concat(curr)))\n      .toPromise()\n    return ret || []\n  }\n}\n","import { BlockView } from './blockView'\nimport { BBI, RequestOptions } from './bbi'\n\nexport class BigWig extends BBI {\n  /**\n   * Retrieves a BlockView of a specific zoomLevel\n   *\n   * @param refName - The chromosome name\n   * @param start - The start of a region\n   * @param end - The end of a region\n   * @param opts - An object containing basesPerSpan (e.g. pixels per basepair) or scale used to infer the zoomLevel to use\n   */\n  protected async getView(\n    scale: number,\n    opts: RequestOptions,\n  ): Promise<BlockView> {\n    const { zoomLevels, refsByName, fileSize, isBigEndian, uncompressBufSize } =\n      await this.getHeader(opts)\n    const basesPerPx = 1 / scale\n    let maxLevel = zoomLevels.length\n    if (!fileSize) {\n      // if we don't know the file size, we can't fetch the highest zoom level :-(\n      maxLevel -= 1\n    }\n\n    for (let i = maxLevel; i >= 0; i -= 1) {\n      const zh = zoomLevels[i]\n      if (zh && zh.reductionLevel <= 2 * basesPerPx) {\n        const indexLength =\n          i < zoomLevels.length - 1\n            ? zoomLevels[i + 1].dataOffset - zh.indexOffset\n            : fileSize - 4 - zh.indexOffset\n        return new BlockView(\n          this.bbi,\n          refsByName,\n          zh.indexOffset,\n          indexLength,\n          isBigEndian,\n          uncompressBufSize > 0,\n          'summary',\n        )\n      }\n    }\n    return this.getUnzoomedView(opts)\n  }\n}\n","import { Parser } from '@gmod/binary-parser'\nimport { Observable, Observer, merge } from 'rxjs'\nimport { map, reduce } from 'rxjs/operators'\nimport AbortablePromiseCache from 'abortable-promise-cache'\nimport QuickLRU from 'quick-lru'\n\nimport { BBI, Feature, RequestOptions } from './bbi'\nimport { BlockView } from './blockView'\n\ninterface Loc {\n  key: string\n  offset: number\n  length: number\n  field?: number\n}\n\ninterface Index {\n  type: number\n  fieldcount: number\n  offset: number\n  field: number\n}\n\nexport function filterUndef<T>(ts: (T | undefined)[]): T[] {\n  return ts.filter((t: T | undefined): t is T => !!t)\n}\n\nexport class BigBed extends BBI {\n  public readIndicesCache = new AbortablePromiseCache({\n    cache: new QuickLRU({ maxSize: 1 }),\n    fill: async (args: any, signal?: AbortSignal) => {\n      return this._readIndices({ ...args, signal })\n    },\n  })\n\n  public constructor(opts?: any) {\n    super(opts)\n  }\n\n  public readIndices(opts: AbortSignal | RequestOptions = {}) {\n    const options = 'aborted' in opts ? { signal: opts } : opts\n    return this.readIndicesCache.get(\n      JSON.stringify(options),\n      options,\n      options.signal,\n    )\n  }\n\n  /*\n   * retrieve unzoomed view for any scale\n   * @param scale - unused\n   * @param abortSignal - an optional AbortSignal to kill operation\n   * @return promise for a BlockView\n   */\n  protected async getView(\n    scale: number,\n    opts: RequestOptions,\n  ): Promise<BlockView> {\n    return this.getUnzoomedView(opts)\n  }\n\n  /*\n   * parse the bigbed extraIndex fields\n   * @param abortSignal to abort operation\n   * @return a Promise for an array of Index data structure since there can be multiple extraIndexes in a bigbed, see bedToBigBed documentation\n   */\n  private async _readIndices(opts: RequestOptions): Promise<Index[]> {\n    const { extHeaderOffset, isBigEndian } = await this.getHeader(opts)\n    const { buffer: data } = await this.bbi.read(\n      Buffer.alloc(64),\n      0,\n      64,\n      extHeaderOffset,\n    )\n    const le = isBigEndian ? 'big' : 'little'\n    const ret = new Parser()\n      .endianess(le)\n      .uint16('size')\n      .uint16('count')\n      .uint64('offset')\n      .parse(data).result\n    const { count, offset } = ret\n\n    // no extra index is defined if count==0\n    if (count === 0) {\n      return []\n    }\n\n    const blocklen = 20\n    const len = blocklen * count\n    const { buffer } = await this.bbi.read(Buffer.alloc(len), 0, len, offset)\n    const extParser = new Parser()\n      .endianess(le)\n      .int16('type')\n      .int16('fieldcount')\n      .uint64('offset')\n      .skip(4)\n      .int16('field')\n    const indices = []\n\n    for (let i = 0; i < count; i += 1) {\n      indices.push(extParser.parse(buffer.slice(i * blocklen)).result)\n    }\n    return indices\n  }\n\n  /*\n   * perform a search in the bigbed extraIndex to find which blocks in the bigbed data to look for the\n   * actual feature data\n   *\n   * @param name - the name to search for\n   * @param opts - a SearchOptions argument with optional signal\n   * @return a Promise for an array of bigbed block Loc entries\n   */\n  private async searchExtraIndexBlocks(\n    name: string,\n    opts: RequestOptions = {},\n  ): Promise<Loc[]> {\n    const { isBigEndian } = await this.getHeader(opts)\n    const indices = await this.readIndices(opts)\n    if (!indices.length) {\n      return []\n    }\n    const locs = indices.map(async (index: any): Promise<Loc | undefined> => {\n      const { offset, field } = index\n      const { buffer: data } = await this.bbi.read(\n        Buffer.alloc(32),\n        0,\n        32,\n        offset,\n        opts,\n      )\n      const p = new Parser()\n        .endianess(isBigEndian ? 'big' : 'little')\n        .int32('magic')\n        .int32('blockSize')\n        .int32('keySize')\n        .int32('valSize')\n        .uint64('itemCount')\n\n      const { blockSize, keySize, valSize } = p.parse(data).result\n      const bpt = new Parser()\n        .endianess(isBigEndian ? 'big' : 'little')\n        .int8('nodeType')\n        .skip(1)\n        .int16('cnt')\n        .choice({\n          tag: 'nodeType',\n          choices: {\n            0: new Parser().array('leafkeys', {\n              length: 'cnt',\n              type: new Parser()\n                .string('key', { length: keySize, stripNull: true })\n                .uint64('offset'),\n            }),\n            1: new Parser().array('keys', {\n              length: 'cnt',\n              type: new Parser()\n                .string('key', { length: keySize, stripNull: true })\n                .uint64('offset')\n                .uint32('length')\n                .uint32('reserved'),\n            }),\n          },\n        })\n\n      const bptReadNode = async (\n        nodeOffset: number,\n      ): Promise<Loc | undefined> => {\n        const len = 4 + blockSize * (keySize + valSize)\n        const { buffer } = await this.bbi.read(\n          Buffer.alloc(len),\n          0,\n          len,\n          nodeOffset,\n          opts,\n        )\n        const node = bpt.parse(buffer).result\n        if (node.leafkeys) {\n          let lastOffset\n          for (let i = 0; i < node.leafkeys.length; i += 1) {\n            const { key } = node.leafkeys[i]\n            if (name.localeCompare(key) < 0 && lastOffset) {\n              return bptReadNode(lastOffset)\n            }\n            lastOffset = node.leafkeys[i].offset\n          }\n          return bptReadNode(lastOffset)\n        }\n        for (let i = 0; i < node.keys.length; i += 1) {\n          if (node.keys[i].key === name) {\n            return { ...node.keys[i], field }\n          }\n        }\n\n        return undefined\n      }\n      const rootNodeOffset = 32\n      return bptReadNode(offset + rootNodeOffset)\n    })\n    return filterUndef(await Promise.all(locs))\n  }\n\n  /*\n   * retrieve the features from the bigbed data that were found through the lookup of the extraIndex\n   * note that there can be multiple extraIndex, see the BigBed specification and the -extraIndex argument to bedToBigBed\n   *\n   * @param name - the name to search for\n   * @param opts - a SearchOptions argument with optional signal\n   * @return a Promise for an array of Feature\n   */\n  public async searchExtraIndex(\n    name: string,\n    opts: RequestOptions = {},\n  ): Promise<Feature[]> {\n    const blocks = await this.searchExtraIndexBlocks(name, opts)\n    if (!blocks.length) {\n      return []\n    }\n    const view = await this.getUnzoomedView(opts)\n    const res = blocks.map(block => {\n      return new Observable((observer: Observer<Feature[]>) => {\n        view.readFeatures(observer, [block], opts)\n      }).pipe(\n        reduce((acc, curr) => acc.concat(curr)),\n        map(x => {\n          for (let i = 0; i < x.length; i += 1) {\n            x[i].field = block.field\n          }\n          return x\n        }),\n      )\n    })\n    const ret = await merge(...res).toPromise()\n    return ret.filter((f: any) => {\n      return f.rest.split('\\t')[f.field - 3] === name\n    })\n  }\n}\n"],"names":["unzip","input","Buffer","from","inflate","Range","arg1","arg2","this","ranges","arguments","length","min","max","Object","assign","pos","s","r","map","join","s1","getRanges","concat","sort","rangeOrder","oranges","current","i","nxt","push","arg","s0","r0","r1","l0","l1","i0","i1","or","lapMin","Math","lapMax","Error","tot","rl","ri","tmpa","tmpb","a","b","AbortError","message","code","groupBlocks","blocks","b0","b1","offset","lastBlock","lastBlockEnd","blockGroups","checkAbortSignal","signal","aborted","DOMException","e","BlockView","bbi","refsByName","cirTreeOffset","cirTreeLength","isBigEndian","isCompressed","blockType","featureCache","AbortablePromiseCache","cache","QuickLRU","maxSize","fill","requestData","read","alloc","buffer","le","summaryParser","Parser","endianess","uint32","float","leafParser","uint8","skip","uint16","choice","tag","choices","array","type","uint64","bigBedParser","int32","string","zeroTerminated","bigWigParser","getParsers","chrName","start","end","observer","opts","undefined","chrId","complete","request","cirTreePromise","cirBlockSize","readUInt32BE","readUInt32LE","blocksToFetch","outstanding","cirFobRecur2","cirBlockData","level","data","slice","p","parse","result","filter","filterFeats","l","blockOffset","blockSize","recurOffsets","cirFobRecur","error","startChrom","startBase","endChrom","endBase","cirFobStartFetch","off","fr","get","resultBuffer","contains","readFeatures","maxCirBlockSpan","spans","blockSpan","union","startOffset","features","currOffset","byteLength","res","items","elt","chromId","feats","maxScore","minScore","score","sumData","validCnt","summary","f","coordFilter","uniqueId","bytes","results","itemSpan","itemStep","blockStart","blockGroupsToFetch","Promise","all","blockGroup","forEach","block","resultData","next","parseSummaryBlock","parseBigWigBlock","parseBigBedBlock","console","warn","range","BIG_WIG_MAGIC","BIG_BED_MAGIC","isBE","headerParser","totalSummaryParser","double","chromTreeParser","isLeafNode","BBI","options","headerCache","params","_getHeader","filehandle","renameRefSeqs","path","url","RemoteFile","LocalFile","JSON","stringify","_getMainHeader","header","_readChromTree","chroms","requestSize","_isBigEndian","ret","fileType","magic","asOffset","totalSummaryOffset","autoSql","indexOf","toString","tail","totalSummary","readInt32LE","readInt32BE","refsByNumber","chromTreeOffset","unzoomedDataOffset","keySize","leafNodeParser","stripNull","nonleafNodeParser","bptReadNode","currentOffset","cnt","n","leafRet","key","refId","refSize","refRec","name","id","nextNodes","nonleafRet","childOffset","getHeader","unzoomedIndexOffset","zoomLevels","uncompressBufSize","nzl","cirLen","dataOffset","refName","scale","basesPerSpan","getView","view","Observable","readWigData","getFeatureStream","ob","pipe","reduce","acc","curr","toPromise","BigWig","fileSize","basesPerPx","maxLevel","zh","reductionLevel","indexLength","indexOffset","getUnzoomedView","filterUndef","ts","t","BigBed","readIndicesCache","args","_readIndices","extHeaderOffset","count","len","blocklen","extParser","int16","indices","readIndices","locs","index","field","valSize","bpt","int8","nodeOffset","node","leafkeys","localeCompare","lastOffset","keys","searchExtraIndexBlocks","x","merge","rest","split"],"sourceRoot":""}