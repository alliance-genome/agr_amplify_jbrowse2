{"version":3,"file":"static/js/8111.d68c8806.chunk.js","mappings":"wPAIA,MAAM,cAAEA,GAAkBC,EAAAA,eAEX,MAAMC,UAAuBC,EAAAA,cAE1CC,GAAAA,CAAIC,GACF,MAAY,eAARA,EACKL,EAAcM,KAAKF,IAAI,UAEzBG,MAAMH,IAAIC,EACnB,E,eCqFF,SAASG,EAAaC,GAEpB,MAAOC,EAAUC,GAAaF,EAAOG,QACnC,EAAEF,EAAUC,IAAaE,EAAOC,KAAY,CAC1CJ,EAAWG,EAAQC,EACnBH,EAAYG,IAEd,CAAC,EAAG,IAEN,OAAOJ,EAAWC,CACpB,CAEO,SAASI,EAAaC,GAC3B,MACEC,EAAM,CAENC,EACAC,EACAC,EACAC,EAAM,CAENC,EACAC,EACAC,EACAC,EACAC,KACGC,GACDX,EAAKY,MAAM,MAWf,MAAO,CACLP,QACAC,QAASA,EACTC,MAAOA,EACPN,QACAC,QAASA,EACTC,MAAOA,EACPC,OAAmB,MAAXA,GAAkB,EAAI,EAC9BS,MAAO,CACLL,YAAaA,EACbC,UAAWA,EACXC,aAAcA,KApBLI,OAAOC,YAClBJ,EAAOK,KAAIC,IACT,MAAMC,EAAID,EAAME,QAAQ,KAGxB,MAAO,CAFWF,EAAMG,MAAM,EAAGF,GACdD,EAAMG,MAAMF,EAAI,GACL,MAmBpC,CAEO,SAASG,EAAUC,GACxB,MAAMC,EAAM,GACZ,IAAK,IAAIC,EAAIF,EAAMG,OAAS,EAAGD,GAAK,EAAGA,GAAK,EAAG,CAC7CD,EAAIG,KAAKJ,EAAME,IACf,MAAMG,EAAKL,EAAME,EAAI,GACV,MAAPG,EACFJ,EAAIG,KAAK,KACO,MAAPC,EACTJ,EAAIG,KAAK,KAETH,EAAIG,KAAKC,EAEb,CACA,OAAOJ,CACT,CC5IA,MAAM,WAAEK,GAAe3C,EAAAA,eAMR,MAAM4C,UAAmBC,EAAAA,uBAGtC,oBAA6B,CAAC,cAAe,eAE7C,WAAMC,CAAMC,GAOV,OANK1C,KAAK2C,SACR3C,KAAK2C,OAAS3C,KAAK4C,SAASF,GAAMG,OAAMC,IAEtC,MADA9C,KAAK2C,YAASI,EACRD,CAAC,KAGJ9C,KAAK2C,MACd,CAEA,cAAMC,CAASF,GACb,MAAMM,EAAKhD,KAAKiD,cACVC,GAAcC,EAAAA,EAAAA,cAAanD,KAAKoD,QAAQ,eAAgBJ,GACxDK,QAAgBH,EAAYI,SAASZ,GACrCa,GAAMC,EAAAA,EAAAA,IAAOH,SAAgBI,EAAAA,EAAAA,OAAMJ,GAAUA,EACnD,OAAOK,EAAAA,EAAAA,IAAgBH,EAAK9C,EAC9B,CAEA,uBAAMkD,GAIJ,OAAO,CACT,CAEAC,gBAAAA,GACE,MAAMC,EAAgB7D,KAAKoD,QAAQ,iBACnC,OAA6B,IAAzBS,EAAc1B,OAGT,CAFOnC,KAAKoD,QAAQ,iBACZpD,KAAKoD,QAAQ,mBAGvBS,CACT,CAEA,iBAAMC,CAAYpB,EAAoB,CAAC,GAErC,MAAMqB,EAAKrB,EAAKsB,UAAU,GAAGC,aACvBC,QAAclE,KAAKyC,MAAMC,GAEzByB,EAAMnE,KAAK4D,mBAAmB/B,QAAQkC,GAC5C,IAAa,IAATI,EAAY,CACd,MAAMC,EAAM,IAAIC,IAChB,IAAK,MAAMC,KAAQJ,EACjBE,EAAIG,IAAY,IAARJ,EAAYG,EAAK3D,MAAQ2D,EAAKvD,OAExC,MAAO,IAAIqD,EACb,CAEA,OADAI,QAAQC,KAAK,wCACN,EACT,CAEAC,WAAAA,CAAYC,EAAejC,EAAmB,CAAC,GAC7C,OAAOkC,EAAAA,EAAAA,mBAA0BC,UAC/B,IAAIC,QAAmB9E,KAAKyC,MAAMC,GAClC,MAAM,OAAEqC,GAAWrC,EAIfqC,GAAgD,uBAAtCC,EAAAA,EAAAA,gBAAeD,EAAQ,aACnCD,EDzCD,SAA0BG,GAC/B,MAAMC,EAA+D,CAAC,EACtE,IAAK,MAAMC,KAASF,EAAK,CACvB,MAEMG,EAFQD,EAAMxE,MAEA,IADLwE,EAAMpE,MAEhBmE,EAASE,KACZF,EAASE,GAAO,CAAEC,MAAO,GAAIC,IAAK,KAEpCJ,EAASE,GAAKC,MAAMjD,KAAK+C,EAAM5D,MAAMH,aACrC8D,EAASE,GAAKE,IAAIlD,KAAK+C,EAAM5D,MAAMJ,UAAY,EACjD,CAEA,MAAMoE,EAAe/D,OAAOC,YAC1BD,OAAOgE,QAAQN,GAAUxD,KAAI,EAAE0D,EAAKK,KAE3B,CAACL,EAAKlF,GADAwF,EAAAA,EAAAA,IAAID,EAAIJ,MAAOI,EAAIH,UAIpC,IAAK,MAAMH,KAASF,EAAK,CACvB,MAEMG,EAFQD,EAAMxE,MAEA,IADLwE,EAAMpE,MAErBoE,EAAM5D,MAAMoE,UAAYJ,EAAaH,EACvC,CAEA,IAAIQ,EAAM,IACNC,EAAM,EACV,IAAK,MAAMV,KAASF,EAClBW,EAAME,KAAKF,IAAIT,EAAM5D,MAAMoE,WAAa,EAAGC,GAC3CC,EAAMC,KAAKD,IAAIV,EAAM5D,MAAMoE,WAAa,EAAGE,GAE7C,IAAK,MAAMV,KAASF,EAAK,CACvB,MAAMc,EAAIZ,EAAM5D,MAAMoE,WAAa,EACnCR,EAAM5D,MAAMoE,WAAaI,EAAIH,IAAQC,EAAMD,EAC7C,CAEA,OAAOX,CACT,CCGqBe,CAAiBlB,IAEhC,MAAMjB,EAAgB7D,KAAK4D,mBAIrBqC,EAAQpC,EAAchC,QAAQ8C,EAAMV,eAClCiC,MAAOtF,EAAQuF,IAAKtF,EAAMuF,QAASC,EAAI,aAAEpC,GAAiBU,GACnD,IAAXsB,IACFzB,QAAQC,KAAM,GAAER,+BAChBqC,EAASC,YAGX,IAAK,IAAIrE,EAAI,EAAGA,EAAI4C,EAAW3C,OAAQD,IAAK,CAC1C,MAAMN,EAAIkD,EAAW5C,GACrB,IAAIgE,EAAQ,EACRC,EAAM,EACNC,EAAU,GACVI,EAAW,GACXC,EAAY,EACZC,EAAU,EACd,MAAMC,EAAiB,IAAVV,EACPhC,EAAeJ,IAAgB8C,GACvB,IAAVV,GACFC,EAAQtE,EAAEhB,OACVuF,EAAMvE,EAAEf,KACRuF,EAAUxE,EAAEjB,MACZ6F,EAAW5E,EAAEb,MACb0F,EAAY7E,EAAEZ,OACd0F,EAAU9E,EAAEX,OAEZiF,EAAQtE,EAAEZ,OACVmF,EAAMvE,EAAEX,KACRmF,EAAUxE,EAAEb,MACZyF,EAAW5E,EAAEjB,MACb8F,EAAY7E,EAAEhB,OACd8F,EAAU9E,EAAEf,MAEd,MAAM,MAAEU,EAAK,OAAET,GAAWc,EAC1B,GAAIwE,IAAYC,IAAQO,EAAAA,EAAAA,IAAehG,EAAQC,EAAMqF,EAAOC,GAAM,CAChE,MAAM,WAAEjF,EAAa,EAAC,SAAEC,EAAW,EAAC,GAAE0F,KAAOC,GAASvF,EAEtD,IAAIwF,EAAQxF,EAAMsF,GACdtF,EAAMsF,KACJF,IAAoB,IAAZ7F,EACViG,EAAQhF,EAAUO,EAAWf,EAAMsF,KAAKG,KAAK,IACpCL,IACTI,EAAuBxF,EAAMsF,GDyB5BI,WAAW,IAAK,KAAKA,WAAW,IAAK,KAAKA,WAAW,IAAK,OCrB/DX,EAASY,KACP,IAAItH,EAAe,CACjBuH,SAAUjF,EAAI+B,EACdA,eACAiC,QACAC,MACAiB,KAAM,QACNhB,UACAtF,YACGgG,EACHC,QACAM,UAAWnF,EACXoF,SAAUpG,EAAaC,EACvBD,aACAC,WACAoG,KAAM,CACJrB,MAAOO,EACPN,IAAKO,EACLN,QAASI,EACTvC,aAAcJ,GAAe8C,MAIrC,CACF,CAEAL,EAASC,UAAU,GAEvB,CAEAiB,aAAAA,GAAsC,E,uFC9KjC,SAAShE,EAAOD,GACrB,OAAkB,KAAXA,EAAI,IAAwB,MAAXA,EAAI,IAAyB,IAAXA,EAAI,EAChD,CAEO,SAASkE,EAASC,GACvB,OAAO,IAAIC,IACTD,EACGpG,MAAM,cACNsG,QAAOC,KAAOA,GAAKA,EAAEC,WAAW,OAChCpG,KAAIhB,IACH,MAAO0F,EAASF,EAAOC,EAAK4B,EAAMC,EAAOlH,GAAUJ,EAAKY,MAAM,MAC9D,MAAO,CACLyG,EACA,CACE3B,UACAF,OAAQA,EACRC,KAAMA,EACN6B,OAAQA,EACRD,OACAjH,OAAmB,MAAXA,GAAkB,EAAI,GAEjC,IAGT,CAEO+D,eAAevB,EAAS2E,EAAyBvF,GACtD,MAAMW,QAAgB4E,EAAK3E,SAASZ,GACpC,OAAO,IAAIwF,YAAY,OAAQ,CAAEC,OAAO,IAAQC,OAC9C5E,EAAOH,SAAgBI,EAAAA,EAAAA,OAAMJ,GAAUA,EAE3C,CAEO,SAASqC,EAAI2C,EAAatC,GAC/B,OAAOsC,EAAE3G,KAAI,CAACoB,EAAGZ,IAAM,CAACY,EAAGiD,EAAE7D,KAC/B,CAEA,MAAMoG,EACmB,oBAAhBJ,YAA8B,IAAIA,YAAY,aAAUnF,EAE1D,SAASW,EACdL,EACAkF,GAEA,IAAIC,EAAa,EACjB,MAAMhD,EAAU,GAChB,KAAOgD,EAAanF,EAAOlB,QAAQ,CACjC,MAAMsG,EAAIpF,EAAOxB,QAAQ,KAAM2G,GAC/B,IAAW,IAAPC,EACF,MAEF,MAAM1C,EAAI1C,EAAOvB,MAAM0G,EAAYC,GAC7B/H,GAAQ4H,GAASF,OAAOrC,IAAMA,EAAE2C,YAAYC,OAC9CjI,GACF8E,EAAQpD,KAAKmG,EAAG7H,IAGlB8H,EAAaC,EAAI,CACnB,CACA,OAAOjD,CACT,C,8FChDAX,eAAepB,EAAMmF,GACnB,IACE,IAAIC,EACAC,EAAM,EACN5G,EAAI,EACR,MAAM6G,EAAS,GACf,IACIC,EADAC,EAAY,EAEhB,EAAG,CACD,MAAMC,EAAiBN,EAAUO,SAASL,GAK1C,GAJAE,EAAW,IAAI,EAAAI,UAEXP,QAASG,GACbA,EAAS5G,KAAK8G,EAAgB,EAAAG,cAC1BL,EAASM,IACX,MAAM,IAAIC,MAAMP,EAASQ,KAG3BV,GAAOD,EAAKY,QACZV,EAAO7G,GAAK8G,EAASU,OACrBT,GAAaF,EAAO7G,GAAGC,OACvBD,GAAK,C,OACE2G,EAAKc,UAEd,MAAMD,EAAS,IAAIE,WAAWX,GAC9B,IAAK,IAAI/G,EAAI,EAAG2H,EAAS,EAAG3H,EAAI6G,EAAO5G,OAAQD,IAC7CwH,EAAOtF,IAAI2E,EAAO7G,GAAI2H,GACtBA,GAAUd,EAAO7G,GAAGC,OAEtB,OAAO,EAAA2H,OAAOC,KAAKL,E,CACnB,MAAO5G,GAEP,GAAI,GAAGA,IAAIkH,MAAM,0BACf,MAAM,IAAIT,MACR,4DAGJ,MAAMzG,C,CAEV,CAgDA+B,eAAeoF,EAAgBrB,EAAmBsB,GAChD,IACE,IAAIrB,EACJ,MAAM,KAAEsB,EAAI,KAAEC,GAASF,EACvB,IAAIG,EAAOF,EAAKG,cACZC,EAAOJ,EAAKK,aAChB,MAAMzB,EAAS,GACT0B,EAAa,GACbC,EAAa,GAEnB,IAAIzB,EAAY,EACZ/G,EAAI,EACR,EAAG,CACD,MAAMgH,EAAiBN,EAAUO,SAASkB,EAAOF,EAAKG,eAChDtB,EAAW,IAAI,EAAAI,QAIrB,KAFIP,QAASG,GACbA,EAAS5G,KAAK8G,EAAgB,EAAAG,cAC1BL,EAASM,IACX,MAAM,IAAIC,MAAMP,EAASQ,KAG3B,MAAMnG,EAAS2F,EAASU,OACxBX,EAAO3G,KAAKiB,GACZ,IAAIiC,EAAMjC,EAAOlB,OAEjBsI,EAAWrI,KAAKiI,GAChBK,EAAWtI,KAAKmI,GACM,IAAlBxB,EAAO5G,QAAgBgI,EAAKK,eAE9BzB,EAAO,GAAKA,EAAO,GAAGI,SAASgB,EAAKK,cACpClF,EAAMyD,EAAO,GAAG5G,QAElB,MAAMwI,EAAWN,EAIjB,GAHAA,GAAQxB,EAAKY,QACbc,GAAQjF,EAEJqF,GAAYP,EAAKE,cAAe,CAKlCvB,EAAO7G,GAAK6G,EAAO7G,GAAGiH,SACpB,EACAiB,EAAKE,gBAAkBH,EAAKG,cACxBF,EAAKI,aAAeL,EAAKK,aAAe,EACxCJ,EAAKI,aAAe,GAG1BC,EAAWrI,KAAKiI,GAChBK,EAAWtI,KAAKmI,GAChBtB,GAAaF,EAAO7G,GAAGC,OACvB,K,CAEF8G,GAAaF,EAAO7G,GAAGC,OACvBD,G,OACO2G,EAAKc,UAEd,MAAMD,EAAS,IAAIE,WAAWX,GAC9B,IAAK,IAAI/G,EAAI,EAAG2H,EAAS,EAAG3H,EAAI6G,EAAO5G,OAAQD,IAC7CwH,EAAOtF,IAAI2E,EAAO7G,GAAI2H,GACtBA,GAAUd,EAAO7G,GAAGC,OAItB,MAAO,CAAEkB,OAFM,EAAAyG,OAAOC,KAAKL,GAEVe,aAAYC,a,CAC7B,MAAO5H,GAEP,GAAI,GAAGA,IAAIkH,MAAM,0BACf,MAAM,IAAIT,MACR,4DAGJ,MAAMzG,C,CAEV,C,wBC5Ke,MAAM8H,EAKnB,WAAAC,EAAY,WACVC,EAAU,KACVC,IAKA,GAAID,EACF9K,KAAK8K,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIC,UAAU,6CAFpBhL,KAAK8K,WAAa,IAAI,KAAUC,E,CAIpC,CAEA,qBAAAE,CAAsB1H,EAAasG,EAAS,EAAGqB,GAAW,GAExD,MAAMC,EAAO,gBAAiB5H,EAAIzB,MAAM+H,EAAQA,EAAS,GAAIqB,GAC7D,GACEC,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBAErB,MAAM,IAAIR,UAAU,oBAGtB,OAAOG,EAAKM,UACd,CAEA,SAAAC,GAIE,OAHK1L,KAAKiG,QACRjG,KAAKiG,MAAQjG,KAAK2L,cAEb3L,KAAKiG,KACd,CAEA,gBAAM0F,GACJ,IAAIpI,EAAM,EAAAuG,OAAO8B,YAAY,SACvB5L,KAAK8K,WAAWe,KAAKtI,EAAK,EAAG,EAAG,GACtC,MAAMuI,EAAa9L,KAAKiL,sBAAsB1H,EAAK,GAAG,GACtD,IAAKuI,EACH,MAAO,CAAC,CAAC,EAAG,IAGd,MAAMtG,EAAU,IAAIuG,MAAMD,EAAa,GACvCtG,EAAQ,GAAK,CAAC,EAAG,GAGjB,MAAMwG,EAAU,GAAQF,EACxB,GAAIE,EAAUX,OAAOC,iBACnB,MAAM,IAAIN,UAAU,oBAEtBzH,EAAM,EAAAuG,OAAO8B,YAAYI,SACnBhM,KAAK8K,WAAWe,KAAKtI,EAAK,EAAGyI,EAAS,GAC5C,IAAK,IAAIC,EAAc,EAAGA,EAAcH,EAAYG,GAAe,EAAG,CACpE,MAAMC,EAAqBlM,KAAKiL,sBAC9B1H,EACc,GAAd0I,GAEIE,EAAuBnM,KAAKiL,sBAChC1H,EACc,GAAd0I,EAAmB,GAErBzG,EAAQyG,EAAc,GAAK,CAACC,EAAoBC,E,CAGlD,OAAO3G,CACT,CAEA,kBAAM4G,GACJ,MAAM5G,QAAgBxF,KAAK0L,YAC3B,GAAKlG,EAAQrD,OAGb,OAAOqD,EAAQA,EAAQrD,OAAS,EAClC,CAEA,8BAAMkK,CAAyBlK,EAAgBmK,GAC7C,MAAMC,EAAcD,EAAWnK,EAC/B,GAAe,IAAXA,EACF,MAAO,GAET,MAAMqD,QAAgBxF,KAAK0L,YACrBc,EAAW,GAIXC,EAAU,CAACtH,EAAYuH,KAC3B,MAAMP,EAAuBhH,EA/FL,GAgGlBwH,EAA2BD,EAC7BA,EAjGoB,GAkGpBE,IAEJ,OACET,GAAwBG,GACxBK,EAA2BL,EAEpB,EAGLH,EAAuBG,GACjB,EAGH,CAAC,EAGV,IAAIO,EAAa,EACbC,EAAatH,EAAQrD,OAAS,EAC9B4K,EAAiBjH,KAAKkH,MAAMxH,EAAQrD,OAAS,GAE7C8K,EAAaR,EACfjH,EAAQuH,GACRvH,EAAQuH,EAAiB,IAE3B,KAAsB,IAAfE,GACDA,EAAa,EACfH,EAAaC,EAAiB,EACrBE,EAAa,IACtBJ,EAAaE,EAAiB,GAEhCA,EAAiBjH,KAAKoH,MAAMJ,EAAaD,GAAc,GAAKA,EAC5DI,EAAaR,EAAQjH,EAAQuH,GAAiBvH,EAAQuH,EAAiB,IAIzEP,EAASpK,KAAKoD,EAAQuH,IACtB,IAAI7K,EAAI6K,EAAiB,EACzB,KAAO7K,EAAIsD,EAAQrD,SACjBqK,EAASpK,KAAKoD,EAAQtD,MAClBsD,EAAQtD,GAzIY,IAyIiBqK,IAFhBrK,GAAK,GAShC,OAHIsK,EAASA,EAASrK,OAAS,GA7IL,GA6IiCoK,GACzDC,EAASpK,KAAK,IAEToK,CACT,EC/Ia,MAAMW,EAInB,WAAAtC,EAAY,WACVC,EAAU,KACVC,EAAI,cACJqC,EAAa,QACbC,IAOA,GAAIvC,EACF9K,KAAK8K,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIC,UAAU,6CAFpBhL,KAAK8K,WAAa,IAAI,KAAUC,E,CAKlC,IAAKqC,IAAkBC,IAAYtC,EACjC,MAAM,IAAIC,UAAU,mDAGtBhL,KAAKsN,IAAM,IAAI1C,EAAS,CACtBE,WAAYsC,EACZrC,KAAOqC,GAAkBC,IAAWtC,EAAiB,GAAGA,QAAbsC,GAE/C,CAEA,UAAME,GACJ,MAAMC,QAAuBxN,KAAK8K,WAAWyC,OAC7C,OAAO/L,OAAOiM,OAAOD,EAAgB,CACnCE,WAAY1N,KAAK2N,0BACjBC,YAAQ7K,EACR8K,aAAS9K,GAEb,CAEA,6BAAM4K,GAGJ,MAAO,CAAExB,SAA8BnM,KAAKsN,IAAIlB,gBAE1C,KAAEsB,SAAe1N,KAAK8K,WAAWyC,OAEjChK,EAAM,EAAAuG,OAAO8B,YAAY,IAGzB,UAAEkC,SAAoB9N,KAAK8K,WAAWe,KAAKtI,EAAK,EAAG,EAAGmK,EAAO,GAAK,GACxE,GAAkB,IAAdI,EACF,MAAM,IAAIvE,MAAM,cAGlB,OAAO4C,EAD2B5I,EAAIwK,aAAa,EAErD,CAEA,6BAAMC,CACJC,GACC/B,IACAgC,IAED,IAAIhH,EAAOgH,EACNhH,IACHA,SAAclH,KAAK8K,WAAWyC,QAAQG,MAIxC,MAAMS,EAAwBjH,EAAOgF,EAcrC,aAZMlM,KAAK8K,WAAWe,KACpBoC,EACA,EACAE,EACAjC,SAI2BzI,EAC3BwK,EAAYnM,MAAM,EAAGqM,GAIzB,CAEA,UAAMtC,CAAKtI,EAAasG,EAAgB1H,EAAgBmK,GAEtD,MAAM8B,QAAuBpO,KAAKsN,IAAIjB,yBACpClK,EACAmK,GAEI2B,EAAc,EAAAnE,OAAO8B,YAAY,OAEvC,IAAIyC,EAAoBxE,EACpBiE,EAAY,EAChB,IACE,IAAIQ,EAAW,EACfA,EAAWF,EAAejM,OAAS,EACnCmM,GAAY,EACZ,CAEA,MAAMC,QAA2BvO,KAAKgO,wBACpCC,EACAG,EAAeE,GACfF,EAAeE,EAAW,KAErB,CAAEnC,GAAwBiC,EAAeE,GAC1CE,EACJrC,GAAwBG,EAAW,EAAIA,EAAWH,EAC9CsC,EACJ3I,KAAKF,IACH0G,EAAWnK,EACXgK,EAAuBoC,EAAmBpM,QACxCgK,EACFqC,GAAgB,GAAKA,EAAeD,EAAmBpM,SACzDoM,EAAmBG,KAAKnL,EAAK8K,EAAmBG,EAAcC,GAC9DJ,GAAqBI,EAAYD,EACjCV,GAAaW,EAAYD,E,CAI7B,MAAO,CAAEV,YAAWzK,OAAQE,EAC9B,E","sources":["../../../plugins/comparative-adapters/src/PAFAdapter/SyntenyFeature.ts","../../../plugins/comparative-adapters/src/PAFAdapter/util.ts","../../../plugins/comparative-adapters/src/PAFAdapter/PAFAdapter.ts","../../../plugins/comparative-adapters/src/util.ts","../../../node_modules/@gmod/bgzf-filehandle/src/unzip-pako.ts","../../../node_modules/@gmod/bgzf-filehandle/src/gziIndex.ts","../../../node_modules/@gmod/bgzf-filehandle/src/bgzFilehandle.ts"],"sourcesContent":["import { SimpleFeature } from '@jbrowse/core/util'\nimport { MismatchParser } from '@jbrowse/plugin-alignments'\n\n// locals\nconst { getMismatches } = MismatchParser\n\nexport default class SyntenyFeature extends SimpleFeature {\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  get(arg: string): any {\n    if (arg === 'mismatches') {\n      return getMismatches(this.get('CIGAR'))\n    }\n    return super.get(arg)\n  }\n}\n","import { zip } from '../util'\n\nexport interface PAFRecord {\n  qname: string\n  qstart: number\n  qend: number\n  tname: string\n  tstart: number\n  tend: number\n  strand: number\n  extra: {\n    cg?: string\n    blockLen?: number\n    mappingQual: number\n    numMatches?: number\n    meanScore?: number\n  }\n}\n// based on \"weighted mean\" method from https://github.com/tpoorten/dotPlotly\n// License reproduced here\n//\n// MIT License\n\n// Copyright (c) 2017 Tom Poorten\n\n// Permission is hereby granted, free of charge, to any person obtaining a copy\n// of this software and associated documentation files (the \"Software\"), to deal\n// in the Software without restriction, including without limitation the rights\n// to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n// copies of the Software, and to permit persons to whom the Software is\n// furnished to do so, subject to the following conditions:\n\n// The above copyright notice and this permission notice shall be included in all\n// copies or substantial portions of the Software.\n\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n// IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n// FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n// AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n// LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n// OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n// SOFTWARE.\n//\n// Notes: in the weighted mean longer alignments factor in more heavily of all\n// the fragments of a query vs the reference that it mapped to\n//\n// this uses a combined key query+'-'+ref to iteratively map all the alignments\n// that match a particular ref from a particular query (so 1d array of what\n// could be a 2d map)\n//\n// the result is a single number that says e.g. chr5 from human mapped to chr5\n// on mouse with 0.8 quality, and that0.8 is then attached to all the pieces of\n// chr5 on human that mapped to chr5 on mouse. if chr5 on human also more\n// weakly mapped to chr6 on mouse, then it would have another value e.g. 0.6.\n// this can show strong and weak levels of synteny, especially in polyploidy\n// situations\n\nexport function getWeightedMeans(ret: PAFRecord[]) {\n  const scoreMap: Record<string, { quals: number[]; len: number[] }> = {}\n  for (const entry of ret) {\n    const query = entry.qname\n    const target = entry.tname\n    const key = query + '-' + target\n    if (!scoreMap[key]) {\n      scoreMap[key] = { quals: [], len: [] }\n    }\n    scoreMap[key].quals.push(entry.extra.mappingQual)\n    scoreMap[key].len.push(entry.extra.blockLen || 1)\n  }\n\n  const meanScoreMap = Object.fromEntries(\n    Object.entries(scoreMap).map(([key, val]) => {\n      const vals = zip(val.quals, val.len)\n      return [key, weightedMean(vals)]\n    }),\n  )\n  for (const entry of ret) {\n    const query = entry.qname\n    const target = entry.tname\n    const key = query + '-' + target\n    entry.extra.meanScore = meanScoreMap[key]\n  }\n\n  let min = 10000\n  let max = 0\n  for (const entry of ret) {\n    min = Math.min(entry.extra.meanScore || 0, min)\n    max = Math.max(entry.extra.meanScore || 0, max)\n  }\n  for (const entry of ret) {\n    const b = entry.extra.meanScore || 0\n    entry.extra.meanScore = (b - min) / (max - min)\n  }\n\n  return ret\n}\n\n// https://gist.github.com/stekhn/a12ed417e91f90ecec14bcfa4c2ae16a\nfunction weightedMean(tuples: [number, number][]) {\n  // eslint-disable-next-line unicorn/no-array-reduce\n  const [valueSum, weightSum] = tuples.reduce(\n    ([valueSum, weightSum], [value, weight]) => [\n      valueSum + value * weight,\n      weightSum + weight,\n    ],\n    [0, 0],\n  )\n  return valueSum / weightSum\n}\n\nexport function parsePAFLine(line: string) {\n  const [\n    qname,\n    ,\n    qstart,\n    qend,\n    strand,\n    tname,\n    ,\n    tstart,\n    tend,\n    numMatches,\n    blockLen,\n    mappingQual,\n    ...fields\n  ] = line.split('\\t')\n\n  const rest = Object.fromEntries(\n    fields.map(field => {\n      const r = field.indexOf(':')\n      const fieldName = field.slice(0, r)\n      const fieldValue = field.slice(r + 3)\n      return [fieldName, fieldValue]\n    }),\n  )\n\n  return {\n    tname,\n    tstart: +tstart,\n    tend: +tend,\n    qname,\n    qstart: +qstart,\n    qend: +qend,\n    strand: strand === '-' ? -1 : 1,\n    extra: {\n      numMatches: +numMatches,\n      blockLen: +blockLen,\n      mappingQual: +mappingQual,\n      ...rest,\n    },\n  } as PAFRecord\n}\n\nexport function flipCigar(cigar: string[]) {\n  const arr = []\n  for (let i = cigar.length - 2; i >= 0; i -= 2) {\n    arr.push(cigar[i])\n    const op = cigar[i + 1]\n    if (op === 'D') {\n      arr.push('I')\n    } else if (op === 'I') {\n      arr.push('D')\n    } else {\n      arr.push(op)\n    }\n  }\n  return arr\n}\n\nexport function swapIndelCigar(cigar: string) {\n  return cigar.replaceAll('D', 'K').replaceAll('I', 'D').replaceAll('K', 'I')\n}\n","import {\n  BaseFeatureDataAdapter,\n  BaseOptions,\n} from '@jbrowse/core/data_adapters/BaseAdapter'\nimport { Region } from '@jbrowse/core/util/types'\nimport { doesIntersect2 } from '@jbrowse/core/util/range'\nimport { openLocation } from '@jbrowse/core/util/io'\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs'\nimport { Feature } from '@jbrowse/core/util'\nimport {\n  AnyConfigurationModel,\n  readConfObject,\n} from '@jbrowse/core/configuration'\nimport { unzip } from '@gmod/bgzf-filehandle'\nimport { MismatchParser } from '@jbrowse/plugin-alignments'\n\n// locals\nimport SyntenyFeature from './SyntenyFeature'\nimport { isGzip, parseLineByLine } from '../util'\nimport {\n  getWeightedMeans,\n  flipCigar,\n  swapIndelCigar,\n  parsePAFLine,\n  PAFRecord,\n} from './util'\n\nconst { parseCigar } = MismatchParser\n\ninterface PAFOptions extends BaseOptions {\n  config?: AnyConfigurationModel\n}\n\nexport default class PAFAdapter extends BaseFeatureDataAdapter {\n  private setupP?: Promise<PAFRecord[]>\n\n  public static capabilities = ['getFeatures', 'getRefNames']\n\n  async setup(opts?: BaseOptions) {\n    if (!this.setupP) {\n      this.setupP = this.setupPre(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async setupPre(opts?: BaseOptions) {\n    const pm = this.pluginManager\n    const pafLocation = openLocation(this.getConf('pafLocation'), pm)\n    const buffer = (await pafLocation.readFile(opts)) as Buffer\n    const buf = isGzip(buffer) ? await unzip(buffer) : buffer\n    return parseLineByLine(buf, parsePAFLine)\n  }\n\n  async hasDataForRefName() {\n    // determining this properly is basically a call to getFeatures\n    // so is not really that important, and has to be true or else\n    // getFeatures is never called (BaseAdapter filters it out)\n    return true\n  }\n\n  getAssemblyNames() {\n    const assemblyNames = this.getConf('assemblyNames') as string[]\n    if (assemblyNames.length === 0) {\n      const query = this.getConf('queryAssembly') as string\n      const target = this.getConf('targetAssembly') as string\n      return [query, target]\n    }\n    return assemblyNames\n  }\n\n  async getRefNames(opts: BaseOptions = {}) {\n    // @ts-expect-error\n    const r1 = opts.regions?.[0].assemblyName\n    const feats = await this.setup(opts)\n\n    const idx = this.getAssemblyNames().indexOf(r1)\n    if (idx !== -1) {\n      const set = new Set<string>()\n      for (const feat of feats) {\n        set.add(idx === 0 ? feat.qname : feat.tname)\n      }\n      return [...set]\n    }\n    console.warn('Unable to do ref renaming on adapter')\n    return []\n  }\n\n  getFeatures(query: Region, opts: PAFOptions = {}) {\n    return ObservableCreate<Feature>(async observer => {\n      let pafRecords = await this.setup(opts)\n      const { config } = opts\n\n      // note: this is not the adapter config, it is responding to a display\n      // setting passed in via the opts parameter\n      if (config && readConfObject(config, 'colorBy') === 'meanQueryIdentity') {\n        pafRecords = getWeightedMeans(pafRecords)\n      }\n      const assemblyNames = this.getAssemblyNames()\n\n      // The index of the assembly name in the query list corresponds to the\n      // adapter in the subadapters list\n      const index = assemblyNames.indexOf(query.assemblyName)\n      const { start: qstart, end: qend, refName: qref, assemblyName } = query\n      if (index === -1) {\n        console.warn(`${assemblyName} not found in this adapter`)\n        observer.complete()\n      }\n\n      for (let i = 0; i < pafRecords.length; i++) {\n        const r = pafRecords[i]\n        let start = 0\n        let end = 0\n        let refName = ''\n        let mateName = ''\n        let mateStart = 0\n        let mateEnd = 0\n        const flip = index === 0\n        const assemblyName = assemblyNames[+!flip]\n        if (index === 0) {\n          start = r.qstart\n          end = r.qend\n          refName = r.qname\n          mateName = r.tname\n          mateStart = r.tstart\n          mateEnd = r.tend\n        } else {\n          start = r.tstart\n          end = r.tend\n          refName = r.tname\n          mateName = r.qname\n          mateStart = r.qstart\n          mateEnd = r.qend\n        }\n        const { extra, strand } = r\n        if (refName === qref && doesIntersect2(qstart, qend, start, end)) {\n          const { numMatches = 0, blockLen = 1, cg, ...rest } = extra\n\n          let CIGAR = extra.cg\n          if (extra.cg) {\n            if (flip && strand === -1) {\n              CIGAR = flipCigar(parseCigar(extra.cg)).join('')\n            } else if (flip) {\n              CIGAR = swapIndelCigar(extra.cg)\n            }\n          }\n\n          observer.next(\n            new SyntenyFeature({\n              uniqueId: i + assemblyName,\n              assemblyName,\n              start,\n              end,\n              type: 'match',\n              refName,\n              strand,\n              ...rest,\n              CIGAR,\n              syntenyId: i,\n              identity: numMatches / blockLen,\n              numMatches,\n              blockLen,\n              mate: {\n                start: mateStart,\n                end: mateEnd,\n                refName: mateName,\n                assemblyName: assemblyNames[+flip],\n              },\n            }),\n          )\n        }\n      }\n\n      observer.complete()\n    })\n  }\n\n  freeResources(/* { query } */): void {}\n}\n","import { BaseOptions } from '@jbrowse/core/data_adapters/BaseAdapter'\nimport { GenericFilehandle } from 'generic-filehandle'\nimport { unzip } from '@gmod/bgzf-filehandle'\nimport { PAFRecord } from './PAFAdapter/util'\n\nexport function isGzip(buf: Buffer) {\n  return buf[0] === 31 && buf[1] === 139 && buf[2] === 8\n}\n\nexport function parseBed(text: string) {\n  return new Map(\n    text\n      .split(/\\n|\\r\\n|\\r/)\n      .filter(f => !!f || f.startsWith('#'))\n      .map(line => {\n        const [refName, start, end, name, score, strand] = line.split('\\t')\n        return [\n          name,\n          {\n            refName,\n            start: +start,\n            end: +end,\n            score: +score,\n            name,\n            strand: strand === '-' ? -1 : 1,\n          },\n        ]\n      }),\n  )\n}\n\nexport async function readFile(file: GenericFilehandle, opts?: BaseOptions) {\n  const buffer = (await file.readFile(opts)) as Buffer\n  return new TextDecoder('utf8', { fatal: true }).decode(\n    isGzip(buffer) ? await unzip(buffer) : buffer,\n  )\n}\n\nexport function zip(a: number[], b: number[]) {\n  return a.map((e, i) => [e, b[i]] as [number, number])\n}\n\nconst decoder =\n  typeof TextDecoder !== 'undefined' ? new TextDecoder('utf8') : undefined\n\nexport function parseLineByLine(\n  buffer: Buffer,\n  cb: (line: string) => PAFRecord,\n) {\n  let blockStart = 0\n  const entries = []\n  while (blockStart < buffer.length) {\n    const n = buffer.indexOf('\\n', blockStart)\n    if (n === -1) {\n      break\n    }\n    const b = buffer.slice(blockStart, n)\n    const line = (decoder?.decode(b) || b.toString()).trim()\n    if (line) {\n      entries.push(cb(line))\n    }\n\n    blockStart = n + 1\n  }\n  return entries\n}\n","import { Buffer } from 'buffer'\n//@ts-ignore\nimport { Z_SYNC_FLUSH, Inflate } from 'pako'\n\ninterface VirtualOffset {\n  blockPosition: number\n  dataPosition: number\n}\ninterface Chunk {\n  minv: VirtualOffset\n  maxv: VirtualOffset\n}\n\n// browserify-zlib, which is the zlib shim used by default in webpacked code,\n// does not properly uncompress bgzf chunks that contain more than\n// one bgzf block, so export an unzip function that uses pako directly\n// if we are running in a browser.\nasync function unzip(inputData: Buffer) {\n  try {\n    let strm\n    let pos = 0\n    let i = 0\n    const chunks = []\n    let totalSize = 0\n    let inflator\n    do {\n      const remainingInput = inputData.subarray(pos)\n      inflator = new Inflate()\n      //@ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      pos += strm.next_in\n      chunks[i] = inflator.result as Uint8Array\n      totalSize += chunks[i].length\n      i += 1\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    return Buffer.from(result)\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to pakounzip, except it does extra counting\n// to return the positions of compressed and decompressed\n// data offsets\nasync function unzipChunk(inputData: Buffer) {\n  try {\n    let strm\n    let cpos = 0\n    let dpos = 0\n    const blocks = []\n    const cpositions = []\n    const dpositions = []\n    do {\n      const remainingInput = inputData.slice(cpos)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = Buffer.from(inflator.result)\n      blocks.push(buffer)\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n\n      cpos += strm.next_in\n      dpos += buffer.length\n    } while (strm.avail_in)\n\n    const buffer = Buffer.concat(blocks)\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to unzipChunk above but slices (0,minv.dataPosition) and\n// (maxv.dataPosition,end) off\nasync function unzipChunkSlice(inputData: Buffer, chunk: Chunk) {\n  try {\n    let strm\n    const { minv, maxv } = chunk\n    let cpos = minv.blockPosition\n    let dpos = minv.dataPosition\n    const chunks = []\n    const cpositions = []\n    const dpositions = []\n\n    let totalSize = 0\n    let i = 0\n    do {\n      const remainingInput = inputData.subarray(cpos - minv.blockPosition)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = inflator.result\n      chunks.push(buffer as Uint8Array)\n      let len = buffer.length\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n      if (chunks.length === 1 && minv.dataPosition) {\n        // this is the first chunk, trim it\n        chunks[0] = chunks[0].subarray(minv.dataPosition)\n        len = chunks[0].length\n      }\n      const origCpos = cpos\n      cpos += strm.next_in\n      dpos += len\n\n      if (origCpos >= maxv.blockPosition) {\n        // this is the last chunk, trim it and stop decompressing\n        // note if it is the same block is minv it subtracts that already\n        // trimmed part of the slice length\n\n        chunks[i] = chunks[i].subarray(\n          0,\n          maxv.blockPosition === minv.blockPosition\n            ? maxv.dataPosition - minv.dataPosition + 1\n            : maxv.dataPosition + 1,\n        )\n\n        cpositions.push(cpos)\n        dpositions.push(dpos)\n        totalSize += chunks[i].length\n        break\n      }\n      totalSize += chunks[i].length\n      i++\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    const buffer = Buffer.from(result)\n\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\nfunction nodeUnzip() {\n  throw new Error('nodeUnzip not implemented.')\n}\n\nexport { unzip, unzipChunk, unzipChunkSlice, unzip as pakoUnzip, nodeUnzip }\n","import Long from 'long'\nimport { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// const COMPRESSED_POSITION = 0\nconst UNCOMPRESSED_POSITION = 1\n\nexport default class GziIndex {\n  filehandle: GenericFilehandle\n\n  index?: any\n\n  constructor({\n    filehandle,\n    path,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n  }\n\n  _readLongWithOverflow(buf: Buffer, offset = 0, unsigned = true) {\n    //@ts-ignore\n    const long = Long.fromBytesLE(buf.slice(offset, offset + 8), unsigned)\n    if (\n      long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n      long.lessThan(Number.MIN_SAFE_INTEGER)\n    ) {\n      throw new TypeError('integer overflow')\n    }\n\n    return long.toNumber()\n  }\n\n  _getIndex() {\n    if (!this.index) {\n      this.index = this._readIndex()\n    }\n    return this.index\n  }\n\n  async _readIndex() {\n    let buf = Buffer.allocUnsafe(8)\n    await this.filehandle.read(buf, 0, 8, 0)\n    const numEntries = this._readLongWithOverflow(buf, 0, true)\n    if (!numEntries) {\n      return [[0, 0]]\n    }\n\n    const entries = new Array(numEntries + 1)\n    entries[0] = [0, 0]\n\n    // TODO rewrite this to make an index-index that stays in memory\n    const bufSize = 8 * 2 * numEntries\n    if (bufSize > Number.MAX_SAFE_INTEGER) {\n      throw new TypeError('integer overflow')\n    }\n    buf = Buffer.allocUnsafe(bufSize)\n    await this.filehandle.read(buf, 0, bufSize, 8)\n    for (let entryNumber = 0; entryNumber < numEntries; entryNumber += 1) {\n      const compressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16,\n      )\n      const uncompressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16 + 8,\n      )\n      entries[entryNumber + 1] = [compressedPosition, uncompressedPosition]\n    }\n\n    return entries\n  }\n\n  async getLastBlock() {\n    const entries = await this._getIndex()\n    if (!entries.length) {\n      return undefined\n    }\n    return entries[entries.length - 1]\n  }\n\n  async getRelevantBlocksForRead(length: number, position: number) {\n    const endPosition = position + length\n    if (length === 0) {\n      return []\n    }\n    const entries = await this._getIndex()\n    const relevant = []\n\n    // binary search to find the block that the\n    // read starts in and extend forward from that\n    const compare = (entry: any, nextEntry: any) => {\n      const uncompressedPosition = entry[UNCOMPRESSED_POSITION]\n      const nextUncompressedPosition = nextEntry\n        ? nextEntry[UNCOMPRESSED_POSITION]\n        : Infinity\n      // block overlaps read start\n      if (\n        uncompressedPosition <= position &&\n        nextUncompressedPosition > position\n      ) {\n        return 0\n        // block is before read start\n      }\n      if (uncompressedPosition < position) {\n        return -1\n      }\n      // block is after read start\n      return 1\n    }\n\n    let lowerBound = 0\n    let upperBound = entries.length - 1\n    let searchPosition = Math.floor(entries.length / 2)\n\n    let comparison = compare(\n      entries[searchPosition],\n      entries[searchPosition + 1],\n    )\n    while (comparison !== 0) {\n      if (comparison > 0) {\n        upperBound = searchPosition - 1\n      } else if (comparison < 0) {\n        lowerBound = searchPosition + 1\n      }\n      searchPosition = Math.ceil((upperBound - lowerBound) / 2) + lowerBound\n      comparison = compare(entries[searchPosition], entries[searchPosition + 1])\n    }\n\n    // here's where we read forward\n    relevant.push(entries[searchPosition])\n    let i = searchPosition + 1\n    for (; i < entries.length; i += 1) {\n      relevant.push(entries[i])\n      if (entries[i][UNCOMPRESSED_POSITION] >= endPosition) {\n        break\n      }\n    }\n    if (relevant[relevant.length - 1][UNCOMPRESSED_POSITION] < endPosition) {\n      relevant.push([])\n    }\n    return relevant\n  }\n}\n","import { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// locals\nimport { unzip } from './unzip'\nimport GziIndex from './gziIndex'\n\nexport default class BgzFilehandle {\n  filehandle: GenericFilehandle\n  gzi: GziIndex\n\n  constructor({\n    filehandle,\n    path,\n    gziFilehandle,\n    gziPath,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n    gziFilehandle?: GenericFilehandle\n    gziPath?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n\n    if (!gziFilehandle && !gziPath && !path) {\n      throw new TypeError('either gziFilehandle or gziPath must be defined')\n    }\n\n    this.gzi = new GziIndex({\n      filehandle: gziFilehandle,\n      path: !gziFilehandle && !gziPath && path ? gziPath : `${path}.gzi`,\n    })\n  }\n\n  async stat() {\n    const compressedStat = await this.filehandle.stat()\n    return Object.assign(compressedStat, {\n      size: await this.getUncompressedFileSize(),\n      blocks: undefined,\n      blksize: undefined,\n    })\n  }\n\n  async getUncompressedFileSize() {\n    // read the last block's ISIZE (see gzip RFC),\n    // and add it to its uncompressedPosition\n    const [, uncompressedPosition] = await this.gzi.getLastBlock()\n\n    const { size } = await this.filehandle.stat()\n\n    const buf = Buffer.allocUnsafe(4)\n    // note: there should be a 28-byte EOF marker (an empty block) at\n    // the end of the file, so we skip backward past that\n    const { bytesRead } = await this.filehandle.read(buf, 0, 4, size - 28 - 4)\n    if (bytesRead !== 4) {\n      throw new Error('read error')\n    }\n    const lastBlockUncompressedSize = buf.readUInt32LE(0)\n    return uncompressedPosition + lastBlockUncompressedSize\n  }\n\n  async _readAndUncompressBlock(\n    blockBuffer: Buffer,\n    [compressedPosition]: [number],\n    [nextCompressedPosition]: [number],\n  ) {\n    let next = nextCompressedPosition\n    if (!next) {\n      next = (await this.filehandle.stat()).size\n    }\n\n    // read the compressed data into the block buffer\n    const blockCompressedLength = next - compressedPosition\n\n    await this.filehandle.read(\n      blockBuffer,\n      0,\n      blockCompressedLength,\n      compressedPosition,\n    )\n\n    // uncompress it\n    const unzippedBuffer = await unzip(\n      blockBuffer.slice(0, blockCompressedLength),\n    )\n\n    return unzippedBuffer as Buffer\n  }\n\n  async read(buf: Buffer, offset: number, length: number, position: number) {\n    // get the block positions for this read\n    const blockPositions = await this.gzi.getRelevantBlocksForRead(\n      length,\n      position,\n    )\n    const blockBuffer = Buffer.allocUnsafe(32768 * 2)\n    // uncompress the blocks and read from them one at a time to keep memory usage down\n    let destinationOffset = offset\n    let bytesRead = 0\n    for (\n      let blockNum = 0;\n      blockNum < blockPositions.length - 1;\n      blockNum += 1\n    ) {\n      // eslint-disable-next-line no-await-in-loop\n      const uncompressedBuffer = await this._readAndUncompressBlock(\n        blockBuffer,\n        blockPositions[blockNum],\n        blockPositions[blockNum + 1],\n      )\n      const [, uncompressedPosition] = blockPositions[blockNum]\n      const sourceOffset =\n        uncompressedPosition >= position ? 0 : position - uncompressedPosition\n      const sourceEnd =\n        Math.min(\n          position + length,\n          uncompressedPosition + uncompressedBuffer.length,\n        ) - uncompressedPosition\n      if (sourceOffset >= 0 && sourceOffset < uncompressedBuffer.length) {\n        uncompressedBuffer.copy(buf, destinationOffset, sourceOffset, sourceEnd)\n        destinationOffset += sourceEnd - sourceOffset\n        bytesRead += sourceEnd - sourceOffset\n      }\n    }\n\n    return { bytesRead, buffer: buf }\n  }\n}\n"],"names":["getMismatches","MismatchParser","SyntenyFeature","SimpleFeature","get","arg","this","super","weightedMean","tuples","valueSum","weightSum","reduce","value","weight","parsePAFLine","line","qname","qstart","qend","strand","tname","tstart","tend","numMatches","blockLen","mappingQual","fields","split","extra","Object","fromEntries","map","field","r","indexOf","slice","flipCigar","cigar","arr","i","length","push","op","parseCigar","PAFAdapter","BaseFeatureDataAdapter","setup","opts","setupP","setupPre","catch","e","undefined","pm","pluginManager","pafLocation","openLocation","getConf","buffer","readFile","buf","isGzip","unzip","parseLineByLine","hasDataForRefName","getAssemblyNames","assemblyNames","getRefNames","r1","regions","assemblyName","feats","idx","set","Set","feat","add","console","warn","getFeatures","query","ObservableCreate","async","pafRecords","config","readConfObject","ret","scoreMap","entry","key","quals","len","meanScoreMap","entries","val","zip","meanScore","min","max","Math","b","getWeightedMeans","index","start","end","refName","qref","observer","complete","mateName","mateStart","mateEnd","flip","doesIntersect2","cg","rest","CIGAR","join","replaceAll","next","uniqueId","type","syntenyId","identity","mate","freeResources","parseBed","text","Map","filter","f","startsWith","name","score","file","TextDecoder","fatal","decode","a","decoder","cb","blockStart","n","toString","trim","inputData","strm","pos","chunks","inflator","totalSize","remainingInput","subarray","Inflate","Z_SYNC_FLUSH","err","Error","msg","next_in","result","avail_in","Uint8Array","offset","Buffer","from","match","unzipChunkSlice","chunk","minv","maxv","cpos","blockPosition","dpos","dataPosition","cpositions","dpositions","origCpos","GziIndex","constructor","filehandle","path","TypeError","_readLongWithOverflow","unsigned","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","_getIndex","_readIndex","allocUnsafe","read","numEntries","Array","bufSize","entryNumber","compressedPosition","uncompressedPosition","getLastBlock","getRelevantBlocksForRead","position","endPosition","relevant","compare","nextEntry","nextUncompressedPosition","Infinity","lowerBound","upperBound","searchPosition","floor","comparison","ceil","BgzFilehandle","gziFilehandle","gziPath","gzi","stat","compressedStat","assign","size","getUncompressedFileSize","blocks","blksize","bytesRead","readUInt32LE","_readAndUncompressBlock","blockBuffer","nextCompressedPosition","blockCompressedLength","blockPositions","destinationOffset","blockNum","uncompressedBuffer","sourceOffset","sourceEnd","copy"],"sourceRoot":""}