{"version":3,"file":"static/js/524.5ea39db6.chunk.js","mappings":"2PAIA,MAAMA,EAAe,UAErB,SAASC,EAAYC,EAAaC,GAChC,MAAMC,EAASF,EAAOG,UAAUF,GAC1BG,EAAe,SAASH,IAC9BD,EAAOG,UAAUF,GAAc,WAI7B,OAHMG,KAAgBC,OACpBA,KAAKD,GAAgBF,EAAOI,KAAKD,OAE5BA,KAAKD,EACd,CACF,CAEA,MAAMG,EAAS,CAAC,IAAK,IAAK,IAAK,KAGzBC,EAAe,GACrB,IAAK,IAAIC,EAAI,EAAGA,EAAI,IAAKA,IACvBD,EAAaE,KACXH,EAAQE,GAAK,EAAK,GAChBF,EAAQE,GAAK,EAAK,GAClBF,EAAQE,GAAK,EAAK,GAClBF,EAAW,EAAJE,IAKb,MAAME,EAAqBH,EAAaI,KAAIC,GAASA,EAAMC,gBAE5C,MAAMC,EAWnB,WAAAC,EAAY,WACVC,EAAU,KACVC,IAKA,GAAID,EACFZ,KAAKY,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIC,MAAM,kCAFhBd,KAAKY,WAAa,IAAI,KAAUC,E,CAIlCb,KAAKe,iBAAcC,CACrB,CAEA,gBAAMC,CAAWC,GACf,MAAMC,SAAgBnB,KAAKoB,eAAeF,GAC1C,IAAKC,EACH,MAAM,IAAIL,MAAM,UAAUI,eAE5B,OAAOC,CACT,CAEA,uBAAME,GACJ,MAAMC,QAAYtB,KAAKY,WAAWW,KAAKC,EAAOC,YAAY,GAAI,EAAG,EAAG,IAC9D,OAAEC,GAAWJ,EACnB,GAAII,EAAOC,YAAY,KAAOlC,EAC5BO,KAAKe,aAAc,EACnBf,KAAK4B,QAAUF,EAAOC,YAAY,OAC7B,IAAID,EAAOG,YAAY,KAAOpC,EAInC,MAAM,IAAIqB,MAAM,mBAHhBd,KAAKe,aAAc,EACnBf,KAAK4B,QAAUF,EAAOG,YAAY,E,CAItC,CAOA,iBAAMT,SACEpB,KAAKqB,oBAEX,MAAMS,EAAY9B,KAAKe,YAAc,MAAQ,SACvCgB,EAAO/B,KAAKe,YAAc,KAAO,KAEvC,IAAIiB,GAAmB,IAAI,KACxBF,UAAUA,GACVG,MAAM,cACNC,OAAO,OAAQ,CAAEC,OAAQ,eAwB5B,OAtBEH,EADmB,IAAjBhC,KAAK4B,QACYI,EAAiBN,OAAO,cAAe,CACxDS,OAAQ,IAGSH,EAAiBI,OAAO,UAkBtC,CACLC,QAhBa,IAAI,KAChBP,UAAUA,GACVQ,MAAM,QAAS,CACdC,OAASC,GAAoB,YAANA,IAExBF,MAAM,UAAW,CAEhBC,OAASE,GAAoB,IAANA,GAAiB,IAANA,IAEnCL,OAAO,gBAAiB,CAEvBG,OAASE,GAAcA,GAAK,IAE7BL,OAAO,YAIRM,OAAO,IAAI,KACRZ,UAAUA,GACVM,OAAO,iBACPA,OAAO,YACPO,MAAM,QAAS,CACdR,OAAQ,gBACRS,KAAMZ,IAEVa,SAAS,IAAI,KACVf,UAAUA,GACVM,OAAO,WACPA,OAAO,eACVU,SAAS,IAAI,KACVhB,UAAUA,GACVM,OAAO,eACPO,MAAM,eAAgB,CACrBR,OAAQ,cACRS,KAAM,SAASb,MAEhBY,MAAM,cAAe,CACpBR,OAAQ,cACRS,KAAM,SAASb,MAEhBK,OAAO,kBACVW,SAAS,IAAI,KACVjB,UAAUA,GACVM,OAAO,kBACPO,MAAM,kBAAmB,CACxBR,OAAQ,iBACRS,KAAM,SAASb,MAEhBY,MAAM,iBAAkB,CACvBR,OAAQ,iBACRS,KAAM,SAASb,MAEhBO,MAAM,YAGb,CAOA,eAAMU,SACEhD,KAAKqB,oBAEX,MAAM,OAAEK,SAAiB1B,KAAKY,WAAWW,KACvCC,EAAOC,YAAY,IACnB,EACA,GACA,GAGF,aAD2BzB,KAAKiB,WAAW,WACvBgC,MAAMvB,GAAQwB,MACpC,CAMA,cAAMC,GACJ,MACMC,EACJ,SAFmBpD,KAAKgD,aAEbK,eAAiB,KAA4B,IAAjBrD,KAAK4B,QAAgB,EAAI,KAC5D,OAAEF,SAAiB1B,KAAKY,WAAWW,KACvCC,EAAOC,YAAY2B,GACnB,EACAA,EACA,GAGIE,SADoBtD,KAAKiB,WAAW,UACZgC,MAAMvB,GAAQwB,OAAOR,MAC7CA,EAAQ,CAAC,EAoBf,OAnBqB,IAAjB1C,KAAK4B,QACP0B,EAAUC,SACR,EAAGrC,OAAMsC,kBACP,MAAMC,EAAO,cAAeD,GAAa,GAAOxD,KAAKe,aACrD,GAAI0C,EAAKC,YAAYC,OAAOC,kBAC1B,MAAM,IAAI9C,MACR,qHAGJ4B,EAAMxB,GAAQuC,EAAKI,UAAU,IAIjCP,EAAUC,SACR,EAAGrC,OAAM4C,aACPpB,EAAMxB,GAAQ4C,CAAM,IAInBpB,CACT,CAKA,sBAAMqB,GACJ,MAAMrB,QAAc1C,KAAKmD,WACzB,OAAOa,OAAOC,KAAKvB,EACrB,CAKA,sBAAMwB,GACJ,MAAMxB,QAAc1C,KAAKmD,WACnBgB,EAAWH,OAAOC,KAAKvB,GACvB0B,EAAeJ,OAAOK,OAAO3B,GAAOnC,KAAIuD,GAC5C9D,KAAKsE,iBAAiBR,KAElBS,QAAcC,QAAQC,IAAIL,GAC1BM,EAAe,CAAC,EACtB,IAAK,IAAItE,EAAI,EAAGA,EAAI+D,EAAShC,OAAQ/B,GAAK,EACxCsE,EAAaP,EAAS/D,IAAMmE,EAAMnE,GAEpC,OAAOsE,CACT,CAMA,qBAAMC,CAAgBC,GACpB,MACMd,SADc9D,KAAKmD,YACJyB,GACrB,GAAKd,EAGL,OAAO9D,KAAKsE,iBAAiBR,EAC/B,CAEA,sBAAMQ,CAAiBR,GAErB,QAAe9C,IAAX8C,GAAwBA,EAAS,EACnC,MAAM,IAAIhD,MAAM,kBAGlB,aADmBd,KAAK6E,WAAWf,EAAQ,EAAG,YAClCgB,OACd,CAEA,wBAAMC,CAAmBjB,GAEvB,QAAe9C,IAAX8C,GAAwBA,EAAS,EACnC,MAAM,IAAIhD,MAAM,kBAElB,MAAMkE,QAAahF,KAAK6E,WAAWf,EAAQ,EAAG,WACxCmB,EAAoC,EAAnBD,EAAKE,YAAkB,EACxCC,QAAanF,KAAK6E,WAAWf,EAAS,EAAGmB,EAAgB,WACzDG,EAAuC,EAAtBD,EAAKE,eAAqB,EAC3CC,QAAatF,KAAK6E,WACtBf,EAAS,EAAImB,EAAiB,EAC9BG,EACA,WASF,MANY,CACVN,QAASE,EAAKF,QACdS,QAAS,CAAEC,OAAQL,EAAKM,aAAclB,MAAOY,EAAKO,aAClDC,WAAY,CAAEH,OAAQF,EAAKM,gBAAiBrB,MAAOe,EAAKO,gBACxDC,YAAahC,EAAS,EAAImB,EAAiB,EAAIG,EAGnD,CAEA,gBAAMP,CAAWf,EAAgB3B,EAAgB4D,GAC/C,MAAM,OAAErE,SAAiB1B,KAAKY,WAAWW,KACvCC,EAAOC,YAAYU,GACnB,EACAA,EACA2B,GAGF,aADqB9D,KAAKiB,WAAW8E,IACvB9C,MAAMvB,GAAQwB,MAC9B,CAQA,iBAAM8C,CAAYpB,EAAiBqB,EAAc,EAAGC,GAClD,MACMpC,SADc9D,KAAKmD,YACJyB,GACrB,IAAKd,EACH,OAGF,MAAMqC,QAAenG,KAAK+E,mBAAmBjB,GAE7C,GAAImC,EAAc,EAChB,MAAM,IAAIG,UAAU,2CAGJpF,IAAdkF,GAA2BA,EAAYC,EAAOrB,WAChDoB,EAAYC,EAAOrB,SAGrB,MAAMS,EAAUvF,KAAKqG,sBACnBJ,EACAC,EACAC,EAAOZ,QAAQC,OACfW,EAAOZ,QAAQhB,OAEXoB,EAAa3F,KAAKqG,sBACtBJ,EACAC,EACAC,EAAOR,WAAWH,OAClBW,EAAOR,WAAWpB,OAGd+B,EAAY9E,EAAOC,YACvB8E,KAAKC,MAAMN,EAAYD,GAAe,GAAK,GAEvCQ,EAAkBF,KAAKG,MAAMT,EAAc,IAC3C,OAAEvE,SAAiB1B,KAAKY,WAAWW,KACvC+E,EACA,EACAA,EAAUnE,OACVgE,EAAOL,YAAcW,GAGvB,IAAIE,EAAgB,GACpB,IACE,IAAIC,EAAkBX,EACtBW,EAAkBV,EAClBU,GAAmB,EACnB,CAEA,KAAOjB,EAAWxD,QAAUwD,EAAW,GAAGkB,KAAOD,GAC/CjB,EAAWmB,QAEb,MAAMC,EACJpB,EAAW,IACXA,EAAW,GAAGqB,OAASJ,GACvBjB,EAAW,GAAGkB,IAAMD,EAGtB,GACErB,EAAQ,IACRqB,GAAmBrB,EAAQ,GAAGyB,OAC9BJ,EAAkBrB,EAAQ,GAAGsB,IAC7B,CACA,MAAMI,EAAgB1B,EAAQuB,QAC9B,KAEEF,EAAkBK,EAAcJ,KAAOD,EAAkBV,EACzDU,GAAmB,EAEnBD,GAAiBI,EAAe,IAAM,IAExCH,GAAmB,C,KACd,CACL,MACMM,EAAcN,EAAkB,EAChCO,EAAOzF,EAFQ6E,KAAKG,MAAME,EAAkB,GAAKH,GAGvDE,GAAiBI,EACbzG,EAAmB6G,GAAMD,GACzB/G,EAAagH,GAAMD,E,EAI3B,OAAOP,CACT,CAEA,qBAAAN,CACEJ,EACAC,EACAkB,EACAC,GAGA,IAAIC,EACAC,EACJ,IAAK,IAAInH,EAAI,EAAGA,EAAIgH,EAAYjF,OAAQ/B,GAAK,EAAG,CAC9C,MAAMoH,EAAaJ,EAAYhH,GAE/B,GAAI6F,GAAeuB,EADDH,EAAWjH,IACgB8F,GAAasB,GAExD,QAAmBxG,IAAfsG,EAA0B,CAC5BC,EAAWnH,EACX,K,YAEsBY,IAAfsG,IACTA,EAAalH,E,CAIjB,QAAmBY,IAAfsG,EACF,MAAO,QAIQtG,IAAbuG,IACFA,EAAWH,EAAYjF,QAGzB,MAAMsF,EAAS,IAAIC,MAAMH,EAAWD,GACpC,IAAK,IAAIK,EAAWL,EAAYK,EAAWJ,EAAUI,GAAY,EAC/DF,EAAOE,EAAWL,GAAc,CAC9BN,MAAOI,EAAYO,GACnBd,IAAKO,EAAYO,GAAYN,EAAWM,GACxCC,KAAMP,EAAWM,IAGrB,OAAOF,CACT,EAGF/H,EAAYgB,EAAY,eACxBhB,EAAYgB,EAAY,YACxBhB,EAAYgB,EAAY,a,eC3aT,MAAMmH,UAAsBC,EAAAA,oBAOzC,oBAAcC,GACZ,MAAMC,GAAOC,EAAAA,EAAAA,gBAAejI,KAAKkI,OAAQ,sBAIzC,GAAiB,iCAAbF,EAAKG,KAAuD,KAAbH,EAAKG,IAAY,CAClE,MAAMC,GAAOC,EAAAA,EAAAA,cAAaL,EAAMhI,KAAKsI,eAC/BC,QAAaH,EAAKI,SAAS,QACjC,OAAOxE,OAAOyE,YACZF,GACIG,MAAM,cACPC,QAAOC,KAAUA,EAAKC,SACtBtI,KAAIqI,IACH,MAAO1H,EAAMiB,GAAUyG,EAAKF,MAAM,MAClC,MAAO,CAACxH,GAAOiB,EAAO,IAG9B,CAEF,CAEAxB,WAAAA,CACEuH,EACAY,EACAR,GAEAS,MAAMb,EAAQY,EAAeR,GAC7B,MAAMU,EAAKhJ,KAAKsI,cAChBtI,KAAKiJ,eAAiBjJ,KAAK+H,iBAC3B/H,KAAKkJ,OAAS,IAAIxI,EAAW,CAC3BE,YAAYyH,EAAAA,EAAAA,cAAarI,KAAKmJ,QAAQ,kBAAmBH,IAE7D,CAEA,iBAAaI,GACX,MAAMH,QAAuBjJ,KAAKiJ,eAClC,OAAIA,EACKjF,OAAOC,KAAKgF,GAEdjJ,KAAKkJ,OAAOnF,kBACrB,CAEA,gBAAasF,GACX,MAAMJ,QAAuBjJ,KAAKiJ,eAClC,GAAIA,EACF,OAAOjF,OAAOC,KAAKgF,GAAgB1I,KAAI+I,IAAW,CAChDA,UACAtC,MAAO,EACPH,IAAKoC,EAAeK,OAGxB,MAAMC,QAAiBvJ,KAAKkJ,OAAOhF,mBACnC,OAAOF,OAAOC,KAAKsF,GAAUhJ,KAAI+I,IAAW,CAC1CA,UACAtC,MAAO,EACPH,IAAK0C,EAASD,MAElB,CAOOE,WAAAA,EAAY,QAAEF,EAAO,MAAEtC,EAAK,IAAEH,IACnC,OAAO4C,EAAAA,EAAAA,mBAA0BC,UAC/B,MAAM9B,QAAa5H,KAAKkJ,OAAOvE,gBAAgB2E,GACzCpD,OAAqBlF,IAAT4G,EAAqBrB,KAAKoD,IAAI/B,EAAMf,GAAOA,EACvD+C,QAAY5J,KAAKkJ,OAAOlD,YAAYsD,EAAStC,EAAOd,GACtD0D,GACFC,EAASC,KACP,IAAIC,EAAAA,EAAc,CAChBC,GAAK,GAAEV,KAAWtC,KAASd,IAC3BqC,KAAM,CAAEe,UAAStC,QAAOH,IAAKX,EAAW0D,UAI9CC,EAASI,UAAU,GAEvB,CAOOC,aAAAA,GAAuC,E","sources":["../../../node_modules/@gmod/twobit/src/twoBitFile.ts","../../../plugins/sequence/src/TwoBitAdapter/TwoBitAdapter.ts"],"sourcesContent":["import Long from 'long'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\nimport { Parser } from '@gmod/binary-parser'\n\nconst TWOBIT_MAGIC = 0x1a412743\n\nfunction tinyMemoize(_class: any, methodName: string) {\n  const method = _class.prototype[methodName]\n  const memoAttrName = `_memo_${methodName}`\n  _class.prototype[methodName] = function _tinyMemoized() {\n    if (!(memoAttrName in this)) {\n      this[memoAttrName] = method.call(this)\n    }\n    return this[memoAttrName]\n  }\n}\n\nconst twoBit = ['T', 'C', 'A', 'G']\n// byteTo4Bases is an array of byteValue -> 'ACTG'\n// the weird `...keys()` incantation generates an array of numbers 0 to 255\nconst byteTo4Bases = [] as string[]\nfor (let i = 0; i < 256; i++) {\n  byteTo4Bases.push(\n    twoBit[(i >> 6) & 3] +\n      twoBit[(i >> 4) & 3] +\n      twoBit[(i >> 2) & 3] +\n      twoBit[i & 3],\n  )\n}\n\ntype ParserName = 'header' | 'index' | 'record1' | 'record2' | 'record3'\nconst maskedByteTo4Bases = byteTo4Bases.map(bases => bases.toLowerCase())\n\nexport default class TwoBitFile {\n  private filehandle: GenericFilehandle\n  private isBigEndian?: boolean\n  private version?: number\n\n  /**\n   * @param {object} args\n   * @param {string} [args.path] filesystem path for the .2bit file to open\n   * @param {Filehandle} [args.filehandle] node fs.promises-like filehandle for the .2bit file.\n   *  Only needs to support `filehandle.read(buffer, offset, length, position)`\n   */\n  constructor({\n    filehandle,\n    path,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new Error('must supply path or filehandle')\n    }\n    this.isBigEndian = undefined\n  }\n\n  async _getParser(name: ParserName) {\n    const parser = (await this._getParsers())[name]\n    if (!parser) {\n      throw new Error(`parser ${name} not found`)\n    }\n    return parser\n  }\n\n  async _detectEndianness() {\n    const ret = await this.filehandle.read(Buffer.allocUnsafe(8), 0, 8, 0)\n    const { buffer } = ret\n    if (buffer.readInt32LE(0) === TWOBIT_MAGIC) {\n      this.isBigEndian = false\n      this.version = buffer.readInt32LE(4)\n    } else if (buffer.readInt32BE(0) === TWOBIT_MAGIC) {\n      this.isBigEndian = true\n      this.version = buffer.readInt32BE(4)\n    } else {\n      throw new Error('not a 2bit file')\n    }\n  }\n\n  // memoize\n  /**\n   * @private\n   * detects the file's endianness and instantiates our binary parsers accordingly\n   */\n  async _getParsers() {\n    await this._detectEndianness()\n\n    const endianess = this.isBigEndian ? 'big' : 'little'\n    const lebe = this.isBigEndian ? 'be' : 'le'\n\n    let indexEntryParser = new Parser()\n      .endianess(endianess)\n      .uint8('nameLength')\n      .string('name', { length: 'nameLength' })\n    if (this.version === 1) {\n      indexEntryParser = indexEntryParser.buffer('offsetBytes', {\n        length: 8,\n      })\n    } else {\n      indexEntryParser = indexEntryParser.uint32('offset')\n    }\n    /* istanbul ignore next */\n    const header = new Parser()\n      .endianess(endianess)\n      .int32('magic', {\n        assert: (m: number) => m === 0x1a412743,\n      })\n      .int32('version', {\n        /* istanbul ignore next */\n        assert: (v: number) => v === 0 || v === 1,\n      })\n      .uint32('sequenceCount', {\n        /* istanbul ignore next */\n        assert: (v: number) => v >= 0,\n      })\n      .uint32('reserved')\n\n    return {\n      header,\n      index: new Parser()\n        .endianess(endianess)\n        .uint32('sequenceCount')\n        .uint32('reserved')\n        .array('index', {\n          length: 'sequenceCount',\n          type: indexEntryParser,\n        }),\n      record1: new Parser()\n        .endianess(endianess)\n        .uint32('dnaSize')\n        .uint32('nBlockCount'),\n      record2: new Parser()\n        .endianess(endianess)\n        .uint32('nBlockCount')\n        .array('nBlockStarts', {\n          length: 'nBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .array('nBlockSizes', {\n          length: 'nBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .uint32('maskBlockCount'),\n      record3: new Parser()\n        .endianess(endianess)\n        .uint32('maskBlockCount')\n        .array('maskBlockStarts', {\n          length: 'maskBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .array('maskBlockSizes', {\n          length: 'maskBlockCount',\n          type: `uint32${lebe}`,\n        })\n        .int32('reserved'),\n      // .buffer('packedDna', { length: 'dnaSize' }),\n    }\n  }\n\n  // memoize\n  /**\n   * @returns {Promise} for object with the file's header information, like\n   *  `{ magic: 0x1a412743, version: 0, sequenceCount: 42, reserved: 0 }`\n   */\n  async getHeader() {\n    await this._detectEndianness()\n\n    const { buffer } = await this.filehandle.read(\n      Buffer.allocUnsafe(16),\n      0,\n      16,\n      0,\n    )\n    const headerParser = await this._getParser('header')\n    return headerParser.parse(buffer).result\n  }\n\n  // memoize\n  /**\n   * @returns {Promise} for object with the file's index of offsets, like `{ seqName: fileOffset, ...}`\n   */\n  async getIndex() {\n    const header = await this.getHeader()\n    const maxIndexLength =\n      8 + header.sequenceCount * (1 + 256 + (this.version === 1 ? 8 : 4))\n    const { buffer } = await this.filehandle.read(\n      Buffer.allocUnsafe(maxIndexLength),\n      0,\n      maxIndexLength,\n      8,\n    )\n    const indexParser = await this._getParser('index')\n    const indexData = indexParser.parse(buffer).result.index\n    const index = {} as { [key: string]: number }\n    if (this.version === 1) {\n      indexData.forEach(\n        ({ name, offsetBytes }: { name: string; offsetBytes: number }) => {\n          const long = Long.fromBytes(offsetBytes, true, !this.isBigEndian)\n          if (long.greaterThan(Number.MAX_SAFE_INTEGER)) {\n            throw new Error(\n              'integer overflow. File offset greater than 2^53-1 encountered. This library can only handle offsets up to 2^53-1.',\n            )\n          }\n          index[name] = long.toNumber()\n        },\n      )\n    } else {\n      indexData.forEach(\n        ({ name, offset }: { name: string; offset: number }) => {\n          index[name] = offset\n        },\n      )\n    }\n    return index\n  }\n\n  /**\n   * @returns {Promise} for an array of string sequence names that are found in the file\n   */\n  async getSequenceNames() {\n    const index = await this.getIndex()\n    return Object.keys(index)\n  }\n\n  /**\n   * @returns {Promise} for an object listing the lengths of all sequences like `{seqName: length, ...}`\n   */\n  async getSequenceSizes() {\n    const index = await this.getIndex()\n    const seqNames = Object.keys(index)\n    const sizePromises = Object.values(index).map(offset =>\n      this._getSequenceSize(offset as number),\n    )\n    const sizes = await Promise.all(sizePromises)\n    const returnObject = {} as { [key: string]: number }\n    for (let i = 0; i < seqNames.length; i += 1) {\n      returnObject[seqNames[i]] = sizes[i]\n    }\n    return returnObject\n  }\n\n  /**\n   * @param {string} seqName name of the sequence\n   * @returns {Promise} for the sequence's length, or undefined if it is not in the file\n   */\n  async getSequenceSize(seqName: string) {\n    const index = await this.getIndex()\n    const offset = index[seqName]\n    if (!offset) {\n      return undefined\n    }\n    return this._getSequenceSize(offset)\n  }\n\n  async _getSequenceSize(offset: number) {\n    // we have to parse the sequence record in 3 parts, because we have to buffer 3 fixed-length file reads\n    if (offset === undefined || offset < 0) {\n      throw new Error('invalid offset')\n    }\n    const rec1 = await this._parseItem(offset, 8, 'record1')\n    return rec1.dnaSize\n  }\n\n  async _getSequenceRecord(offset: number) {\n    // we have to parse the sequence record in 3 parts, because we have to buffer 3 fixed-length file reads\n    if (offset === undefined || offset < 0) {\n      throw new Error('invalid offset')\n    }\n    const rec1 = await this._parseItem(offset, 8, 'record1')\n    const rec2DataLength = rec1.nBlockCount * 8 + 8\n    const rec2 = await this._parseItem(offset + 4, rec2DataLength, 'record2')\n    const rec3DataLength = rec2.maskBlockCount * 8 + 8\n    const rec3 = await this._parseItem(\n      offset + 4 + rec2DataLength - 4,\n      rec3DataLength,\n      'record3',\n    )\n\n    const rec = {\n      dnaSize: rec1.dnaSize,\n      nBlocks: { starts: rec2.nBlockStarts, sizes: rec2.nBlockSizes },\n      maskBlocks: { starts: rec3.maskBlockStarts, sizes: rec3.maskBlockSizes },\n      dnaPosition: offset + 4 + rec2DataLength - 4 + rec3DataLength,\n    }\n    return rec\n  }\n\n  async _parseItem(offset: number, length: number, parserName: ParserName) {\n    const { buffer } = await this.filehandle.read(\n      Buffer.allocUnsafe(length),\n      0,\n      length,\n      offset,\n    )\n    const parser = await this._getParser(parserName)\n    return parser.parse(buffer).result\n  }\n\n  /**\n   * @param {string} seqName name of the sequence you want\n   * @param {number} [regionStart] optional 0-based half-open start of the sequence region to fetch.\n   * @param {number} [regionEnd] optional 0-based half-open end of the sequence region to fetch. defaults to end of the sequence\n   * @returns {Promise} for a string of sequence bases\n   */\n  async getSequence(seqName: string, regionStart = 0, regionEnd: number) {\n    const index = await this.getIndex()\n    const offset = index[seqName]\n    if (!offset) {\n      return undefined\n    }\n    // fetch the record for the seq\n    const record = await this._getSequenceRecord(offset)\n\n    if (regionStart < 0) {\n      throw new TypeError('regionStart cannot be less than 0')\n    }\n    // end defaults to the end of the sequence\n    if (regionEnd === undefined || regionEnd > record.dnaSize) {\n      regionEnd = record.dnaSize\n    }\n\n    const nBlocks = this._getOverlappingBlocks(\n      regionStart,\n      regionEnd,\n      record.nBlocks.starts,\n      record.nBlocks.sizes,\n    )\n    const maskBlocks = this._getOverlappingBlocks(\n      regionStart,\n      regionEnd,\n      record.maskBlocks.starts,\n      record.maskBlocks.sizes,\n    )\n\n    const baseBytes = Buffer.allocUnsafe(\n      Math.ceil((regionEnd - regionStart) / 4) + 1,\n    )\n    const baseBytesOffset = Math.floor(regionStart / 4)\n    const { buffer } = await this.filehandle.read(\n      baseBytes,\n      0,\n      baseBytes.length,\n      record.dnaPosition + baseBytesOffset,\n    )\n\n    let sequenceBases = ''\n    for (\n      let genomicPosition = regionStart;\n      genomicPosition < regionEnd;\n      genomicPosition += 1\n    ) {\n      // check whether we are currently masked\n      while (maskBlocks.length && maskBlocks[0].end <= genomicPosition) {\n        maskBlocks.shift()\n      }\n      const baseIsMasked =\n        maskBlocks[0] &&\n        maskBlocks[0].start <= genomicPosition &&\n        maskBlocks[0].end > genomicPosition\n\n      // process the N block if we have one\n      if (\n        nBlocks[0] &&\n        genomicPosition >= nBlocks[0].start &&\n        genomicPosition < nBlocks[0].end\n      ) {\n        const currentNBlock = nBlocks.shift()\n        for (\n          ;\n          genomicPosition < currentNBlock.end && genomicPosition < regionEnd;\n          genomicPosition += 1\n        ) {\n          sequenceBases += baseIsMasked ? 'n' : 'N'\n        }\n        genomicPosition -= 1\n      } else {\n        const bytePosition = Math.floor(genomicPosition / 4) - baseBytesOffset\n        const subPosition = genomicPosition % 4\n        const byte = buffer[bytePosition]\n        sequenceBases += baseIsMasked\n          ? maskedByteTo4Bases[byte][subPosition]\n          : byteTo4Bases[byte][subPosition]\n      }\n    }\n\n    return sequenceBases\n  }\n\n  _getOverlappingBlocks(\n    regionStart: number,\n    regionEnd: number,\n    blockStarts: number[],\n    blockSizes: number[],\n  ) {\n    // find the start and end indexes of the blocks that match\n    let startIndex\n    let endIndex\n    for (let i = 0; i < blockStarts.length; i += 1) {\n      const blockStart = blockStarts[i]\n      const blockSize = blockSizes[i]\n      if (regionStart >= blockStart + blockSize || regionEnd <= blockStart) {\n        // block does not overlap the region\n        if (startIndex !== undefined) {\n          endIndex = i\n          break\n        }\n      } else if (startIndex === undefined) {\n        startIndex = i\n      } // block does overlap the region, record this if it is the first\n    }\n\n    if (startIndex === undefined) {\n      return []\n    }\n\n    // now format some block objects to return\n    if (endIndex === undefined) {\n      endIndex = blockStarts.length\n    }\n\n    const blocks = new Array(endIndex - startIndex)\n    for (let blockNum = startIndex; blockNum < endIndex; blockNum += 1) {\n      blocks[blockNum - startIndex] = {\n        start: blockStarts[blockNum],\n        end: blockStarts[blockNum] + blockSizes[blockNum],\n        size: blockSizes[blockNum],\n      }\n    }\n    return blocks\n  }\n}\n\ntinyMemoize(TwoBitFile, '_getParsers')\ntinyMemoize(TwoBitFile, 'getIndex')\ntinyMemoize(TwoBitFile, 'getHeader')\n","import { BaseSequenceAdapter } from '@jbrowse/core/data_adapters/BaseAdapter'\nimport { NoAssemblyRegion } from '@jbrowse/core/util/types'\nimport { openLocation } from '@jbrowse/core/util/io'\nimport { ObservableCreate } from '@jbrowse/core/util/rxjs'\nimport SimpleFeature, { Feature } from '@jbrowse/core/util/simpleFeature'\nimport { TwoBitFile } from '@gmod/twobit'\nimport { readConfObject } from '@jbrowse/core/configuration'\nimport { AnyConfigurationModel } from '@jbrowse/core/configuration'\nimport PluginManager from '@jbrowse/core/PluginManager'\nimport { getSubAdapterType } from '@jbrowse/core/data_adapters/dataAdapterCache'\n\nexport default class TwoBitAdapter extends BaseSequenceAdapter {\n  private twobit: TwoBitFile\n\n  // the chromSizesData can be used to speed up loading since TwoBit has to do\n  // many range requests at startup to perform the getRegions request\n  protected chromSizesData: Promise<Record<string, number> | undefined>\n\n  private async initChromSizes() {\n    const conf = readConfObject(this.config, 'chromSizesLocation')\n    // check against default and empty in case someone makes the field blank in\n    // config editor, may want better way to check \"optional config slots\" in\n    // future\n    if (conf.uri !== '/path/to/default.chrom.sizes' && conf.uri !== '') {\n      const file = openLocation(conf, this.pluginManager)\n      const data = await file.readFile('utf8')\n      return Object.fromEntries(\n        data\n          ?.split(/\\n|\\r\\n|\\r/)\n          .filter(line => !!line.trim())\n          .map(line => {\n            const [name, length] = line.split('\\t')\n            return [name, +length]\n          }),\n      )\n    }\n    return undefined\n  }\n\n  constructor(\n    config: AnyConfigurationModel,\n    getSubAdapter?: getSubAdapterType,\n    pluginManager?: PluginManager,\n  ) {\n    super(config, getSubAdapter, pluginManager)\n    const pm = this.pluginManager\n    this.chromSizesData = this.initChromSizes()\n    this.twobit = new TwoBitFile({\n      filehandle: openLocation(this.getConf('twoBitLocation'), pm),\n    })\n  }\n\n  public async getRefNames() {\n    const chromSizesData = await this.chromSizesData\n    if (chromSizesData) {\n      return Object.keys(chromSizesData)\n    }\n    return this.twobit.getSequenceNames()\n  }\n\n  public async getRegions(): Promise<NoAssemblyRegion[]> {\n    const chromSizesData = await this.chromSizesData\n    if (chromSizesData) {\n      return Object.keys(chromSizesData).map(refName => ({\n        refName,\n        start: 0,\n        end: chromSizesData[refName],\n      }))\n    }\n    const refSizes = await this.twobit.getSequenceSizes()\n    return Object.keys(refSizes).map(refName => ({\n      refName,\n      start: 0,\n      end: refSizes[refName],\n    }))\n  }\n\n  /**\n   * Fetch features for a certain region\n   * @param param -\n   * @returns Observable of Feature objects in the region\n   */\n  public getFeatures({ refName, start, end }: NoAssemblyRegion) {\n    return ObservableCreate<Feature>(async observer => {\n      const size = await this.twobit.getSequenceSize(refName)\n      const regionEnd = size !== undefined ? Math.min(size, end) : end\n      const seq = await this.twobit.getSequence(refName, start, regionEnd)\n      if (seq) {\n        observer.next(\n          new SimpleFeature({\n            id: `${refName} ${start}-${regionEnd}`,\n            data: { refName, start, end: regionEnd, seq },\n          }),\n        )\n      }\n      observer.complete()\n    })\n  }\n\n  /**\n   * called to provide a hint that data tied to a certain region\n   * will not be needed for the foreseeable future and can be purged\n   * from caches, etc\n   */\n  public freeResources(/* { region } */): void {}\n}\n"],"names":["TWOBIT_MAGIC","tinyMemoize","_class","methodName","method","prototype","memoAttrName","this","call","twoBit","byteTo4Bases","i","push","maskedByteTo4Bases","map","bases","toLowerCase","TwoBitFile","constructor","filehandle","path","Error","isBigEndian","undefined","_getParser","name","parser","_getParsers","_detectEndianness","ret","read","Buffer","allocUnsafe","buffer","readInt32LE","version","readInt32BE","endianess","lebe","indexEntryParser","uint8","string","length","uint32","header","int32","assert","m","v","index","array","type","record1","record2","record3","getHeader","parse","result","getIndex","maxIndexLength","sequenceCount","indexData","forEach","offsetBytes","long","greaterThan","Number","MAX_SAFE_INTEGER","toNumber","offset","getSequenceNames","Object","keys","getSequenceSizes","seqNames","sizePromises","values","_getSequenceSize","sizes","Promise","all","returnObject","getSequenceSize","seqName","_parseItem","dnaSize","_getSequenceRecord","rec1","rec2DataLength","nBlockCount","rec2","rec3DataLength","maskBlockCount","rec3","nBlocks","starts","nBlockStarts","nBlockSizes","maskBlocks","maskBlockStarts","maskBlockSizes","dnaPosition","parserName","getSequence","regionStart","regionEnd","record","TypeError","_getOverlappingBlocks","baseBytes","Math","ceil","baseBytesOffset","floor","sequenceBases","genomicPosition","end","shift","baseIsMasked","start","currentNBlock","subPosition","byte","blockStarts","blockSizes","startIndex","endIndex","blockStart","blocks","Array","blockNum","size","TwoBitAdapter","BaseSequenceAdapter","initChromSizes","conf","readConfObject","config","uri","file","openLocation","pluginManager","data","readFile","fromEntries","split","filter","line","trim","getSubAdapter","super","pm","chromSizesData","twobit","getConf","getRefNames","getRegions","refName","refSizes","getFeatures","ObservableCreate","async","min","seq","observer","next","SimpleFeature","id","complete","freeResources"],"sourceRoot":""}