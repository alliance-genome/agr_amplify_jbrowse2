{"version":3,"file":"static/js/4133.8e3a4ecd.chunk.js","mappings":"yJAAe,MAAMA,EAGnB,WAAAC,CAAYC,EAAuBC,GACjCC,KAAKF,cAAgBA,EACrBE,KAAKD,aAAeA,CACtB,CAEA,QAAAE,GACE,MAAO,GAAGD,KAAKF,iBAAiBE,KAAKD,cACvC,CAEA,SAAAG,CAAUC,GACR,OACEH,KAAKF,cAAgBK,EAAEL,eAAiBE,KAAKD,aAAeI,EAAEJ,YAElE,CAEA,UAAOK,IAAOC,GACZ,IAAID,EACAE,EAAI,EACR,MAAQF,EAAKE,GAAK,EAChBF,EAAMC,EAAKC,GAEb,KAAOA,EAAID,EAAKE,OAAQD,GAAK,EACvBF,EAAIF,UAAUG,EAAKC,IAAM,IAC3BF,EAAMC,EAAKC,IAGf,OAAOF,CACT,EAEK,SAASI,EAAUC,EAAeC,EAAS,EAAGC,GAAY,GAC/D,GAAIA,EACF,MAAM,IAAIC,MAAM,mDAGlB,OAAO,IAAIhB,EACW,cAApBa,EAAMC,EAAS,GACO,WAApBD,EAAMC,EAAS,GACK,SAApBD,EAAMC,EAAS,GACK,MAApBD,EAAMC,EAAS,GACK,IAApBD,EAAMC,EAAS,GACfD,EAAMC,EAAS,GAChBD,EAAMC,EAAS,IAAM,EAAKD,EAAMC,GAErC,CC3Ce,MAAMG,EAGnB,WAAAhB,CACSiB,EACAC,EACAC,EACAC,GAHA,KAAAH,KAAAA,EACA,KAAAC,KAAAA,EACA,KAAAC,IAAAA,EACA,KAAAC,aAAAA,CACN,CAEH,cAAAC,GACE,MAAO,GAAGlB,KAAKc,SAASd,KAAKe,aAC3Bf,KAAKgB,oBACUhB,KAAKmB,gBACxB,CAEA,QAAAlB,GACE,OAAOD,KAAKkB,gBACd,CAEA,SAAAhB,CAAUC,GACR,OACEH,KAAKc,KAAKZ,UAAUC,EAAEW,OACtBd,KAAKe,KAAKb,UAAUC,EAAEY,OACtBf,KAAKgB,IAAMb,EAAEa,GAEjB,CAEA,WAAAG,GACE,YAA0BC,IAAtBpB,KAAKiB,aACAjB,KAAKiB,aAEPjB,KAAKe,KAAKjB,cAAgB,MAAYE,KAAKc,KAAKhB,aACzD,E,wBChCK,SAASuB,EAAQC,GACtB,OAAO,IAAIC,SAAQC,GAAWC,WAAWD,EAASF,IACpD,CA0EO,SAASI,EAAeC,EAAiBC,GAC9C,MAAMC,EAAwB,GAC9B,IAAIC,EAEJ,GAAsB,IAAlBH,EAAOpB,OACT,OAAOoB,EAGTA,EAAOI,MAAK,CAACC,EAAIC,KACf,MAAMC,EAAMF,EAAGlB,KAAKhB,cAAgBmC,EAAGnB,KAAKhB,cAC5C,OAAe,IAARoC,EAAYF,EAAGlB,KAAKf,aAAekC,EAAGnB,KAAKf,aAAemC,CAAG,IAGtE,IAAK,MAAMC,KAASR,IACbC,GAAUO,EAAMpB,KAAKb,UAAU0B,GAAU,UAC1BR,IAAdU,GACFD,EAAaO,KAAKD,GAClBL,EAAYK,IAvCWE,EAyCJP,GAzCmBQ,EAyCRH,GAvC3BrB,KAAKhB,cAAgBuC,EAAOtB,KAAKjB,cAAgB,MACxDwC,EAAOvB,KAAKjB,cAAgBuC,EAAOvB,KAAKhB,cAAgB,IAuC9CqC,EAAMpB,KAAKb,UAAU4B,EAAUf,MAAQ,IACzCe,EAAUf,KAAOoB,EAAMpB,OAGzBc,EAAaO,KAAKD,GAClBL,EAAYK,KA/Cf,IAAwBE,EAAeC,EAqD5C,OAAOT,CACT,CAEO,SAASU,EAAe9B,EAAeC,GAO5C,MAAO,CAAE8B,UAjHJ,SAAsBC,GAC3B,GACEA,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBAErB,MAAM,IAAIlC,MAAM,oBAElB,OAAO6B,EAAKM,UACd,CAmGoBC,CAChB,gBACEC,MAAMC,UAAUC,MAAMC,KAAK3C,EAAOC,EAAQA,EAAS,IACnD,IAIN,CAEO,SAAS2C,EACdC,EACAC,GAEA,OAAOD,EACHA,EAAcpD,UAAUqD,GAAiB,EACvCA,EACAD,EACFC,CACN,CAEO,SAASC,EACdC,EACAC,EAAwCC,IAAKA,IAE7C,IAAIC,EAAY,EACZC,EAAgB,EACpB,MAAMC,EAAc,GACdC,EAAyC,CAAC,EAChD,IAAK,IAAIzD,EAAI,EAAGA,EAAImD,EAAWlD,OAAQD,GAAK,EAC1C,IAAKmD,EAAWnD,GAAI,CAClB,GAAIuD,EAAgBvD,EAAG,CACrB,IAAI0D,EAAUP,EAAWxD,SAAS,OAAQ4D,EAAevD,GACzD0D,EAAUN,EAAaM,GACvBF,EAAYF,GAAaI,EACzBD,EAAYC,GAAWJ,C,CAEzBC,EAAgBvD,EAAI,EACpBsD,GAAa,C,CAGjB,MAAO,CAAEG,cAAaD,cACxB,CCxJe,MAAeG,EAQ5B,WAAApE,EAAY,WACVqE,EAAU,aACVR,EAAe,CAACS,GAAcA,KAK9BnE,KAAKkE,WAAaA,EAClBlE,KAAK0D,aAAeA,CACtB,ECMa,MAAMU,UAAYH,EAG/B,eAAMzB,CAAU6B,EAAeC,G,QAE7B,OAAsC,QAA/B,EAAwB,QAAxB,SADiBtE,KAAKuE,MAAMD,IAClBE,QAAQH,UAAM,eAAEI,aAAK,eAAEjC,YAAa,CACvD,CAGA,YAAMkC,CAAOJ,GACX,MAAM7D,QAAeT,KAAKkE,WAAWS,SAASL,GAG9C,GAlCc,WAkCV7D,EAAMmE,aAAa,GACrB,MAAM,IAAIhE,MAAM,kBAGlB,MAAMiE,EAAWpE,EAAMqE,YAAY,GAKnC,IACIxB,EADAyB,EAAO,EAKX,MAAMP,EAAU,IAAIvB,MAIjB4B,GACH,IAAK,IAAIvE,EAAI,EAAGA,EAAIuE,EAAUvE,IAAK,CAEjC,MAAM0E,EAAWvE,EAAMqE,YAAYC,GACnC,IAAIN,EAEJM,GAAQ,EACR,MAAME,EAAuC,CAAC,EAE9C,IAAK,IAAIC,EAAI,EAAGA,EAAIF,EAAUE,GAAK,EAAG,CACpC,MAAMlE,EAAMP,EAAMmE,aAAaG,GAE/B,GADAA,GAAQ,EACII,QAARnE,EACF+D,GAAQ,EACRN,EAAQlC,EAAe9B,EAAOsE,EAAO,IACrCA,GAAQ,OACH,IAAI/D,EAAMmE,MACf,MAAM,IAAIvE,MAAM,oDACX,CACL,MAAMwE,EAAa3E,EAAMqE,YAAYC,GACrCA,GAAQ,EACR,MAAMpD,EAAS,IAAIsB,MAAamC,GAChC,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,IAAK,CACnC,MAAMC,EAAI9E,EAAUC,EAAOsE,GAC3BA,GAAQ,EACR,MAAMQ,EAAI/E,EAAUC,EAAOsE,GAC3BA,GAAQ,EACRzB,EAAgBD,EAAcC,EAAegC,GAC7C3D,EAAO0D,GAAK,IAAIxE,EAAMyE,EAAGC,EAAGvE,E,CAE9BiE,EAASjE,GAAOW,C,GAIpB,MAAM6D,EAAc/E,EAAMqE,YAAYC,GACtCA,GAAQ,EAIR,MAAMU,EAAc,IAAIxC,MAAqBuC,GAC7C,IAAK,IAAIN,EAAI,EAAGA,EAAIM,EAAaN,IAAK,CACpC,MAAMxE,EAASF,EAAUC,EAAOsE,GAChCA,GAAQ,EACRzB,EAAgBD,EAAcC,EAAe5C,GAC7C+E,EAAYP,GAAKxE,C,CAGnB8D,EAAQlE,GAAK,CAAE2E,WAAUQ,cAAahB,Q,CAGxC,MAAO,CACLiB,KAAK,EACLpC,gBACAqC,aAAc,MACdnB,UACAK,WAEJ,CAEA,cAAMe,CACJC,EACAC,EACAC,EACAzB,EAAiB,CAAC,GAElB,MAAMiB,EAAI,MACJS,OAAkB5E,IAAV0E,EAERG,SADkBjG,KAAKuE,MAAMD,IACVE,QAAQqB,GACjC,IAAKI,EACH,MAAO,GAET,MAAM,YAAER,EAAc,GAAE,MAAEhB,GAAUwB,EACpC,GAA2B,IAAvBR,EAAYlF,OACd,MAAO,GAET,MAAM2F,OAAY9E,IAAR2E,GAAqBN,EAAYlF,OAAS,GAAKgF,GA3H5CpB,EA2HwD4B,GA1H3D5B,EA0HgEoB,QA3H9E,IAAiBpB,EA4Hb,MAAMR,OAAcvC,IAAV0E,EAAsB,EA/HpC,SAAmB3B,EAAWgC,GAC5B,OAAOhC,EAAKA,EA8H2CoB,KA7HzD,CA6HwCa,CAAUN,GACxCO,EACF,IAAIpD,MADO+C,GACAE,EAAIvC,GAAK4B,EACVE,EAAYlF,OAAS,GAC7B+F,EAAYb,EAAYA,EAAYlF,OAAS,GAAGT,cACtD,GAAIoG,GAAKT,EAAYlF,OAAS,GAAKgF,EACjC,MAAM,IAAI3E,MAAM,0CAElB,IAAI2F,EAAad,EAAY9B,EAAI4B,GAAGzF,cACpC,IAAK,IAAIQ,EAAIqD,EAAI4B,EAAGL,EAAI,EAAG5E,EAAI4F,EAAIX,EAAGjF,IAAK4E,IACzCmB,EAAOnB,GAAK,CACVsB,MAAOf,EAAYnF,EAAI,GAAGR,cAAgByG,EAC1CT,MAAOxF,EAAIiF,EACXQ,IAAKzF,EAAIiF,EAAIA,GAEfgB,EAAad,EAAYnF,EAAI,GAAGR,cAElC,OAAOuG,EAAOI,KAAIC,IAAK,IAClBA,EACHF,MAAQE,EAAEF,QAAS/B,aAAK,EAALA,EAAOjC,YAAa,GAAM8D,KAEjD,CAEA,oBAAMK,CACJtC,EACAjE,EACAwG,EACAtC,EAAiB,CAAC,GAEdlE,EAAM,IACRA,EAAM,GAGR,MAAMyG,QAAkB7G,KAAKuE,MAAMD,GACnC,IAAKuC,EACH,MAAO,GAET,MAAMC,EAAKD,EAAUrC,QAAQH,GAC7B,IAAKyC,EACH,MAAO,GAIT,MAAMC,GAnKqBhB,EAmKWa,EAjKjC,CACL,CAAC,EAAG,GACJ,CAAC,IAJaI,EAmKmB5G,IA/JpB,IAAK,IAHpB2F,GAAO,IAGyB,KAC9B,CAAC,GAAKiB,GAAO,IAAK,GAAKjB,GAAO,KAC9B,CAAC,IAAMiB,GAAO,IAAK,IAAMjB,GAAO,KAChC,CAAC,KAAOiB,GAAO,IAAK,KAAOjB,GAAO,KAClC,CAAC,MAAQiB,GAAO,IAAK,MAAQjB,GAAO,OARxC,IAAkBiB,EAAajB,EAoK3B,MAAMpE,EAAkB,GAGxB,IAAK,MAAOmE,EAAOC,KAAQgB,EACzB,IAAK,IAAI/F,EAAM8E,EAAO9E,GAAO+E,EAAK/E,IAChC,GAAI8F,EAAG7B,SAASjE,GAAM,CACpB,MAAMiG,EAAYH,EAAG7B,SAASjE,GAC9B,IAAK,MAAMkG,KAAYD,EACrBtF,EAAOS,KAAK8E,E,CAQpB,MAAMC,EAAQL,EAAGrB,YAAYlF,OAC7B,IAAIqB,EACJ,MAAMwF,EAASC,KAAKjH,IAAIA,GAAO,GAAI+G,EAAQ,GACrCG,EAASD,KAAKjH,IAAIwG,GAAO,GAAIO,EAAQ,GAC3C,IAAK,IAAI7G,EAAI8G,EAAQ9G,GAAKgH,IAAUhH,EAAG,CACrC,MAAMiH,EAAKT,EAAGrB,YAAYnF,GACtBiH,KAAQ3F,GAAU2F,EAAGrH,UAAU0B,GAAU,KAC3CA,EAAS2F,E,CAIb,OAAO7F,EAAeC,EAAQC,EAChC,CAEA,WAAM2C,CAAMD,EAAiB,CAAC,GAO5B,OANKtE,KAAKwH,SACRxH,KAAKwH,OAASxH,KAAK0E,OAAOJ,GAAMmD,OAAMvB,IAEpC,MADAlG,KAAKwH,YAASpG,EACR8E,CAAC,KAGJlG,KAAKwH,MACd,CAEA,eAAME,CAAU7B,EAAevB,EAAiB,CAAC,G,MAE/C,SAA8B,QAArB,SADYtE,KAAKuE,MAAMD,IAChBE,QAAQqB,UAAM,eAAEZ,SAClC,E,8FC3MF,SAAS0C,EAAOC,EAAaC,GAC3B,OAAOR,KAAKS,MAAMF,EAAM,GAAKC,EAC/B,CAEe,MAAME,UAAY9D,EAAjC,c,oBACU,KAAA+D,aAAe,EACf,KAAAC,MAAQ,EACR,KAAAC,SAAW,CA+MrB,CA3ME,eAAM1F,CAAU6B,EAAeC,G,QAE7B,OAAsC,QAA/B,EAAwB,QAAxB,SADiBtE,KAAKuE,MAAMD,IAClBE,QAAQH,UAAM,eAAEI,aAAK,eAAEjC,YAAa,CACvD,CAEA,cAAMoD,GACJ,MAAO,EACT,CAEA,YAAAuC,CAAa1H,EAAeC,GAC1B,MAAM0H,EAAc3H,EAAMqE,YAAYpE,GAChC2H,EACU,MAAdD,EAAwB,uBAAyB,iBAC7CE,EACJ,CAAE,EAAG,UAAW,EAAG,MAAO,EAAG,OAGf,GAAdF,GACF,IAAKE,EACH,MAAM,IAAI1H,MAAM,qCAAqCwH,KAEvD,MAAMG,EAAgB,CACpBC,IAAK/H,EAAMqE,YAAYpE,EAAS,GAChCoF,MAAOrF,EAAMqE,YAAYpE,EAAS,GAClCqF,IAAKtF,EAAMqE,YAAYpE,EAAS,KAE5B+H,EAAYhI,EAAMqE,YAAYpE,EAAS,IACvCgI,EAAWD,EAAYE,OAAOC,aAAaH,GAAa,GACxDI,EAAYpI,EAAMqE,YAAYpE,EAAS,IACvCoI,EAAoBrI,EAAMqE,YAAYpE,EAAS,IAErD,MAAO,CACL6H,gBACAF,iBACAI,YACAC,WACAG,YACAP,SACAF,iBACG5E,EACD/C,EAAMsI,SAASrI,EAAS,GAAIA,EAAS,GAAKoI,GAC1C9I,KAAK0D,cAGX,CAGA,YAAMgB,CAAOJ,GACX,MAAM0E,QAAehJ,KAAKkE,WAAWS,SAASL,GACxC7D,QAAc,IAAAwI,OAAMD,GAE1B,IAAIE,EAEJ,GAtEe,WAsEXzI,EAAMmE,aAAa,GACrBsE,EAAa,MACR,IAvEQ,WAuEJzI,EAAMmE,aAAa,GAG5B,MAAM,IAAIhE,MAAM,kBAFhBsI,EAAa,C,CAMflJ,KAAKkI,SAAWzH,EAAMqE,YAAY,GAClC9E,KAAKiI,MAAQxH,EAAMqE,YAAY,GAC/B9E,KAAKgI,eAAiB,GAAyB,GAAlBhI,KAAKiI,MAAQ,IAAW,GAAK,EAC1D,MAAMkB,EAAY1I,EAAMqE,YAAY,IAC9BsE,EAAMD,GAAa,GAAKnJ,KAAKmI,aAAa1H,EAAO,SAAMW,EACvDyD,EAAWpE,EAAMqE,YAAY,GAAKqE,GAKxC,IACI7F,EADAyB,EAAO,GAAKoE,EAAY,EAE5B,MAAM3E,EAAU,IAAIvB,MAGjB4B,GACH,IAAK,IAAIvE,EAAI,EAAGA,EAAIuE,EAAUvE,IAAK,CAEjC,MAAM0E,EAAWvE,EAAMqE,YAAYC,GACnCA,GAAQ,EACR,MAAME,EAAuC,CAAC,EAC9C,IAAIR,EACJ,IAAK,IAAIS,EAAI,EAAGA,EAAIF,EAAUE,IAAK,CACjC,MAAMlE,EAAMP,EAAMmE,aAAaG,GAE/B,GADAA,GAAQ,EACJ/D,EAAMhB,KAAKgI,aACbvD,EAAQlC,EAAe9B,EAAOsE,EAAO,IACrCA,GAAQ,OACH,CACLzB,EAAgBD,EAAcC,EAAe9C,EAAUC,EAAOsE,IAC9DA,GAAQ,EACR,MAAMK,EAAa3E,EAAMqE,YAAYC,GACrCA,GAAQ,EACR,MAAMpD,EAAS,IAAIsB,MAAamC,GAChC,IAAK,IAAIC,EAAI,EAAGA,EAAID,EAAYC,GAAK,EAAG,CACtC,MAAMC,EAAI9E,EAAUC,EAAOsE,GAC3BA,GAAQ,EACR,MAAMQ,EAAI/E,EAAUC,EAAOsE,GAC3BA,GAAQ,EACRzB,EAAgBD,EAAcC,EAAegC,GAC7C3D,EAAO0D,GAAK,IAAIxE,EAAMyE,EAAGC,EAAGvE,E,CAE9BiE,EAASjE,GAAOW,C,EAIpB6C,EAAQlE,GAAK,CAAE2E,WAAUR,Q,CAG3B,MAAO,CACLyE,aACA5F,gBACAkB,UACAK,WACAwE,KAAK,EACL1D,aAAc,SACXyD,EAEP,CAEA,oBAAMzC,CACJtC,EACAjE,EACAwG,EACAtC,EAAiB,CAAC,GAEdlE,EAAM,IACRA,EAAM,GAGR,MAAMyG,QAAkB7G,KAAKuE,MAAMD,GAC7BwC,EAAKD,aAAS,EAATA,EAAWrC,QAAQH,GAC9B,IAAKyC,EACH,MAAO,GAET,MAAMC,EAAkB/G,KAAKsJ,SAASlJ,EAAKwG,GAE3C,GAA+B,IAA3BG,EAAgBxG,OAClB,MAAO,GAGT,MAAMoB,EAAS,GAEf,IAAK,MAAOmE,EAAOC,KAAQgB,EACzB,IAAK,IAAI/F,EAAM8E,EAAO9E,GAAO+E,EAAK/E,IAChC,GAAI8F,EAAG7B,SAASjE,GAAM,CACpB,MAAMiG,EAAYH,EAAG7B,SAASjE,GAC9B,IAAK,MAAMuI,KAAKtC,EACdtF,EAAOS,KAAKmH,E,CAMpB,OAAO7H,EAAeC,EAAQ,IAAI/B,EAAc,EAAG,GACrD,CAMA,QAAA0J,CAAStC,EAAajB,IACpBiB,GAAO,GACG,IACRA,EAAM,GAEJjB,EAAM,GAAK,KACbA,EAAM,GAAK,IAEbA,GAAO,EACP,IAAIyD,EAAI,EACJC,EAAI,EACJ9F,EAAI3D,KAAKkI,SAAwB,EAAblI,KAAKiI,MAC7B,MAAMyB,EAAO,GACb,KAAOF,GAAKxJ,KAAKiI,MAAOtE,GAAK,EAAG8F,GAAY,EA7LjC,IA6LwC,EAAJD,GAAQA,GAAK,EAAG,CAC7D,MAAMrJ,EAAIsJ,EAAI9B,EAAOX,EAAKrD,GACpBuC,EAAIuD,EAAI9B,EAAO5B,EAAKpC,GAC1B,GAAIuC,EAAI/F,EAAIuJ,EAAKnJ,OAASP,KAAKgI,aAC7B,MAAM,IAAIpH,MACR,SAASoG,KAAOjB,oDAAsD/F,KAAKkI,mBAAmBlI,KAAKiI,iEAGvGyB,EAAKtH,KAAK,CAACjC,EAAG+F,G,CAEhB,OAAOwD,CACT,CAEA,WAAMnF,CAAMD,EAAiB,CAAC,GAO5B,OANKtE,KAAKwH,SACRxH,KAAKwH,OAASxH,KAAK0E,OAAOJ,GAAMmD,OAAMvB,IAEpC,MADAlG,KAAKwH,YAASpG,EACR8E,CAAC,KAGJlG,KAAKwH,MACd,CAEA,eAAME,CAAU7B,EAAevB,EAAiB,CAAC,G,MAE/C,SAA8B,QAArB,SADYtE,KAAKuE,MAAMD,IAChBE,QAAQqB,UAAM,eAAEZ,SAClC,ECxOF,MCGM0E,EAAiB,mBAAmBC,MAAM,IAC1CC,EAAgB,mBAAmBD,MAAM,IAKhC,MAAME,EAUnB,WAAAjK,CAAYQ,GATJ,KAAA0J,KAAO,CAAC,EAIR,KAAAC,SAAqB,GACrB,KAAAC,gBAAiB,EAKvB,MAAM,MAAExJ,EAAK,WAAEyJ,GAAe7J,GACxB,UAAE8J,EAAS,MAAErE,GAAUrF,EAC7BT,KAAK+J,KAAO,CAAC,EACb/J,KAAKS,MAAQA,EACbT,KAAKoK,IAAMF,EACXlK,KAAKqK,OAASF,EAAUrF,YAAYgB,EAAQ,GAC5C9F,KAAK+J,KAAKjE,MAAQqE,EAAUrF,YAAYgB,EAAQ,GAChD9F,KAAKsK,OAA6C,WAApCH,EAAUrF,YAAYgB,EAAQ,MAAqB,EACnE,CAEA,GAAAyE,CAAIC,GAEF,OAAIxK,KAAKwK,IAEHxK,KAAK+J,KAAKS,KAIdxK,KAAK+J,KAAKS,GAASxK,KAAKwK,MAHfxK,KAAK+J,KAAKS,IAMdxK,KAAKyK,KAAKD,EAAME,cACzB,CAEA,GAAA3E,GACE,OAAO/F,KAAKuK,IAAI,SAAWvK,KAAKuK,IAAI,gBACtC,CAEA,MAAAI,GACE,OAAO3K,KAAKqK,MACd,CAIA,IAAAI,CAAKD,GACH,OAAIA,KAASxK,KAAK+J,OAGlB/J,KAAK+J,KAAKS,GAASxK,KAAK4K,UAAUJ,IAFzBxK,KAAK+J,KAAKS,EAIrB,CAEA,KAAAK,GACE7K,KAAK8K,gBAEL,IAAIC,EAAO,CAAC,OAEP/K,KAAKgL,qBACRD,EAAK3I,KACH,QACA,MACA,SACA,QACA,OACA,KACA,QACA,gBACA,mBAGApC,KAAKiL,YACPF,EAAK3I,KAAK,wBAAyB,oBAErC2I,EAAOA,EAAKG,OAAOlL,KAAKgK,UAAY,IAEpC,IAAK,MAAM3E,KAAK8F,OAAOC,KAAKpL,KAAK+J,MAClB,MAAT1E,EAAE,IAAoB,gBAANA,GAClB0F,EAAK3I,KAAKiD,GAId,MAAMgG,EAAmC,CAAC,EAC1C,OAAON,EAAKO,QAAO7B,IACjB,GACGA,KAAKzJ,KAAK+J,WAAyB3I,IAAjBpB,KAAK+J,KAAKN,IACvB,OAANA,GACM,OAANA,EAEA,OAAO,EAGT,MAAM8B,EAAK9B,EAAEiB,cACP/G,EAAI0H,EAAKE,GAEf,OADAF,EAAKE,IAAM,GACH5H,CAAC,GAEb,CAEA,MAAA6H,GAEA,CAEA,QAAAC,GACE,OAAOzL,KAAKuK,IAAI,cAClB,CAEA,EAAAmB,GACE,OAAO1L,KAAKoK,GACd,CAMA,EAAAuB,GACE,MAAMA,GAA+B,MAAzB3L,KAAKuK,IAAI,gBAA2B,EAChD,OAAc,MAAPoB,OAAavK,EAAYuK,CAClC,CAEA,KAAAnF,GACE,OAAOxG,KAAKuK,IAAI,KAClB,CAEA,IAAAqB,G,MACE,OAAqB,QAAd,EAAA5L,KAAK6L,iBAAS,eAAEC,KAAK,IAC9B,CAEA,OAAAD,GACE,GAAI7L,KAAKgL,oBACP,OAGF,MAAM,MAAElF,EAAK,UAAEqE,GAAcnK,KAAKS,MAC5BsL,EACJjG,EACA,GACA9F,KAAKuK,IAAI,gBACiB,EAA1BvK,KAAKuK,IAAI,eACTvK,KAAKuK,IAAI,cACLyB,EAAOhM,KAAKuK,IAAI,cACtB,OAAOJ,EAAUpB,SAASgD,EAAGA,EAAIC,EACnC,CAEA,MAAAC,GACE,OAAOjM,KAAKkM,yBAA2B,EAAI,CAC7C,CAEA,iCAAAC,GACE,IAAInM,KAAKoM,iBAGT,OAAOpM,KAAKqM,6BAA+B,EAAI,CACjD,CAEA,IAAAC,GACE,OAAOtM,KAAKuK,IAAI,aAClB,CAEA,UAAAgC,GACE,MAAMC,EAAKxM,KAAKuK,IAAI,iBACd,UAAEJ,EAAS,MAAErE,GAAU9F,KAAKS,MAClC,OAAO0J,EAAUlK,SAAS,QAAS6F,EAAQ,GAAIA,EAAQ,GAAK0G,EAAK,EACnE,CAMA,SAAA5B,CAAU6B,GAIR,GAAIzM,KAAKiK,eACP,OAGF,MAAM,UAAEE,EAAS,MAAErE,GAAU9F,KAAKS,MAClC,IAAIsL,EACF/L,KAAK0M,YACL5G,EACE,GACA9F,KAAKuK,IAAI,gBACiB,EAA1BvK,KAAKuK,IAAI,eACTvK,KAAKuK,IAAI,cACTvK,KAAKuK,IAAI,cAEb,MAAMoC,EAAW3M,KAAKS,MAAMsF,IAC5B,IAAI6G,EACJ,KAAOb,EAAIY,GAAYC,IAAUH,GAAS,CACxC,MAAMI,EAAMlE,OAAOC,aAAauB,EAAU4B,GAAI5B,EAAU4B,EAAI,IAC5Da,EAAQC,EAAInC,cACZ,MAAMoC,EAAOnE,OAAOC,aAAauB,EAAU4B,EAAI,IAG/C,IAAIgB,EACJ,OAHAhB,GAAK,EAGGe,GACN,IAAK,IACHC,EAAQpE,OAAOC,aAAauB,EAAU4B,IACtCA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAUrF,YAAYiH,GAC9BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAUvF,aAAamH,GAC/BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAU6C,SAASjB,GAC3BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAU8C,UAAUlB,GAC5BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAU+C,YAAYnB,GAC9BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAUgD,aAAapB,GAC/BA,GAAK,EACL,MAEF,IAAK,IACHgB,EAAQ5C,EAAUiD,YAAYrB,GAC9BA,GAAK,EACL,MAEF,IAAK,IACL,IAAK,IAEH,IADAgB,EAAQ,GACDhB,GAAKY,GAAU,CACpB,MAAMU,EAAKlD,EAAU4B,KACrB,GAAW,IAAPsB,EACF,MAEAN,GAASpE,OAAOC,aAAayE,E,CAGjC,MAEF,IAAK,IAAK,CACRN,EAAQ,GACR,MAAMM,EAAKlD,EAAU4B,KACfuB,EAAQ3E,OAAOC,aAAayE,GAC5BE,EAAQpD,EAAUrF,YAAYiH,GAEpC,GADAA,GAAK,EACS,MAAVuB,EACF,GAAY,OAART,EACF,IAAK,IAAIxH,EAAI,EAAGA,EAAIkI,EAAOlI,IAAK,CAC9B,MAAMmI,EAAQrD,EAAUrF,YAAYiH,GAGpCgB,IAFYS,GAAS,GACV3D,EAAsB,GAAR2D,GAEzBzB,GAAK,C,MAGP,IAAK,IAAI1G,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAUrF,YAAYiH,GAC3B1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAIX,GAAc,MAAVuB,EACF,GAAY,OAART,EACF,IAAK,IAAIxH,EAAI,EAAGA,EAAIkI,EAAOlI,IAAK,CAC9B,MAAMmI,EAAQrD,EAAUvF,aAAamH,GAGrCgB,IAFYS,GAAS,GACV3D,EAAsB,GAAR2D,GAEzBzB,GAAK,C,MAGP,IAAK,IAAI1G,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAUvF,aAAamH,GAC5B1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAIX,GAAc,MAAVuB,EACF,IAAK,IAAIjI,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAU+C,YAAYnB,GAC3B1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAIjI,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAUgD,aAAapB,GAC5B1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAIjI,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAU6C,SAASjB,GACxB1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAIjI,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAU8C,UAAUlB,GACzB1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAGT,GAAc,MAAVuB,EACF,IAAK,IAAIjI,EAAI,EAAGA,EAAIkI,EAAOlI,IACzB0H,GAAS5C,EAAUiD,YAAYrB,GAC3B1G,EAAI,EAAIkI,IACVR,GAAS,KAEXhB,GAAK,EAGT,K,CAEF,QACE0B,QAAQC,KAAK,yBAAyBZ,8BACtCC,OAAQ3L,EACR2K,EAAIY,EAOR,GAHA3M,KAAK0M,WAAaX,EAElB/L,KAAKgK,SAAS5H,KAAKyK,GACfD,IAAUH,EACZ,OAAOM,EAGT/M,KAAK+J,KAAK6C,GAASG,C,CAErB/M,KAAKiK,gBAAiB,CAExB,CAEA,aAAAa,GACE9K,KAAK4K,UAAU,GACjB,CAEA,WAAA+C,CAAYC,GACV,OAEEA,EACGC,MAAM,UAENpH,KAAIqH,GAAM,CAACA,EAAGD,MAAM,MAAM,GAAGE,cAAepL,OAAOqL,SAASF,EAAI,MAEvE,CAKA,QAAA7C,GACE,SDlYW,ECkYDjL,KAAKsK,MACjB,CAGA,gBAAA2D,GACE,SDrYgB,ECqYNjO,KAAKsK,MACjB,CAGA,iBAAAU,GACE,SDxYU,ECwYAhL,KAAKsK,MACjB,CAGA,cAAA8B,GACE,SD3YW,EC2YDpM,KAAKsK,MACjB,CAGA,qBAAA4B,GACE,SD9YY,GC8YFlM,KAAKsK,MACjB,CAGA,yBAAA+B,GACE,SDjZa,GCiZHrM,KAAKsK,MACjB,CAGA,OAAA4D,GACE,SDpZU,GCoZAlO,KAAKsK,MACjB,CAGA,OAAA6D,GACE,SDvZU,ICuZAnO,KAAKsK,MACjB,CAGA,WAAA8D,GACE,SD1Zc,IC0ZJpO,KAAKsK,MACjB,CAGA,UAAA+D,GACE,SD7ZW,IC6ZDrO,KAAKsK,MACjB,CAGA,WAAAgE,GACE,SDhaQ,KCgaEtO,KAAKsK,MACjB,CAGA,eAAAiE,GACE,SDnakB,KCmaRvO,KAAKsK,MACjB,CAEA,KAAAsD,GACE,GAAI5N,KAAKgL,oBACP,OAGF,MAAM,UAAEb,EAAS,MAAErE,GAAU9F,KAAKS,MAC5B+N,EAAcxO,KAAKuK,IAAI,eAC7B,IAAIwB,EAAIjG,EAAQ,GAAK9F,KAAKuK,IAAI,gBAC9B,MAAMkE,EAASzO,KAAKuK,IAAI,cACxB,IAAIqD,EAAQ,GACRc,EAAO,EAIPlB,EAAQrD,EAAUrF,YAAYiH,GAC9B4C,EAAMnB,GAAS,EACfM,EAAKjE,EAAsB,GAAR2D,GACvB,GAAW,MAAPM,GAAca,IAAQF,EAWxB,OARA1C,GAAK,EACLyB,EAAQrD,EAAUrF,YAAYiH,GAC9B4C,EAAMnB,GAAS,EACfM,EAAKjE,EAAsB,GAAR2D,GACR,MAAPM,GACFL,QAAQC,KAAK,wBAEf1N,KAAK+J,KAAK6E,cAAgBD,EACnB3O,KAAKuK,IAAI,MAEhB,IAAK,IAAIhB,EAAI,EAAGA,EAAIiF,IAAejF,EACjCiE,EAAQrD,EAAUrF,YAAYiH,GAC9B4C,EAAMnB,GAAS,EACfM,EAAKjE,EAAsB,GAAR2D,GACnBI,GAASe,EAAMb,EAIJ,MAAPA,GAAqB,MAAPA,GAAqB,MAAPA,IAC9BY,GAAQC,GAGV5C,GAAK,EAIP,OADA/L,KAAK+J,KAAK6E,cAAgBF,EACnBd,CAEX,CAEA,MAAAiB,GAAU,CAEV,aAAAD,GACE,OAAI5O,KAAK+J,KAAK6E,eAGZ5O,KAAKuK,IAAI,SAFFvK,KAAK+J,KAAK6E,aAKrB,CAEA,WAAAE,GACE,OAA8B,MAAvB9O,KAAKuK,IAAI,WAClB,CAEA,YAAAwE,GACE,OAAgC,IAAzB/O,KAAKuK,IAAI,aAClB,CAKA,UAAAyE,GACE,OAAQhP,KAAKuK,IAAI,cAAgB,GAAM,CACzC,CAEA,YAAA0E,GACE,OAAOjP,KAAKkP,KACd,CAEA,GAAAA,GACE,MAAM,UAAE/E,EAAS,MAAErE,GAAU9F,KAAKS,MAC5BsL,EACJjG,EAAQ,GAAK9F,KAAKuK,IAAI,gBAA4C,EAA1BvK,KAAKuK,IAAI,eAC7C4E,EAAWnP,KAAKuK,IAAI,cACpB6E,EAAMpP,KAAKuK,IAAI,cACrB,IAAI8E,EAAM,GACN/O,EAAI,EACR,IAAK,IAAI4E,EAAI,EAAGA,EAAIiK,IAAYjK,EAAG,CACjC,MAAMoK,EAAKnF,EAAU4B,EAAI7G,GACzBmK,GAAO1F,GAAqB,IAAL2F,IAAc,GACrChP,IACIA,EAAI8O,IACNC,GAAO1F,EAAoB,GAAL2F,GACtBhP,I,CAGJ,OAAO+O,CACT,CAGA,kBAAAE,GACE,IACGvP,KAAKgL,sBACLhL,KAAKoM,kBACNpM,KAAKqK,SAAWrK,KAAKwP,cACrB,CACA,MAAMC,EAAKzP,KAAKkM,wBAA0B,IAAM,IAC1CwD,EAAK1P,KAAKqM,4BAA8B,IAAM,IACpD,IAAIsD,EAAK,IACLC,EAAK,IACL5P,KAAKkO,WACPyB,EAAK,IACLC,EAAK,KACI5P,KAAKmO,YACdwB,EAAK,IACLC,EAAK,KAGP,MAAMC,EAAM,GAaZ,OAZc7P,KAAK8P,kBACP,GACVD,EAAI,GAAKJ,EACTI,EAAI,GAAKF,EACTE,EAAI,GAAKH,EACTG,EAAI,GAAKD,IAETC,EAAI,GAAKJ,EACTI,EAAI,GAAKF,EACTE,EAAI,GAAKH,EACTG,EAAI,GAAKD,GAEJC,EAAI/D,KAAK,G,CAElB,MAAO,EACT,CAEA,UAAAiE,GACE,OAAO/P,KAAKS,MAAM0J,UAAUrF,YAAY9E,KAAKS,MAAMqF,MAAQ,GAC7D,CAEA,QAAAkK,GACE,OAAOhQ,KAAKS,MAAM0J,UAAUrF,YAAY9E,KAAKS,MAAMqF,MAAQ,GAC7D,CAEA,UAAAmK,GACE,OAAOjQ,KAAKS,MAAM0J,UAAUrF,YAAY9E,KAAKS,MAAMqF,MAAQ,GAC7D,CAEA,WAAA0J,GACE,OAAOxP,KAAKS,MAAM0J,UAAUrF,YAAY9E,KAAKS,MAAMqF,MAAQ,GAC7D,CAEA,SAAAoK,GACE,OAAOlQ,KAAKS,MAAM0J,UAAUrF,YAAY9E,KAAKS,MAAMqF,MAAQ,GAC7D,CAEA,eAAAgK,GACE,OAAO9P,KAAKS,MAAM0J,UAAUrF,YAAY9E,KAAKS,MAAMqF,MAAQ,GAC7D,CAEA,MAAAqK,GACE,MAAMpG,EAA+B,CAAC,EACtC,IAAK,MAAM1E,KAAK8F,OAAOC,KAAKpL,MACN,MAAhBqF,EAAE+K,OAAO,IAAoB,UAAN/K,IAI3B0E,EAAK1E,GAAKrF,KAAKqF,IAGjB,OAAO0E,CACT,EC1mBK,SAASsG,EAAgBC,GAC9B,MAAMC,EAAQD,EAAK1G,MAAM,SACnBG,EAAkE,GACxE,IAAK,MAAMyG,KAAQD,EAAO,CACxB,MAAO1D,KAAQ4D,GAAUD,EAAK5G,MAAM,MAChCiD,GACF9C,EAAK3H,KAAK,CACRyK,IAAKA,EAAI1J,MAAM,GACf4G,KAAM0G,EAAOhK,KAAIiK,IACf,MAAOC,EAAU5D,GAAS2D,EAAE9G,MAAM,IAAK,GACvC,MAAO,CAAEiD,IAAK8D,EAAU5D,QAAO,K,CAKvC,OAAOhD,CACT,CCDO,MAAM6G,EAAY,SAiBzB,MAAMC,EACG,IAAAC,GACL,MAAM,IAAIlQ,MAAM,eAClB,CACO,IAAAmQ,GACL,MAAM,IAAInQ,MAAM,eAClB,CAEO,QAAA+D,GACL,MAAM,IAAI/D,MAAM,eAClB,CAEO,KAAAoQ,GACL,MAAM,IAAIpQ,MAAM,eAClB,EAEa,MAAMqQ,EAyBnB,WAAApR,EAAY,cACVqR,EAAa,QACbC,EAAO,OACPC,EAAM,QACNC,EAAO,cACPC,EAAa,OACbC,EAAM,QACNC,EAAO,cACPC,EAAa,OACbC,EAAM,OACNC,EAAM,gBACNC,EAAkB,IAAG,cACrBC,EAAgB1N,IAAKA,KAiBrB,GA9CK,KAAAwN,QAAS,EAGR,KAAAG,aAAe,IAAI,IAAJ,CAA8C,CACnEC,MAAO,IAAI,IAAJ,CAAa,CAClBC,QAAS,KAEXC,KAAMC,MAAO7R,EAAY8R,KACvB,MAAM,MAAEhQ,EAAK,KAAEmC,GAASjE,GAClB,KAAE0J,EAAI,WAAEqI,EAAU,WAAEC,SAAqBrS,KAAKsS,WAAW,CAC7DnQ,QACAmC,KAAM,IAAKA,EAAM6N,YAEnB,OAAOnS,KAAKuS,gBAAgBxI,EAAMqI,EAAYC,EAAYlQ,EAAM,IA+BlEnC,KAAK0D,aAAemO,EAEhBX,EACFlR,KAAKwS,IAAMtB,OACN,GAAIC,EACTnR,KAAKwS,IAAM,IAAI,KAAUrB,QACpB,GAAIC,EACTpR,KAAKwS,IAAM,IAAI,KAAWpB,OACrB,KAAIO,EAIT,MAAM,IAAI/Q,MAAM,4BAHhBZ,KAAK2R,QAAS,EACd3R,KAAKwS,IAAM,IAAI3B,C,CAIjB,GAAIY,EACFzR,KAAKyS,MAAQ,IAAI1K,EAAI,CAAE7D,WAAYuN,SAC9B,GAAID,EACTxR,KAAKyS,MAAQ,IAAI1K,EAAI,CAAE7D,WAAY,IAAI,KAAUsN,UAC5C,GAAIE,EACT1R,KAAKyS,MAAQ,IAAI1K,EAAI,CAAE7D,WAAY,IAAI,KAAWwN,UAC7C,GAAIJ,EACTtR,KAAKyS,MAAQ,IAAIrO,EAAI,CAAEF,WAAYoN,SAC9B,GAAID,EACTrR,KAAKyS,MAAQ,IAAIrO,EAAI,CAAEF,WAAY,IAAI,KAAUmN,UAC5C,GAAIE,EACTvR,KAAKyS,MAAQ,IAAIrO,EAAI,CAAEF,WAAY,IAAI,KAAWqN,UAC7C,GAAIJ,EACTnR,KAAKyS,MAAQ,IAAIrO,EAAI,CAAEF,WAAY,IAAI,KAAU,GAAGiN,gBAC/C,GAAIC,EACTpR,KAAKyS,MAAQ,IAAIrO,EAAI,CAAEF,WAAY,IAAI,KAAW,GAAGkN,eAChD,KAAIO,EAGT,MAAM,IAAI/Q,MAAM,gCAFhBZ,KAAK2R,QAAS,C,CAIhB3R,KAAK4R,gBAAkBA,CACzB,CAEA,kBAAMc,CAAaC,GACjB,MAAMrO,EP/DH,SAAkBsO,EAA8B,CAAC,GACtD,MAAO,YAAaA,EAAO,CAAET,OAAQS,GAAsBA,CAC7D,CO6DiBC,CAASF,GACtB,IAAK3S,KAAKyS,MACR,OAEF,MAAM5L,QAAkB7G,KAAKyS,MAAMlO,MAAMD,GACnCwO,EAAMjM,EAAUvD,cAClBuD,EAAUvD,cAAcxD,cAAgB,WACxCsB,EACJ,IAAI4H,EACJ,GAAI8J,EAAK,CACP,MAAMnP,EAAImP,EApIC,MAqILC,QAAY/S,KAAKwS,IAAI1B,KAAK,EAAAkC,OAAOC,MAAMtP,GAAI,EAAGA,EAAG,EAAGW,GAC1D,IAAKyO,EAAIG,UACP,MAAM,IAAItS,MAAM,wBAElBoI,EAAS+J,EAAI/J,OAAOD,SAAS,EAAG1B,KAAKjH,IAAI2S,EAAIG,UAAWJ,G,MAExD9J,QAAgBhJ,KAAKwS,IAAI7N,SAASL,GAGpC,MAAM6O,QAAc,IAAAlK,OAAMD,GAE1B,GAAImK,EAAMrO,YAAY,KAAO8L,EAC3B,MAAM,IAAIhQ,MAAM,kBAElB,MAAMwS,EAAUD,EAAMrO,YAAY,GAElC9E,KAAKqT,OAASF,EAAMlT,SAAS,OAAQ,EAAG,EAAImT,GAC5C,MAAM,WAAEE,EAAU,WAAEC,SAAqBvT,KAAKwT,aAC5CJ,EAAU,EACV,MACA9O,GAKF,OAHAtE,KAAKsT,WAAaA,EAClBtT,KAAKuT,WAAaA,EAEXlD,EAAgBrQ,KAAKqT,OAC9B,CAEA,SAAAI,CAAUnP,GAOR,OANKtE,KAAK0T,UACR1T,KAAK0T,QAAU1T,KAAK0S,aAAapO,GAAMmD,OAAMvB,IAE3C,MADAlG,KAAK0T,aAAUtS,EACT8E,CAAC,KAGJlG,KAAK0T,OACd,CAEA,mBAAMC,CAAcrP,EAAiB,CAAC,GAEpC,aADMtE,KAAKyT,UAAUnP,GACdtE,KAAKqT,MACd,CAIA,kBAAMG,CACJ1N,EACA8N,EACAtP,GAKA,GAAIwB,EAAQ8N,EACV,OAAO5T,KAAKwT,aAAa1N,EAAqB,EAAd8N,EAAiBtP,GAEnD,MAAMuP,EAAOD,EA7LA,OA8LP,UAAEV,EAAS,OAAElK,SAAiBhJ,KAAKwS,IAAI1B,KAC3C,EAAAkC,OAAOC,MAAMY,GACb,EACAD,EACA,EACAtP,GAEF,IAAK4O,EACH,MAAM,IAAItS,MAAM,qCAElB,MAAMuS,QAAc,IAAAlK,OAClBD,EAAOD,SAAS,EAAG1B,KAAKjH,IAAI8S,EAAWU,KAEnCE,EAAOX,EAAMrO,YAAYgB,GAC/B,IAAIiG,EAAIjG,EAAQ,EAChB,MAAMwN,EAAwC,CAAC,EACzCC,EAAoD,GAC1D,IAAK,IAAIjT,EAAI,EAAGA,EAAIwT,EAAMxT,GAAK,EAAG,CAChC,MAAMyT,EAAQZ,EAAMrO,YAAYiH,GAC1B/H,EAAUhE,KAAK0D,aACnByP,EAAMlT,SAAS,OAAQ8L,EAAI,EAAGA,EAAI,EAAIgI,EAAQ,IAE1CC,EAAOb,EAAMrO,YAAYiH,EAAIgI,EAAQ,GAM3C,GAJAT,EAAWtP,GAAW1D,EACtBiT,EAAWnR,KAAK,CAAE4B,UAASzD,OAAQyT,IAEnCjI,EAAIA,EAAI,EAAIgI,EACRhI,EAAIoH,EAAM5S,OAIZ,OAHAkN,QAAQC,KACN,wCAAwCkG,YAEnC5T,KAAKwT,aAAa1N,EAAqB,EAAd8N,EAAiBtP,E,CAGrD,MAAO,CAAEgP,aAAYC,aACvB,CAEA,wBAAMU,CACJC,EACA9T,EACAwG,EACAtC,GAEA,OAxOJ4N,eAA4BiC,GAC1B,IAAIC,EAAW,GACf,UAAW,MAAMC,KAAKF,EACpBC,EAAMA,EAAIlJ,OAAOmJ,GAEnB,OAAOD,CACT,CAkOWE,CAAUtU,KAAKuU,sBAAsBL,EAAK9T,EAAKwG,EAAKtC,GAC7D,CAEA,2BAAOiQ,CACLL,EACA9T,EACAwG,EACAtC,G,YAEMtE,KAAKyT,UAAUnP,GACrB,MAAMkQ,EAAuB,QAAf,EAAAxU,KAAKsT,kBAAU,eAAGY,GAChC,QAAc9S,IAAVoT,GAAwBxU,KAAKyS,MAE1B,CACL,MAAM9Q,QAAe3B,KAAKyS,MAAM9L,eAAe6N,EAAOpU,EAAM,EAAGwG,EAAKtC,SAC7DtE,KAAKyU,oBAAoB9S,EAAQ6S,EAAOpU,EAAKwG,EAAKtC,E,WAHnD,EAKV,CAEA,yBAAOmQ,CACL9S,EACA6S,EACApU,EACAwG,EACAtC,EAAgB,CAAC,GAEjB,MAAM,YAAEoQ,GAAgBpQ,EAClBqQ,EAAQ,GACd,IAAIC,GAAO,EAEX,IAAK,MAAMzS,KAASR,EAAQ,CAC1B,MAAMkT,QAAgB7U,KAAK8R,aAAavH,IACtCpI,EAAMlC,WACN,CAAEkC,QAAOmC,QACTA,EAAK6N,QAGD2C,EAAO,GACb,IAAK,MAAMC,KAAWF,EACpB,GAAIE,EAAQpK,WAAa6J,EAAO,CAC9B,GAAIO,EAAQxK,IAAI,UAAY3D,EAAK,CAE/BgO,GAAO,EACP,K,CACSG,EAAQxK,IAAI,QAAUnK,GAE/B0U,EAAK1S,KAAK2S,E,CAMhB,GAFAJ,EAAMvS,KAAK0S,SACLA,EACFF,EACF,K,EPnRD,SAA0BzC,GAC/B,GAAKA,GAIDA,EAAO6C,QAAS,CAElB,GAA4B,oBAAjBC,aAA8B,CACvC,MAAM/O,EAAI,IAAItF,MAAM,WAGpB,MADAsF,EAAEgP,KAAO,cACHhP,C,CAEN,MAAM,IAAI+O,aAAa,UAAW,a,CAGxC,EOuQIE,CAAiB7Q,EAAK6N,QAClBuC,UACI1U,KAAKoV,WAAWZ,EAAOG,EAAOrQ,GAExC,CAEA,gBAAM8Q,CAAWZ,EAAeG,EAAuBrQ,GACrD,MAAM,cAAE+Q,EAAa,cAAEC,EAAgB,KAAWhR,EAC5CiR,EAA2C,CAAC,EAC5CC,EAAqC,CAAC,EAC5Cb,EAAMlO,KAAIqM,IACR,MAAM2C,EAAuC,CAAC,EAC9C,IAAK,MAAMC,KAAW5C,EAAK,CACzB,MAAMxG,EAAOoJ,EAAQpJ,OACfZ,EAAKgK,EAAQhK,KACd+J,EAAUnJ,KACbmJ,EAAUnJ,GAAQ,GAEpBmJ,EAAUnJ,KACVkJ,EAAQ9J,GAAM,C,CAEhB,IAAK,MAAOrG,EAAGE,KAAM4F,OAAOwK,QAAQF,GACxB,IAANlQ,IACFgQ,EAAalQ,IAAK,E,IAKxB,MAAMuQ,EAAmC,GACzCjB,EAAMlO,KAAIqM,IACR,IAAK,MAAMpC,KAAKoC,EAAK,CACnB,MAAMxG,EAAOoE,EAAEpE,OACTxG,EAAQ4K,EAAEnG,IAAI,SACdsL,EAAQnF,EAAER,YACV4F,EAAQpF,EAAElB,cAEdxP,KAAKyS,OACL8C,EAAajJ,KACZ+I,GACES,IAAUtB,GAASnN,KAAK0O,IAAIjQ,EAAQ+P,GAASP,IAEhDM,EAAaxT,KACXpC,KAAKyS,MAAM9L,eAAemP,EAAOD,EAAOA,EAAQ,EAAGvR,G,KAQ3D,MAAMmC,EAAM,IAAIuP,IACVjD,QAAYxR,QAAQ0U,IAAIL,GAC9B,IAAK,MAAMM,KAAKnD,EAAIoD,OACb1P,EAAI2P,IAAIF,EAAEjW,aACbwG,EAAI4P,IAAIH,EAAEjW,WAAYiW,GAwB1B,aApB+B3U,QAAQ0U,IACrC,IAAIxP,EAAI6P,UAAU7P,KAAIyL,MAAM3I,IAC1B,MAAM,KAAEQ,EAAI,WAAEqI,EAAU,WAAEC,EAAU,MAAElQ,SAAgBnC,KAAKsS,WAAW,CACpEnQ,MAAOoH,EACPjF,SAEIiS,EAAW,GACjB,IAAK,MAAMxB,WAAiB/U,KAAKuS,gBAC/BxI,EACAqI,EACAC,EACAlQ,GAEIoT,EAAaR,EAAQxK,IAAI,WAAaiL,EAAQT,EAAQrJ,OACxD6K,EAASnU,KAAK2S,GAGlB,OAAOwB,CAAQ,MAGKJ,MAC1B,CAEA,iBAAMK,CAAYC,EAAkB5C,EAAcvP,EAAiB,CAAC,GAClE,MAAM,UAAE4O,EAAS,OAAElK,SAAiBhJ,KAAKwS,IAAI1B,KAC3C,EAAAkC,OAAOC,MAAMY,GACb,EACAA,EACA4C,EACAnS,GAGF,OAAO0E,EAAOD,SAAS,EAAG1B,KAAKjH,IAAI8S,EAAWW,GAChD,CAEA,gBAAMvB,EAAW,MAAEnQ,EAAK,KAAEmC,IACxB,MAAM0E,QAAehJ,KAAKwW,YACxBrU,EAAMrB,KAAKhB,cACXqC,EAAMhB,cACNmD,IAIA0E,OAAQe,EAAI,WACZqI,EAAU,WACVC,SACQ,QAAgBrJ,EAAQ7G,GAClC,MAAO,CAAE4H,OAAMqI,aAAYC,aAAYlQ,QACzC,CAEA,qBAAMoQ,CACJzL,EACAsL,EACAC,EACAlQ,GAEA,IAAIuU,EAAa,EACjB,MAAMC,EAAO,GACb,IAAIC,EAAM,EACNC,GAAQC,KAAKC,MAEjB,KAAOL,EAAa,EAAI5P,EAAGvG,QAAQ,CACjC,MACMoM,EAAW+J,EAAa,EADZ5P,EAAGhC,YAAY4R,GACa,EAG9C,GAAIrE,EAAY,CACd,KAAOqE,EAAavU,EAAMrB,KAAKf,cAAgBsS,EAAWuE,OAC1DA,G,CAIF,GAAIjK,EAAW7F,EAAGvG,OAAQ,CACxB,MAAMwU,EAAU,IAAI,EAAW,CAC7BtU,MAAO,CACL0J,UAAWrD,EACXhB,MAAO4Q,EACP3Q,IAAK4G,GAsBPzC,WACEkI,EAAW7R,OAAS,EACE,IAAlB6R,EAAWwE,IACVF,EAAarE,EAAWuE,IACzBzU,EAAMrB,KAAKf,aACX,EAEA,WAAa+G,EAAG3D,MAAMuT,EAAY/J,MAG1CgK,EAAKvU,KAAK2S,GACN/U,KAAK4R,kBAAoBkF,KAAKC,MAAQF,EAAO7W,KAAK4R,wBAC9CvQ,EAAQ,GACdwV,GAAQC,KAAKC,M,CAIjBL,EAAa/J,EAAW,C,CAE1B,OAAOgK,CACT,CAEA,eAAMjP,CAAUsP,G,QACd,MAAMnR,EAAuB,QAAf,EAAA7F,KAAKsT,kBAAU,eAAG0D,GAChC,YAAiB5V,IAAVyE,IAAwC,QAAV,EAAA7F,KAAKyS,aAAK,eAAE/K,UAAU7B,GAC7D,CAEA,eAAMrD,CAAUwU,G,MACd,MAAMnR,EAAuB,QAAf,EAAA7F,KAAKsT,kBAAU,eAAG0D,GAChC,YAAiB5V,IAAVyE,GAAwB7F,KAAKyS,MAAYzS,KAAKyS,MAAMjQ,UAAUqD,GAAzB,CAC9C,CAEA,cAAMD,CAASoR,EAAiBlR,EAAgBC,G,MAC9C,IAAK/F,KAAKyS,MACR,MAAO,SAEHzS,KAAKyS,MAAMlO,QACjB,MAAMsB,EAAuB,QAAf,EAAA7F,KAAKsT,kBAAU,eAAG0D,GAChC,YAAiB5V,IAAVyE,EAAsB,GAAK7F,KAAKyS,MAAM7M,SAASC,EAAOC,EAAOC,EACtE,CAEA,oBAAMY,CACJqQ,EACAlR,EACAC,EACAzB,G,MAEA,IAAKtE,KAAKyS,MACR,MAAO,SAEHzS,KAAKyS,MAAMlO,QACjB,MAAMsB,EAAuB,QAAf,EAAA7F,KAAKsT,kBAAU,eAAG0D,GAChC,YAAiB5V,IAAVyE,EACH,GACA7F,KAAKyS,MAAM9L,eAAed,EAAOC,EAAOC,EAAKzB,EACnD,EC7fF4N,eAAehH,EAAO+L,EAAoB3S,GACxC,MAAMyO,QAAYxR,QAAQ0U,IACxBgB,EAAIxQ,KAAIyL,MAAM/P,IACZ,MAAM,IAAE+U,EAAG,QAAEC,GAAYhV,EACzB,GAAI+U,EAAIE,WAAW,SACjB,OAAO,EAAApE,OAAOqE,KAAKH,EAAItN,MAAM,KAAK,GAAI,UACjC,CAIL,MAAM,QAAE0N,KAAYC,GAASJ,EACvBpE,QAAYyE,MAAMN,EAAK,IACxB5S,EACH6S,QAAS,IAAK7S,aAAI,EAAJA,EAAM6S,WAAYI,KAElC,IAAKxE,EAAI0E,GACP,MAAM,IAAI7W,MACR,QAAQmS,EAAI2E,mBAAmBR,YAAcnE,EAAIzC,UAGrD,OAAO,EAAA0C,OAAOqE,WAAWtE,EAAI4E,c,MAKnC,OAAO,EAAA3E,OAAO9H,aAAa3J,QAAQ0U,IAAIlD,EAAItM,KAAImR,IAAO,IAAA3O,OAAM2O,MAC9D,CAEe,MAAMC,UAAmB5G,EAKtC,WAAApR,CAAYQ,GACVyX,MAAM,CAAEnG,QAAQ,IAChB3R,KAAK+X,QAAU1X,EAAK0X,QACpB/X,KAAKgY,QAAU3X,EAAK2X,OACtB,CAEA,2BAAOzD,CACLL,EACA9T,EACAwG,EACAtC,G,MAEA,MACM4S,EAAM,GADIlX,KAAK+X,WAAW/X,KAAKgY,yBACA9D,WAAa9T,SAAWwG,eACvD4N,EAAuB,QAAf,EAAAxU,KAAKsT,kBAAU,eAAGY,GAChC,QAAc9S,IAAVoT,OACI,OACD,CACL,MAAMyD,QAAeT,MAAMN,EAAK,IAAK5S,IACrC,IAAK2T,EAAOR,GACV,MAAM,IAAI7W,MACR,QAAQqX,EAAOP,mBAAmBR,YAAce,EAAO3H,UAG3D,MAAMvG,QAAakO,EAAOC,OACpB/E,QAAcjI,EAAOnB,EAAK4H,OAAOwG,KAAKhV,MAAM,GAAImB,SAE/CtE,KAAKyU,oBACV,CAEE,CACEzL,OAAQmK,EACRlS,kBAAcG,EACdJ,IAAK,EACLd,UAAS,IACA,EAETgB,eAAc,IACL,GAAGgT,KAAO9T,KAAOwG,IAE1BzF,YAAW,IACF,EAETL,KAAM,CACJf,aAAc,EACdD,cAAe,EACfI,UAAW,IAAM,GAEnBa,KAAM,CACJhB,aAAc4C,OAAOC,iBACrB9C,cAAe,EACfI,UAAW,IAAM,GAEnBD,SAAQ,IACC,GAAGiU,KAAO9T,KAAOwG,MAI9B4N,EACApU,EACAwG,EACAtC,E,CAGN,CAEA,gBAAMgO,EAAW,MAAEnQ,IACjB,IAAKA,EAAM6G,OACT,MAAM,IAAIpI,MAAM,mCAElB,MAAO,CAAEmJ,KAAM5H,EAAM6G,OAAQoJ,WAAY,GAAIC,WAAY,GAAIlQ,QAC/D,CAEA,eAAMsR,CAAUnP,EAAiB,CAAC,GAChC,MAAM4S,EAAM,GAAGlX,KAAK+X,WAAW/X,KAAKgY,wCAC9BC,QAAeT,MAAMN,EAAK5S,GAChC,IAAK2T,EAAOR,GACV,MAAM,IAAI7W,MACR,QAAQqX,EAAOP,mBAAmBR,YAAce,EAAO3H,UAG3D,MAAMvG,QAAakO,EAAOC,OACpB/E,QAAcjI,EAAOnB,EAAK4H,OAAOwG,KAAM7T,GAE7C,GAAI6O,EAAMrO,YAAY,KAAO8L,EAC3B,MAAM,IAAIhQ,MAAM,kBAElB,MAAMwS,EAAUD,EAAMrO,YAAY,GAE5BsT,EAAY/H,EADC8C,EAAMlT,SAAS,OAAQ,EAAG,EAAImT,IAK3CiF,EAAkD,GAClDC,EAAmC,CAAC,EACpCC,EAAUH,EAAU9M,QAAO9B,GAAe,OAAVA,EAAEqD,MACxC,IAAK,MAAOxI,EAAOmU,KAAWD,EAAQ5C,UAAW,CAC/C,IAAI3R,EAAU,GACVzD,EAAS,EACb,IAAK,MAAMkY,KAAQD,EAAOzO,KACP,OAAb0O,EAAK5L,IACP7I,EAAUyU,EAAK1L,MACO,OAAb0L,EAAK5L,MACdtM,GAAUkY,EAAK1L,OAGnBuL,EAAStU,GAAWK,EACpBgU,EAAShU,GAAS,CAAEL,UAASzD,S,CAI/B,OAFAP,KAAKsT,WAAagF,EAClBtY,KAAKuT,WAAa8E,EACXD,CACT,E,6FC3IFlG,eAAejJ,EAAMyP,GACnB,IACE,IAAIC,EACA/B,EAAM,EACNtW,EAAI,EACR,MAAMqB,EAAS,GACf,IACIiX,EADAtS,EAAY,EAEhB,EAAG,CACD,MAAMuS,EAAiBH,EAAU3P,SAAS6N,GAK1C,GAJAgC,EAAW,IAAI,EAAAE,UAEXH,QAASC,GACbA,EAASxW,KAAKyW,EAAgB,EAAAE,cAC1BH,EAASI,IACX,MAAM,IAAIpY,MAAMgY,EAASK,KAG3BrC,GAAO+B,EAAKO,QACZvX,EAAOrB,GAAKsY,EAASX,OACrB3R,GAAa3E,EAAOrB,GAAGC,OACvBD,GAAK,C,OACEqY,EAAKQ,UAEd,MAAMlB,EAAS,IAAImB,WAAW9S,GAC9B,IAAK,IAAIhG,EAAI,EAAGI,EAAS,EAAGJ,EAAIqB,EAAOpB,OAAQD,IAC7C2X,EAAO5B,IAAI1U,EAAOrB,GAAII,GACtBA,GAAUiB,EAAOrB,GAAGC,OAEtB,OAAO,EAAAyS,OAAOqE,KAAKY,E,CACnB,MAAO/R,GAEP,GAAI,GAAGA,IAAI2H,MAAM,0BACf,MAAM,IAAIjN,MACR,4DAGJ,MAAMsF,C,CAEV,CAgDAgM,eAAemH,EAAgBX,EAAmBvW,GAChD,IACE,IAAIwW,EACJ,MAAM,KAAE7X,EAAI,KAAEC,GAASoB,EACvB,IAAImX,EAAOxY,EAAKhB,cACZyZ,EAAOzY,EAAKf,aAChB,MAAM4B,EAAS,GACTyQ,EAAa,GACbC,EAAa,GAEnB,IAAI/L,EAAY,EACZhG,EAAI,EACR,EAAG,CACD,MAAMuY,EAAiBH,EAAU3P,SAASuQ,EAAOxY,EAAKhB,eAChD8Y,EAAW,IAAI,EAAAE,QAIrB,KAFIH,QAASC,GACbA,EAASxW,KAAKyW,EAAgB,EAAAE,cAC1BH,EAASI,IACX,MAAM,IAAIpY,MAAMgY,EAASK,KAG3B,MAAMjQ,EAAS4P,EAASX,OACxBtW,EAAOS,KAAK4G,GACZ,IAAIoG,EAAMpG,EAAOzI,OAEjB6R,EAAWhQ,KAAKkX,GAChBjH,EAAWjQ,KAAKmX,GACM,IAAlB5X,EAAOpB,QAAgBO,EAAKf,eAE9B4B,EAAO,GAAKA,EAAO,GAAGoH,SAASjI,EAAKf,cACpCqP,EAAMzN,EAAO,GAAGpB,QAElB,MAAMiZ,EAAWF,EAIjB,GAHAA,GAAQX,EAAKO,QACbK,GAAQnK,EAEJoK,GAAYzY,EAAKjB,cAAe,CAKlC6B,EAAOrB,GAAKqB,EAAOrB,GAAGyI,SACpB,EACAhI,EAAKjB,gBAAkBgB,EAAKhB,cACxBiB,EAAKhB,aAAee,EAAKf,aAAe,EACxCgB,EAAKhB,aAAe,GAG1BqS,EAAWhQ,KAAKkX,GAChBjH,EAAWjQ,KAAKmX,GAChBjT,GAAa3E,EAAOrB,GAAGC,OACvB,K,CAEF+F,GAAa3E,EAAOrB,GAAGC,OACvBD,G,OACOqY,EAAKQ,UAEd,MAAMlB,EAAS,IAAImB,WAAW9S,GAC9B,IAAK,IAAIhG,EAAI,EAAGI,EAAS,EAAGJ,EAAIqB,EAAOpB,OAAQD,IAC7C2X,EAAO5B,IAAI1U,EAAOrB,GAAII,GACtBA,GAAUiB,EAAOrB,GAAGC,OAItB,MAAO,CAAEyI,OAFM,EAAAgK,OAAOqE,KAAKY,GAEV7F,aAAYC,a,CAC7B,MAAOnM,GAEP,GAAI,GAAGA,IAAI2H,MAAM,0BACf,MAAM,IAAIjN,MACR,4DAGJ,MAAMsF,C,CAEV,C,wBC5Ke,MAAMuT,EAKnB,WAAA5Z,EAAY,WACVqE,EAAU,KACVwV,IAKA,GAAIxV,EACFlE,KAAKkE,WAAaA,MACb,KAAIwV,EAGT,MAAM,IAAIC,UAAU,6CAFpB3Z,KAAKkE,WAAa,IAAI,KAAUwV,E,CAIpC,CAEA,qBAAAE,CAAsBvK,EAAa3O,EAAS,EAAGmZ,GAAW,GAExD,MAAMpX,EAAO,gBAAiB4M,EAAIlM,MAAMzC,EAAQA,EAAS,GAAImZ,GAC7D,GACEpX,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBAErB,MAAM,IAAI6W,UAAU,oBAGtB,OAAOlX,EAAKM,UACd,CAEA,SAAA+W,GAIE,OAHK9Z,KAAKyS,QACRzS,KAAKyS,MAAQzS,KAAK+Z,cAEb/Z,KAAKyS,KACd,CAEA,gBAAMsH,GACJ,IAAI1K,EAAM,EAAA2D,OAAOgH,YAAY,SACvBha,KAAKkE,WAAW4M,KAAKzB,EAAK,EAAG,EAAG,GACtC,MAAM4K,EAAaja,KAAK4Z,sBAAsBvK,EAAK,GAAG,GACtD,IAAK4K,EACH,MAAO,CAAC,CAAC,EAAG,IAGd,MAAMtE,EAAU,IAAI1S,MAAMgX,EAAa,GACvCtE,EAAQ,GAAK,CAAC,EAAG,GAGjB,MAAMuE,EAAU,GAAQD,EACxB,GAAIC,EAAUvX,OAAOC,iBACnB,MAAM,IAAI+W,UAAU,oBAEtBtK,EAAM,EAAA2D,OAAOgH,YAAYE,SACnBla,KAAKkE,WAAW4M,KAAKzB,EAAK,EAAG6K,EAAS,GAC5C,IAAK,IAAIC,EAAc,EAAGA,EAAcF,EAAYE,GAAe,EAAG,CACpE,MAAMC,EAAqBpa,KAAK4Z,sBAC9BvK,EACc,GAAd8K,GAEIE,EAAuBra,KAAK4Z,sBAChCvK,EACc,GAAd8K,EAAmB,GAErBxE,EAAQwE,EAAc,GAAK,CAACC,EAAoBC,E,CAGlD,OAAO1E,CACT,CAEA,kBAAM2E,GACJ,MAAM3E,QAAgB3V,KAAK8Z,YAC3B,GAAKnE,EAAQpV,OAGb,OAAOoV,EAAQA,EAAQpV,OAAS,EAClC,CAEA,8BAAMga,CAAyBha,EAAgBkW,GAC7C,MAAM+D,EAAc/D,EAAWlW,EAC/B,GAAe,IAAXA,EACF,MAAO,GAET,MAAMoV,QAAgB3V,KAAK8Z,YACrBW,EAAW,GAIXC,EAAU,CAACC,EAAYC,KAC3B,MAAMP,EAAuBM,EA/FL,GAgGlBE,EAA2BD,EAC7BA,EAjGoB,GAkGpBE,IAEJ,OACET,GAAwB5D,GACxBoE,EAA2BpE,EAEpB,EAGL4D,EAAuB5D,GACjB,EAGH,CAAC,EAGV,IAAIsE,EAAa,EACbC,EAAarF,EAAQpV,OAAS,EAC9B0a,EAAiB5T,KAAKS,MAAM6N,EAAQpV,OAAS,GAE7C2a,EAAaR,EACf/E,EAAQsF,GACRtF,EAAQsF,EAAiB,IAE3B,KAAsB,IAAfC,GACDA,EAAa,EACfF,EAAaC,EAAiB,EACrBC,EAAa,IACtBH,EAAaE,EAAiB,GAEhCA,EAAiB5T,KAAK8T,MAAMH,EAAaD,GAAc,GAAKA,EAC5DG,EAAaR,EAAQ/E,EAAQsF,GAAiBtF,EAAQsF,EAAiB,IAIzER,EAASrY,KAAKuT,EAAQsF,IACtB,IAAI3a,EAAI2a,EAAiB,EACzB,KAAO3a,EAAIqV,EAAQpV,SACjBka,EAASrY,KAAKuT,EAAQrV,MAClBqV,EAAQrV,GAzIY,IAyIiBka,IAFhBla,GAAK,GAShC,OAHIma,EAASA,EAASla,OAAS,GA7IL,GA6IiCia,GACzDC,EAASrY,KAAK,IAETqY,CACT,EC/Ia,MAAMW,EAInB,WAAAvb,EAAY,WACVqE,EAAU,KACVwV,EAAI,cACJ2B,EAAa,QACbC,IAOA,GAAIpX,EACFlE,KAAKkE,WAAaA,MACb,KAAIwV,EAGT,MAAM,IAAIC,UAAU,6CAFpB3Z,KAAKkE,WAAa,IAAI,KAAUwV,E,CAKlC,IAAK2B,IAAkBC,IAAY5B,EACjC,MAAM,IAAIC,UAAU,mDAGtB3Z,KAAKub,IAAM,IAAI9B,EAAS,CACtBvV,WAAYmX,EACZ3B,KAAO2B,GAAkBC,IAAW5B,EAAiB,GAAGA,QAAb4B,GAE/C,CAEA,UAAMvK,GACJ,MAAMyK,QAAuBxb,KAAKkE,WAAW6M,OAC7C,OAAO5F,OAAOsQ,OAAOD,EAAgB,CACnC3H,WAAY7T,KAAK0b,0BACjBC,YAAQva,EACRwa,aAASxa,GAEb,CAEA,6BAAMsa,GAGJ,MAAO,CAAErB,SAA8Bra,KAAKub,IAAIjB,gBAE1C,KAAEzG,SAAe7T,KAAKkE,WAAW6M,OAEjC1B,EAAM,EAAA2D,OAAOgH,YAAY,IAGzB,UAAE9G,SAAoBlT,KAAKkE,WAAW4M,KAAKzB,EAAK,EAAG,EAAGwE,EAAO,GAAK,GACxE,GAAkB,IAAdX,EACF,MAAM,IAAItS,MAAM,cAGlB,OAAOyZ,EAD2BhL,EAAIzK,aAAa,EAErD,CAEA,6BAAMiX,CACJC,GACC1B,IACA2B,IAED,IAAIC,EAAOD,EACNC,IACHA,SAAchc,KAAKkE,WAAW6M,QAAQ8C,MAIxC,MAAMoI,EAAwBD,EAAO5B,EAcrC,aAZMpa,KAAKkE,WAAW4M,KACpBgL,EACA,EACAG,EACA7B,SAI2BnR,EAC3B6S,EAAY3Y,MAAM,EAAG8Y,GAIzB,CAEA,UAAMnL,CAAKzB,EAAa3O,EAAgBH,EAAgBkW,GAEtD,MAAMyF,QAAuBlc,KAAKub,IAAIhB,yBACpCha,EACAkW,GAEIqF,EAAc,EAAA9I,OAAOgH,YAAY,OAEvC,IAAImC,EAAoBzb,EACpBwS,EAAY,EAChB,IACE,IAAIkJ,EAAW,EACfA,EAAWF,EAAe3b,OAAS,EACnC6b,GAAY,EACZ,CAEA,MAAMC,QAA2Brc,KAAK6b,wBACpCC,EACAI,EAAeE,GACfF,EAAeE,EAAW,KAErB,CAAE/B,GAAwB6B,EAAeE,GAC1CE,EACJjC,GAAwB5D,EAAW,EAAIA,EAAW4D,EAC9CkC,EACJlV,KAAKjH,IACHqW,EAAWlW,EACX8Z,EAAuBgC,EAAmB9b,QACxC8Z,EACFiC,GAAgB,GAAKA,EAAeD,EAAmB9b,SACzD8b,EAAmBG,KAAKnN,EAAK8M,EAAmBG,EAAcC,GAC9DJ,GAAqBI,EAAYD,EACjCpJ,GAAaqJ,EAAYD,E,CAI7B,MAAO,CAAEpJ,YAAWlK,OAAQqG,EAC9B,E,wBCnIF,IAAIoN,EAAmBzc,MAAQA,KAAKyc,iBAAoB,SAAUC,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,EACxD,EACAvR,OAAOyR,eAAeC,EAAS,aAAc,CAAE9P,OAAO,IACtD,MAAM+P,EAA6B,EAAQ,OACrCC,EAA6BN,EAAgB,EAAQ,QACrDO,EAA4BP,EAAgB,EAAQ,QAC1D,MAAMQ,EACF,WAAApd,EAAY,KAAEoS,EAAI,MAAEF,IAChB,GAAoB,mBAATE,EACP,MAAM,IAAI0H,UAAU,6BAExB,GAAqB,iBAAV5H,EACP,MAAM,IAAI4H,UAAU,4BAExB,GAAyB,mBAAd5H,EAAMxH,KACQ,mBAAdwH,EAAMsE,KACW,mBAAjBtE,EAAMmL,OACb,MAAM,IAAIvD,UAAU,qEAExB3Z,KAAK+R,MAAQA,EACb/R,KAAKmd,aAAelL,CACxB,CACA,uBAAOmL,CAAiBC,GACpB,MAEmB,eAAnBA,EAAU/Q,MAGa,gBAAnB+Q,EAAUnI,MAEY,wBAAtBmI,EAAUC,SAEY,mBAAtBD,EAAUC,OAClB,CACA,KAAAC,CAAMC,EAAK7C,GACH3a,KAAK+R,MAAMxH,IAAIiT,KAAS7C,GACxB3a,KAAK+R,MAAMmL,OAAOM,EAE1B,CACA,IAAAvL,CAAKuL,EAAKzT,EAAMoI,EAAQsL,GACpB,MAAMC,EAAU,IAAIX,EAA2BY,QACzCC,EAAiB,IAAIZ,EAA0BW,QACrDC,EAAeC,YAAYJ,GAC3B,MAAMK,EAAW,CACbJ,QAASA,EACTK,QAAS/d,KAAKmd,aAAapT,EAAM2T,EAAQvL,QAASmL,IAC9CM,EAAeI,SAASV,EAAQ,IAEpCW,SAAS,EACTL,iBACA,WAAI5I,GACA,OAAOhV,KAAK0d,QAAQvL,OAAO6C,OAC/B,GAEJ8I,EAASJ,QAAQQ,UAAU/L,GAE3B2L,EAASJ,QAAQvL,OAAOgM,iBAAiB,SAAS,KACzCL,EAASG,SACVje,KAAKud,MAAMC,EAAKM,EACpB,IAGJA,EAASC,QACJK,MAAK,KACNN,EAASG,SAAU,CAAI,IACxB,KACCH,EAASG,SAAU,EAEnBje,KAAKud,MAAMC,EAAKM,EAAS,IAExBrW,OAAMvB,IAIP,MADAuH,QAAQ4Q,MAAMnY,GACRA,CAAC,IAEXlG,KAAK+R,MAAMsE,IAAImH,EAAKM,EACxB,CACA,yBAAOQ,CAAmBP,EAAS5L,GAI/B,SAASoM,IACL,GAAIpM,GAAUA,EAAO6C,QACjB,MAAM7J,OAAOsQ,OAAO,IAAI7a,MAAM,WAAY,CAAEsU,KAAM,eAE1D,CACA,OAAO6I,EAAQK,MAAKnG,IAChBsG,IACOtG,KACRoG,IAEC,MADAE,IACMF,CAAK,GAEnB,CACA,GAAAjI,CAAIoH,GACA,OAAOxd,KAAK+R,MAAMqE,IAAIoH,EAC1B,CAaA,GAAAjT,CAAIiT,EAAKzT,EAAMoI,EAAQsL,GACnB,IAAKtL,GAAUpI,aAAgB+S,EAA2B0B,YACtD,MAAM,IAAI7E,UAAU,yGAExB,MAAM8E,EAAaze,KAAK+R,MAAMxH,IAAIiT,GAClC,OAAIiB,EACIA,EAAWzJ,UAAYyJ,EAAWR,SAElCje,KAAKud,MAAMC,EAAKiB,GACTze,KAAKuK,IAAIiT,EAAKzT,EAAMoI,EAAQsL,IAEnCgB,EAAWR,QAEJQ,EAAWV,SAItBU,EAAWf,QAAQQ,UAAU/L,GAC7BsM,EAAWb,eAAeC,YAAYJ,GAC/BR,EAAsBqB,mBAAmBG,EAAWV,QAAS5L,KAGxEnS,KAAKiS,KAAKuL,EAAKzT,EAAMoI,EAAQsL,GACtBR,EAAsBqB,mBAG7Bte,KAAK+R,MAAMxH,IAAIiT,GAAKO,QAAS5L,GACjC,CAOA,OAAOqL,GACH,MAAMkB,EAAc1e,KAAK+R,MAAMxH,IAAIiT,GAC/BkB,IACKA,EAAYT,SACbS,EAAYhB,QAAQiB,QAExB3e,KAAK+R,MAAMmL,OAAOM,GAE1B,CAKA,KAAAoB,GAEI,MAAMC,EAAU7e,KAAK+R,MAAM3G,OAC3B,IAAI0T,EAAc,EAClB,IAAK,IAAI7G,EAAS4G,EAAQ7C,QAAS/D,EAAOrD,KAAMqD,EAAS4G,EAAQ7C,OAC7Dhc,KAAKkd,OAAOjF,EAAOlL,OACnB+R,GAAe,EAEnB,OAAOA,CACX,EAEJjC,EAAA,QAAkBI,C,kBCzKlB9R,OAAOyR,eAAeC,EAAS,aAAc,CAAE9P,OAAO,IACtD,MAAM+P,EAA6B,EAAQ,OAC3C,MAAMiC,GAgDNlC,EAAA,QA1CA,MACI,WAAAhd,GACIG,KAAKgf,QAAU,IAAIC,IACnBjf,KAAKkf,gBAAkB,IAAIpC,EAA2BqC,eAC1D,CAOA,SAAAjB,CAAU/L,EAAS,IAAI4M,GACnB,GAAI/e,KAAKmS,OAAO6C,QACZ,MAAM,IAAIpU,MAAM,yCAIpBZ,KAAKgf,QAAQI,IAAIjN,GACbA,EAAO6C,QAGPhV,KAAKqf,cAAclN,GAEqB,mBAA5BA,EAAOgM,kBACnBhM,EAAOgM,iBAAiB,SAAS,KAC7Bne,KAAKqf,cAAclN,EAAO,GAGtC,CACA,aAAAkN,CAAclN,GACVnS,KAAKgf,QAAQ9B,OAAO/K,GACM,IAAtBnS,KAAKgf,QAAQnL,MACb7T,KAAKkf,gBAAgBP,OAE7B,CACA,UAAIxM,GACA,OAAOnS,KAAKkf,gBAAgB/M,MAChC,CACA,KAAAwM,GACI3e,KAAKkf,gBAAgBP,OACzB,E,gBChDJxT,OAAOyR,eAAeC,EAAS,aAAc,CAAE9P,OAAO,IAgBtD8P,EAAA,QAfA,MACI,WAAAhd,GACIG,KAAKsf,UAAY,IAAIL,GACzB,CACA,WAAApB,CAAYG,EAAW,UACnBhe,KAAKsf,UAAUF,IAAIpB,GACnBA,EAAShe,KAAKuf,eAClB,CACA,QAAAvB,CAASV,GACLtd,KAAKuf,eAAiBjC,EACtBtd,KAAKsf,UAAUE,SAAQ5H,IACnBA,EAAI0F,EAAQ,GAEpB,E,kBCbJnS,OAAOyR,eAAeC,EAAS,aAAc,CAAE9P,OAAO,IACtD8P,EAAQ2B,YAAc3B,EAAQsC,qBAAkB,EAChD,MAAMM,EAAiB,EAAQ,OAC/B,IAAIC,EAAY,WAIZ,GAAoB,oBAATC,KACP,OAAOA,KAEX,GAAsB,oBAAXC,OACP,OAAOA,OAEX,QAAsB,IAAX,EAAAC,EACP,OAAO,EAAAA,EAEX,MAAM,IAAIjf,MAAM,iCACpB,EAEA,IAAIue,OAAyD,IAAhCO,IAAYP,gBAAkCM,EAAeN,gBAAkBO,IAAYP,gBACxHtC,EAAQsC,gBAAkBA,EAE1B,IAAIX,OAAqD,IAAhCkB,IAAYP,gBAAkCM,EAAejB,YAAckB,IAAYlB,YAChH3B,EAAQ2B,YAAcA,C,uBCxBtB,IAAI/B,EAAmBzc,MAAQA,KAAKyc,iBAAoB,SAAUC,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,EACxD,EACAvR,OAAOyR,eAAeC,EAAS,aAAc,CAAE9P,OAAO,IACtD,MAAM+S,EAA0BrD,EAAgB,EAAQ,QACxDI,EAAA,QAAkBiD,EAAwBnC,O","sources":["../../../node_modules/@gmod/bam/src/virtualOffset.ts","../../../node_modules/@gmod/bam/src/chunk.ts","../../../node_modules/@gmod/bam/src/util.ts","../../../node_modules/@gmod/bam/src/indexFile.ts","../../../node_modules/@gmod/bam/src/bai.ts","../../../node_modules/@gmod/bam/src/csi.ts","../../../node_modules/@gmod/bam/src/constants.ts","../../../node_modules/@gmod/bam/src/record.ts","../../../node_modules/@gmod/bam/src/sam.ts","../../../node_modules/@gmod/bam/src/bamFile.ts","../../../node_modules/@gmod/bam/src/htsget.ts","../../../node_modules/@gmod/bgzf-filehandle/src/unzip-pako.ts","../../../node_modules/@gmod/bgzf-filehandle/src/gziIndex.ts","../../../node_modules/@gmod/bgzf-filehandle/src/bgzFilehandle.ts","../../../node_modules/abortable-promise-cache/esm/AbortablePromiseCache.js","../../../node_modules/abortable-promise-cache/esm/AggregateAbortController.js","../../../node_modules/abortable-promise-cache/esm/AggregateStatusReporter.js","../../../node_modules/abortable-promise-cache/esm/abortcontroller-ponyfill.js","../../../node_modules/abortable-promise-cache/esm/index.js"],"sourcesContent":["export default class VirtualOffset {\n  public blockPosition: number\n  public dataPosition: number\n  constructor(blockPosition: number, dataPosition: number) {\n    this.blockPosition = blockPosition // < offset of the compressed data block\n    this.dataPosition = dataPosition // < offset into the uncompressed data\n  }\n\n  toString() {\n    return `${this.blockPosition}:${this.dataPosition}`\n  }\n\n  compareTo(b: VirtualOffset) {\n    return (\n      this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition\n    )\n  }\n\n  static min(...args: VirtualOffset[]) {\n    let min\n    let i = 0\n    for (; !min; i += 1) {\n      min = args[i]\n    }\n    for (; i < args.length; i += 1) {\n      if (min.compareTo(args[i]) > 0) {\n        min = args[i]\n      }\n    }\n    return min\n  }\n}\nexport function fromBytes(bytes: Buffer, offset = 0, bigendian = false) {\n  if (bigendian) {\n    throw new Error('big-endian virtual file offsets not implemented')\n  }\n\n  return new VirtualOffset(\n    bytes[offset + 7] * 0x10000000000 +\n      bytes[offset + 6] * 0x100000000 +\n      bytes[offset + 5] * 0x1000000 +\n      bytes[offset + 4] * 0x10000 +\n      bytes[offset + 3] * 0x100 +\n      bytes[offset + 2],\n    (bytes[offset + 1] << 8) | bytes[offset],\n  )\n}\n","import VirtualOffset from './virtualOffset'\n\n// little class representing a chunk in the index\nexport default class Chunk {\n  public buffer?: Buffer\n\n  constructor(\n    public minv: VirtualOffset,\n    public maxv: VirtualOffset,\n    public bin: number,\n    public _fetchedSize?: number,\n  ) {}\n\n  toUniqueString() {\n    return `${this.minv}..${this.maxv} (bin ${\n      this.bin\n    }, fetchedSize ${this.fetchedSize()})`\n  }\n\n  toString() {\n    return this.toUniqueString()\n  }\n\n  compareTo(b: Chunk) {\n    return (\n      this.minv.compareTo(b.minv) ||\n      this.maxv.compareTo(b.maxv) ||\n      this.bin - b.bin\n    )\n  }\n\n  fetchedSize() {\n    if (this._fetchedSize !== undefined) {\n      return this._fetchedSize\n    }\n    return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition\n  }\n}\n","import Long from 'long'\nimport Chunk from './chunk'\nimport VirtualOffset from './virtualOffset'\n\nexport function timeout(ms: number) {\n  return new Promise(resolve => setTimeout(resolve, ms))\n}\n\nexport function longToNumber(long: Long) {\n  if (\n    long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n    long.lessThan(Number.MIN_SAFE_INTEGER)\n  ) {\n    throw new Error('integer overflow')\n  }\n  return long.toNumber()\n}\n\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nexport function checkAbortSignal(signal?: AbortSignal) {\n  if (!signal) {\n    return\n  }\n\n  if (signal.aborted) {\n    // console.log('bam aborted!')\n    if (typeof DOMException === 'undefined') {\n      const e = new Error('aborted')\n      //@ts-ignore\n      e.code = 'ERR_ABORTED'\n      throw e\n    } else {\n      throw new DOMException('aborted', 'AbortError')\n    }\n  }\n}\n\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nexport async function abortBreakPoint(signal?: AbortSignal) {\n  await Promise.resolve()\n  checkAbortSignal(signal)\n}\n\nexport function canMergeBlocks(chunk1: Chunk, chunk2: Chunk) {\n  return (\n    chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n    chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000\n  )\n}\n\nexport interface BamOpts {\n  viewAsPairs?: boolean\n  pairAcrossChr?: boolean\n  maxInsertSize?: number\n  signal?: AbortSignal\n}\n\nexport interface BaseOpts {\n  signal?: AbortSignal\n}\n\nexport function makeOpts(obj: AbortSignal | BaseOpts = {}): BaseOpts {\n  return 'aborted' in obj ? ({ signal: obj } as BaseOpts) : (obj as BaseOpts)\n}\n\nexport function optimizeChunks(chunks: Chunk[], lowest?: VirtualOffset) {\n  const mergedChunks: Chunk[] = []\n  let lastChunk: Chunk | undefined\n\n  if (chunks.length === 0) {\n    return chunks\n  }\n\n  chunks.sort((c0, c1) => {\n    const dif = c0.minv.blockPosition - c1.minv.blockPosition\n    return dif === 0 ? c0.minv.dataPosition - c1.minv.dataPosition : dif\n  })\n\n  for (const chunk of chunks) {\n    if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n      if (lastChunk === undefined) {\n        mergedChunks.push(chunk)\n        lastChunk = chunk\n      } else {\n        if (canMergeBlocks(lastChunk, chunk)) {\n          if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n            lastChunk.maxv = chunk.maxv\n          }\n        } else {\n          mergedChunks.push(chunk)\n          lastChunk = chunk\n        }\n      }\n    }\n  }\n\n  return mergedChunks\n}\n\nexport function parsePseudoBin(bytes: Buffer, offset: number) {\n  const lineCount = longToNumber(\n    Long.fromBytesLE(\n      Array.prototype.slice.call(bytes, offset, offset + 8),\n      true,\n    ),\n  )\n  return { lineCount }\n}\n\nexport function findFirstData(\n  firstDataLine: VirtualOffset | undefined,\n  virtualOffset: VirtualOffset,\n) {\n  return firstDataLine\n    ? firstDataLine.compareTo(virtualOffset) > 0\n      ? virtualOffset\n      : firstDataLine\n    : virtualOffset\n}\n\nexport function parseNameBytes(\n  namesBytes: Buffer,\n  renameRefSeq: (arg: string) => string = s => s,\n) {\n  let currRefId = 0\n  let currNameStart = 0\n  const refIdToName = []\n  const refNameToId: { [key: string]: number } = {}\n  for (let i = 0; i < namesBytes.length; i += 1) {\n    if (!namesBytes[i]) {\n      if (currNameStart < i) {\n        let refName = namesBytes.toString('utf8', currNameStart, i)\n        refName = renameRefSeq(refName)\n        refIdToName[currRefId] = refName\n        refNameToId[refName] = currRefId\n      }\n      currNameStart = i + 1\n      currRefId += 1\n    }\n  }\n  return { refNameToId, refIdToName }\n}\n","import { GenericFilehandle } from 'generic-filehandle'\nimport Chunk from './chunk'\nimport { BaseOpts } from './util'\n\nexport default abstract class IndexFile {\n  public filehandle: GenericFilehandle\n  public renameRefSeq: (s: string) => string\n\n  /**\n   * @param {filehandle} filehandle\n   * @param {function} [renameRefSeqs]\n   */\n  constructor({\n    filehandle,\n    renameRefSeq = (n: string) => n,\n  }: {\n    filehandle: GenericFilehandle\n    renameRefSeq?: (a: string) => string\n  }) {\n    this.filehandle = filehandle\n    this.renameRefSeq = renameRefSeq\n  }\n  public abstract lineCount(refId: number): Promise<number>\n  public abstract indexCov(\n    refId: number,\n    start?: number,\n    end?: number,\n  ): Promise<{ start: number; end: number; score: number }[]>\n\n  public abstract blocksForRange(\n    chrId: number,\n    start: number,\n    end: number,\n    opts?: BaseOpts,\n  ): Promise<Chunk[]>\n}\n","import VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\n\nimport { optimizeChunks, parsePseudoBin, findFirstData, BaseOpts } from './util'\nimport IndexFile from './indexFile'\n\nconst BAI_MAGIC = 21578050 // BAI\\1\n\nfunction roundDown(n: number, multiple: number) {\n  return n - (n % multiple)\n}\nfunction roundUp(n: number, multiple: number) {\n  return n - (n % multiple) + multiple\n}\n\nfunction reg2bins(beg: number, end: number) {\n  end -= 1\n  return [\n    [0, 0],\n    [1 + (beg >> 26), 1 + (end >> 26)],\n    [9 + (beg >> 23), 9 + (end >> 23)],\n    [73 + (beg >> 20), 73 + (end >> 20)],\n    [585 + (beg >> 17), 585 + (end >> 17)],\n    [4681 + (beg >> 14), 4681 + (end >> 14)],\n  ]\n}\n\nexport default class BAI extends IndexFile {\n  public setupP?: ReturnType<BAI['_parse']>\n\n  async lineCount(refId: number, opts?: BaseOpts) {\n    const indexData = await this.parse(opts)\n    return indexData.indices[refId]?.stats?.lineCount || 0\n  }\n\n  // fetch and parse the index\n  async _parse(opts?: BaseOpts) {\n    const bytes = (await this.filehandle.readFile(opts)) as Buffer\n\n    // check BAI magic numbers\n    if (bytes.readUInt32LE(0) !== BAI_MAGIC) {\n      throw new Error('Not a BAI file')\n    }\n\n    const refCount = bytes.readInt32LE(4)\n    const depth = 5\n    const binLimit = ((1 << ((depth + 1) * 3)) - 1) / 7\n\n    // read the indexes for each reference sequence\n    let curr = 8\n    let firstDataLine: VirtualOffset | undefined\n\n    type BinIndex = { [key: string]: Chunk[] }\n    type LinearIndex = VirtualOffset[]\n    const indices = new Array<{\n      binIndex: BinIndex\n      linearIndex: LinearIndex\n      stats?: { lineCount: number }\n    }>(refCount)\n    for (let i = 0; i < refCount; i++) {\n      // the binning index\n      const binCount = bytes.readInt32LE(curr)\n      let stats\n\n      curr += 4\n      const binIndex: { [key: number]: Chunk[] } = {}\n\n      for (let j = 0; j < binCount; j += 1) {\n        const bin = bytes.readUInt32LE(curr)\n        curr += 4\n        if (bin === binLimit + 1) {\n          curr += 4\n          stats = parsePseudoBin(bytes, curr + 16)\n          curr += 32\n        } else if (bin > binLimit + 1) {\n          throw new Error('bai index contains too many bins, please use CSI')\n        } else {\n          const chunkCount = bytes.readInt32LE(curr)\n          curr += 4\n          const chunks = new Array<Chunk>(chunkCount)\n          for (let k = 0; k < chunkCount; k++) {\n            const u = fromBytes(bytes, curr)\n            curr += 8\n            const v = fromBytes(bytes, curr)\n            curr += 8\n            firstDataLine = findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      const linearCount = bytes.readInt32LE(curr)\n      curr += 4\n      // as we're going through the linear index, figure out the smallest\n      // virtual offset in the indexes, which tells us where the BAM header\n      // ends\n      const linearIndex = new Array<VirtualOffset>(linearCount)\n      for (let j = 0; j < linearCount; j++) {\n        const offset = fromBytes(bytes, curr)\n        curr += 8\n        firstDataLine = findFirstData(firstDataLine, offset)\n        linearIndex[j] = offset\n      }\n\n      indices[i] = { binIndex, linearIndex, stats }\n    }\n\n    return {\n      bai: true,\n      firstDataLine,\n      maxBlockSize: 1 << 16,\n      indices,\n      refCount,\n    }\n  }\n\n  async indexCov(\n    seqId: number,\n    start?: number,\n    end?: number,\n    opts: BaseOpts = {},\n  ): Promise<{ start: number; end: number; score: number }[]> {\n    const v = 16384\n    const range = start !== undefined\n    const indexData = await this.parse(opts)\n    const seqIdx = indexData.indices[seqId]\n    if (!seqIdx) {\n      return []\n    }\n    const { linearIndex = [], stats } = seqIdx\n    if (linearIndex.length === 0) {\n      return []\n    }\n    const e = end === undefined ? (linearIndex.length - 1) * v : roundUp(end, v)\n    const s = start === undefined ? 0 : roundDown(start, v)\n    const depths = range\n      ? new Array((e - s) / v)\n      : new Array(linearIndex.length - 1)\n    const totalSize = linearIndex[linearIndex.length - 1].blockPosition\n    if (e > (linearIndex.length - 1) * v) {\n      throw new Error('query outside of range of linear index')\n    }\n    let currentPos = linearIndex[s / v].blockPosition\n    for (let i = s / v, j = 0; i < e / v; i++, j++) {\n      depths[j] = {\n        score: linearIndex[i + 1].blockPosition - currentPos,\n        start: i * v,\n        end: i * v + v,\n      }\n      currentPos = linearIndex[i + 1].blockPosition\n    }\n    return depths.map(d => ({\n      ...d,\n      score: (d.score * (stats?.lineCount || 0)) / totalSize,\n    }))\n  }\n\n  async blocksForRange(\n    refId: number,\n    min: number,\n    max: number,\n    opts: BaseOpts = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    if (!indexData) {\n      return []\n    }\n    const ba = indexData.indices[refId]\n    if (!ba) {\n      return []\n    }\n\n    // List of bin #s that overlap min, max\n    const overlappingBins = reg2bins(min, max)\n    const chunks: Chunk[] = []\n\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          const binChunks = ba.binIndex[bin]\n          for (const binChunk of binChunks) {\n            chunks.push(binChunk)\n          }\n        }\n      }\n    }\n\n    // Use the linear index to find minimum file position of chunks that could\n    // contain alignments in the region\n    const nintv = ba.linearIndex.length\n    let lowest: VirtualOffset | undefined\n    const minLin = Math.min(min >> 14, nintv - 1)\n    const maxLin = Math.min(max >> 14, nintv - 1)\n    for (let i = minLin; i <= maxLin; ++i) {\n      const vp = ba.linearIndex[i]\n      if (vp && (!lowest || vp.compareTo(lowest) < 0)) {\n        lowest = vp\n      }\n    }\n\n    return optimizeChunks(chunks, lowest)\n  }\n\n  async parse(opts: BaseOpts = {}) {\n    if (!this.setupP) {\n      this.setupP = this._parse(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async hasRefSeq(seqId: number, opts: BaseOpts = {}) {\n    const header = await this.parse(opts)\n    return !!header.indices[seqId]?.binIndex\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\nimport VirtualOffset, { fromBytes } from './virtualOffset'\nimport Chunk from './chunk'\nimport {\n  optimizeChunks,\n  findFirstData,\n  parsePseudoBin,\n  parseNameBytes,\n  BaseOpts,\n} from './util'\n\nimport IndexFile from './indexFile'\n\nconst CSI1_MAGIC = 21582659 // CSI\\1\nconst CSI2_MAGIC = 38359875 // CSI\\2\n\nfunction lshift(num: number, bits: number) {\n  return num * 2 ** bits\n}\nfunction rshift(num: number, bits: number) {\n  return Math.floor(num / 2 ** bits)\n}\n\nexport default class CSI extends IndexFile {\n  private maxBinNumber = 0\n  private depth = 0\n  private minShift = 0\n\n  public setupP?: ReturnType<CSI['_parse']>\n\n  async lineCount(refId: number, opts?: BaseOpts) {\n    const indexData = await this.parse(opts)\n    return indexData.indices[refId]?.stats?.lineCount || 0\n  }\n\n  async indexCov() {\n    return []\n  }\n\n  parseAuxData(bytes: Buffer, offset: number) {\n    const formatFlags = bytes.readInt32LE(offset)\n    const coordinateType =\n      formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed'\n    const format = (\n      { 0: 'generic', 1: 'SAM', 2: 'VCF' } as {\n        [key: number]: string\n      }\n    )[formatFlags & 0xf]\n    if (!format) {\n      throw new Error(`invalid Tabix preset format flags ${formatFlags}`)\n    }\n    const columnNumbers = {\n      ref: bytes.readInt32LE(offset + 4),\n      start: bytes.readInt32LE(offset + 8),\n      end: bytes.readInt32LE(offset + 12),\n    }\n    const metaValue = bytes.readInt32LE(offset + 16)\n    const metaChar = metaValue ? String.fromCharCode(metaValue) : ''\n    const skipLines = bytes.readInt32LE(offset + 20)\n    const nameSectionLength = bytes.readInt32LE(offset + 24)\n\n    return {\n      columnNumbers,\n      coordinateType,\n      metaValue,\n      metaChar,\n      skipLines,\n      format,\n      formatFlags,\n      ...parseNameBytes(\n        bytes.subarray(offset + 28, offset + 28 + nameSectionLength),\n        this.renameRefSeq,\n      ),\n    }\n  }\n\n  // fetch and parse the index\n  async _parse(opts: { signal?: AbortSignal }) {\n    const buffer = await this.filehandle.readFile(opts)\n    const bytes = await unzip(buffer)\n\n    let csiVersion\n    // check TBI magic numbers\n    if (bytes.readUInt32LE(0) === CSI1_MAGIC) {\n      csiVersion = 1\n    } else if (bytes.readUInt32LE(0) === CSI2_MAGIC) {\n      csiVersion = 2\n    } else {\n      throw new Error('Not a CSI file')\n      // TODO: do we need to support big-endian CSI files?\n    }\n\n    this.minShift = bytes.readInt32LE(4)\n    this.depth = bytes.readInt32LE(8)\n    this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7\n    const auxLength = bytes.readInt32LE(12)\n    const aux = auxLength >= 30 ? this.parseAuxData(bytes, 16) : undefined\n    const refCount = bytes.readInt32LE(16 + auxLength)\n\n    type BinIndex = { [key: string]: Chunk[] }\n\n    // read the indexes for each reference sequence\n    let curr = 16 + auxLength + 4\n    let firstDataLine: VirtualOffset | undefined\n    const indices = new Array<{\n      binIndex: BinIndex\n      stats?: { lineCount: number }\n    }>(refCount)\n    for (let i = 0; i < refCount; i++) {\n      // the binning index\n      const binCount = bytes.readInt32LE(curr)\n      curr += 4\n      const binIndex: { [key: string]: Chunk[] } = {}\n      let stats // < provided by parsing a pseudo-bin, if present\n      for (let j = 0; j < binCount; j++) {\n        const bin = bytes.readUInt32LE(curr)\n        curr += 4\n        if (bin > this.maxBinNumber) {\n          stats = parsePseudoBin(bytes, curr + 28)\n          curr += 28 + 16\n        } else {\n          firstDataLine = findFirstData(firstDataLine, fromBytes(bytes, curr))\n          curr += 8\n          const chunkCount = bytes.readInt32LE(curr)\n          curr += 4\n          const chunks = new Array<Chunk>(chunkCount)\n          for (let k = 0; k < chunkCount; k += 1) {\n            const u = fromBytes(bytes, curr)\n            curr += 8\n            const v = fromBytes(bytes, curr)\n            curr += 8\n            firstDataLine = findFirstData(firstDataLine, u)\n            chunks[k] = new Chunk(u, v, bin)\n          }\n          binIndex[bin] = chunks\n        }\n      }\n\n      indices[i] = { binIndex, stats }\n    }\n\n    return {\n      csiVersion,\n      firstDataLine,\n      indices,\n      refCount,\n      csi: true,\n      maxBlockSize: 1 << 16,\n      ...aux,\n    }\n  }\n\n  async blocksForRange(\n    refId: number,\n    min: number,\n    max: number,\n    opts: BaseOpts = {},\n  ) {\n    if (min < 0) {\n      min = 0\n    }\n\n    const indexData = await this.parse(opts)\n    const ba = indexData?.indices[refId]\n    if (!ba) {\n      return []\n    }\n    const overlappingBins = this.reg2bins(min, max)\n\n    if (overlappingBins.length === 0) {\n      return []\n    }\n\n    const chunks = []\n    // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n    for (const [start, end] of overlappingBins) {\n      for (let bin = start; bin <= end; bin++) {\n        if (ba.binIndex[bin]) {\n          const binChunks = ba.binIndex[bin]\n          for (const c of binChunks) {\n            chunks.push(c)\n          }\n        }\n      }\n    }\n\n    return optimizeChunks(chunks, new VirtualOffset(0, 0))\n  }\n\n  /**\n   * calculate the list of bins that may overlap with region [beg,end)\n   * (zero-based half-open)\n   */\n  reg2bins(beg: number, end: number) {\n    beg -= 1 // < convert to 1-based closed\n    if (beg < 1) {\n      beg = 1\n    }\n    if (end > 2 ** 50) {\n      end = 2 ** 34\n    } // 17 GiB ought to be enough for anybody\n    end -= 1\n    let l = 0\n    let t = 0\n    let s = this.minShift + this.depth * 3\n    const bins = []\n    for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n      const b = t + rshift(beg, s)\n      const e = t + rshift(end, s)\n      if (e - b + bins.length > this.maxBinNumber) {\n        throw new Error(\n          `query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`,\n        )\n      }\n      bins.push([b, e])\n    }\n    return bins\n  }\n\n  async parse(opts: BaseOpts = {}) {\n    if (!this.setupP) {\n      this.setupP = this._parse(opts).catch(e => {\n        this.setupP = undefined\n        throw e\n      })\n    }\n    return this.setupP\n  }\n\n  async hasRefSeq(seqId: number, opts: BaseOpts = {}) {\n    const header = await this.parse(opts)\n    return !!header.indices[seqId]?.binIndex\n  }\n}\n","export default {\n  //  the read is paired in sequencing, no matter whether it is mapped in a pair\n  BAM_FPAIRED: 1,\n  //  the read is mapped in a proper pair\n  BAM_FPROPER_PAIR: 2,\n  //  the read itself is unmapped; conflictive with BAM_FPROPER_PAIR\n  BAM_FUNMAP: 4,\n  //  the mate is unmapped\n  BAM_FMUNMAP: 8,\n  //  the read is mapped to the reverse strand\n  BAM_FREVERSE: 16,\n  //  the mate is mapped to the reverse strand\n  BAM_FMREVERSE: 32,\n  //  this is read1\n  BAM_FREAD1: 64,\n  //  this is read2\n  BAM_FREAD2: 128,\n  //  not primary alignment\n  BAM_FSECONDARY: 256,\n  //  QC failure\n  BAM_FQCFAIL: 512,\n  //  optical or PCR duplicate\n  BAM_FDUP: 1024,\n  //  supplementary alignment\n  BAM_FSUPPLEMENTARY: 2048,\n}\n","/* eslint-disable @typescript-eslint/no-empty-function */\nimport Constants from './constants'\n\nconst SEQRET_DECODER = '=ACMGRSVTWYHKDBN'.split('')\nconst CIGAR_DECODER = 'MIDNSHP=X???????'.split('')\n\n/**\n * Class of each BAM record returned by this API.\n */\nexport default class BamRecord {\n  private data = {} as { [key: string]: any }\n  private bytes: { start: number; end: number; byteArray: Buffer }\n  private _id: number\n  private _tagOffset: number | undefined\n  private _tagList: string[] = []\n  private _allTagsParsed = false\n\n  public flags: any\n  public _refID: number\n  constructor(args: any) {\n    const { bytes, fileOffset } = args\n    const { byteArray, start } = bytes\n    this.data = {}\n    this.bytes = bytes\n    this._id = fileOffset\n    this._refID = byteArray.readInt32LE(start + 4)\n    this.data.start = byteArray.readInt32LE(start + 8)\n    this.flags = (byteArray.readInt32LE(start + 16) & 0xffff0000) >> 16\n  }\n\n  get(field: string) {\n    //@ts-ignore\n    if (this[field]) {\n      //@ts-ignore\n      if (this.data[field]) {\n        return this.data[field]\n      }\n      //@ts-ignore\n      this.data[field] = this[field]()\n      return this.data[field]\n    }\n    return this._get(field.toLowerCase())\n  }\n\n  end() {\n    return this.get('start') + this.get('length_on_ref')\n  }\n\n  seq_id() {\n    return this._refID\n  }\n\n  // same as get(), except requires lower-case arguments.  used\n  // internally to save lots of calls to field.toLowerCase()\n  _get(field: string) {\n    if (field in this.data) {\n      return this.data[field]\n    }\n    this.data[field] = this._parseTag(field)\n    return this.data[field]\n  }\n\n  _tags() {\n    this._parseAllTags()\n\n    let tags = ['seq']\n\n    if (!this.isSegmentUnmapped()) {\n      tags.push(\n        'start',\n        'end',\n        'strand',\n        'score',\n        'qual',\n        'MQ',\n        'CIGAR',\n        'length_on_ref',\n        'template_length',\n      )\n    }\n    if (this.isPaired()) {\n      tags.push('next_segment_position', 'pair_orientation')\n    }\n    tags = tags.concat(this._tagList || [])\n\n    for (const k of Object.keys(this.data)) {\n      if (k[0] !== '_' && k !== 'next_seq_id') {\n        tags.push(k)\n      }\n    }\n\n    const seen: { [key: string]: boolean } = {}\n    return tags.filter(t => {\n      if (\n        (t in this.data && this.data[t] === undefined) ||\n        t === 'CG' ||\n        t === 'cg'\n      ) {\n        return false\n      }\n\n      const lt = t.toLowerCase()\n      const s = seen[lt]\n      seen[lt] = true\n      return !s\n    })\n  }\n\n  parent() {\n    return\n  }\n\n  children() {\n    return this.get('subfeatures')\n  }\n\n  id() {\n    return this._id\n  }\n\n  // special parsers\n  /**\n   * Mapping quality score.\n   */\n  mq() {\n    const mq = (this.get('_bin_mq_nl') & 0xff00) >> 8\n    return mq === 255 ? undefined : mq\n  }\n\n  score() {\n    return this.get('mq')\n  }\n\n  qual() {\n    return this.qualRaw()?.join(' ')\n  }\n\n  qualRaw() {\n    if (this.isSegmentUnmapped()) {\n      return\n    }\n\n    const { start, byteArray } = this.bytes\n    const p =\n      start +\n      36 +\n      this.get('_l_read_name') +\n      this.get('_n_cigar_op') * 4 +\n      this.get('_seq_bytes')\n    const lseq = this.get('seq_length')\n    return byteArray.subarray(p, p + lseq)\n  }\n\n  strand() {\n    return this.isReverseComplemented() ? -1 : 1\n  }\n\n  multi_segment_next_segment_strand() {\n    if (this.isMateUnmapped()) {\n      return\n    }\n    return this.isMateReverseComplemented() ? -1 : 1\n  }\n\n  name() {\n    return this.get('_read_name')\n  }\n\n  _read_name() {\n    const nl = this.get('_l_read_name')\n    const { byteArray, start } = this.bytes\n    return byteArray.toString('ascii', start + 36, start + 36 + nl - 1)\n  }\n\n  /**\n   * Get the value of a tag, parsing the tags as far as necessary.\n   * Only called if we have not already parsed that field.\n   */\n  _parseTag(tagName?: string) {\n    // if all of the tags have been parsed and we're still being\n    // called, we already know that we have no such tag, because\n    // it would already have been cached.\n    if (this._allTagsParsed) {\n      return\n    }\n\n    const { byteArray, start } = this.bytes\n    let p =\n      this._tagOffset ||\n      start +\n        36 +\n        this.get('_l_read_name') +\n        this.get('_n_cigar_op') * 4 +\n        this.get('_seq_bytes') +\n        this.get('seq_length')\n\n    const blockEnd = this.bytes.end\n    let lcTag\n    while (p < blockEnd && lcTag !== tagName) {\n      const tag = String.fromCharCode(byteArray[p], byteArray[p + 1])\n      lcTag = tag.toLowerCase()\n      const type = String.fromCharCode(byteArray[p + 2])\n      p += 3\n\n      let value\n      switch (type) {\n        case 'A': {\n          value = String.fromCharCode(byteArray[p])\n          p += 1\n          break\n        }\n        case 'i': {\n          value = byteArray.readInt32LE(p)\n          p += 4\n          break\n        }\n        case 'I': {\n          value = byteArray.readUInt32LE(p)\n          p += 4\n          break\n        }\n        case 'c': {\n          value = byteArray.readInt8(p)\n          p += 1\n          break\n        }\n        case 'C': {\n          value = byteArray.readUInt8(p)\n          p += 1\n          break\n        }\n        case 's': {\n          value = byteArray.readInt16LE(p)\n          p += 2\n          break\n        }\n        case 'S': {\n          value = byteArray.readUInt16LE(p)\n          p += 2\n          break\n        }\n        case 'f': {\n          value = byteArray.readFloatLE(p)\n          p += 4\n          break\n        }\n        case 'Z':\n        case 'H': {\n          value = ''\n          while (p <= blockEnd) {\n            const cc = byteArray[p++]\n            if (cc === 0) {\n              break\n            } else {\n              value += String.fromCharCode(cc)\n            }\n          }\n          break\n        }\n        case 'B': {\n          value = ''\n          const cc = byteArray[p++]\n          const Btype = String.fromCharCode(cc)\n          const limit = byteArray.readInt32LE(p)\n          p += 4\n          if (Btype === 'i') {\n            if (tag === 'CG') {\n              for (let k = 0; k < limit; k++) {\n                const cigop = byteArray.readInt32LE(p)\n                const lop = cigop >> 4\n                const op = CIGAR_DECODER[cigop & 0xf]\n                value += lop + op\n                p += 4\n              }\n            } else {\n              for (let k = 0; k < limit; k++) {\n                value += byteArray.readInt32LE(p)\n                if (k + 1 < limit) {\n                  value += ','\n                }\n                p += 4\n              }\n            }\n          }\n          if (Btype === 'I') {\n            if (tag === 'CG') {\n              for (let k = 0; k < limit; k++) {\n                const cigop = byteArray.readUInt32LE(p)\n                const lop = cigop >> 4\n                const op = CIGAR_DECODER[cigop & 0xf]\n                value += lop + op\n                p += 4\n              }\n            } else {\n              for (let k = 0; k < limit; k++) {\n                value += byteArray.readUInt32LE(p)\n                if (k + 1 < limit) {\n                  value += ','\n                }\n                p += 4\n              }\n            }\n          }\n          if (Btype === 's') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readInt16LE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 2\n            }\n          }\n          if (Btype === 'S') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readUInt16LE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 2\n            }\n          }\n          if (Btype === 'c') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readInt8(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 1\n            }\n          }\n          if (Btype === 'C') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readUInt8(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 1\n            }\n          }\n          if (Btype === 'f') {\n            for (let k = 0; k < limit; k++) {\n              value += byteArray.readFloatLE(p)\n              if (k + 1 < limit) {\n                value += ','\n              }\n              p += 4\n            }\n          }\n          break\n        }\n        default: {\n          console.warn(`Unknown BAM tag type '${type}', tags may be incomplete`)\n          value = undefined\n          p = blockEnd\n        } // stop parsing tags\n      }\n\n      this._tagOffset = p\n\n      this._tagList.push(tag)\n      if (lcTag === tagName) {\n        return value\n      }\n\n      this.data[lcTag] = value\n    }\n    this._allTagsParsed = true\n    return\n  }\n\n  _parseAllTags() {\n    this._parseTag('')\n  }\n\n  _parseCigar(cigar: string) {\n    return (\n      //@ts-ignore\n      cigar\n        .match(/\\d+\\D/g)\n        //@ts-ignore\n        .map(op => [op.match(/\\D/)[0].toUpperCase(), Number.parseInt(op, 10)])\n    )\n  }\n\n  /**\n   * @returns {boolean} true if the read is paired, regardless of whether both segments are mapped\n   */\n  isPaired() {\n    return !!(this.flags & Constants.BAM_FPAIRED)\n  }\n\n  /** @returns {boolean} true if the read is paired, and both segments are mapped */\n  isProperlyPaired() {\n    return !!(this.flags & Constants.BAM_FPROPER_PAIR)\n  }\n\n  /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n  isSegmentUnmapped() {\n    return !!(this.flags & Constants.BAM_FUNMAP)\n  }\n\n  /** @returns {boolean} true if the read itself is unmapped; conflictive with isProperlyPaired */\n  isMateUnmapped() {\n    return !!(this.flags & Constants.BAM_FMUNMAP)\n  }\n\n  /** @returns {boolean} true if the read is mapped to the reverse strand */\n  isReverseComplemented() {\n    return !!(this.flags & Constants.BAM_FREVERSE)\n  }\n\n  /** @returns {boolean} true if the mate is mapped to the reverse strand */\n  isMateReverseComplemented() {\n    return !!(this.flags & Constants.BAM_FMREVERSE)\n  }\n\n  /** @returns {boolean} true if this is read number 1 in a pair */\n  isRead1() {\n    return !!(this.flags & Constants.BAM_FREAD1)\n  }\n\n  /** @returns {boolean} true if this is read number 2 in a pair */\n  isRead2() {\n    return !!(this.flags & Constants.BAM_FREAD2)\n  }\n\n  /** @returns {boolean} true if this is a secondary alignment */\n  isSecondary() {\n    return !!(this.flags & Constants.BAM_FSECONDARY)\n  }\n\n  /** @returns {boolean} true if this read has failed QC checks */\n  isFailedQc() {\n    return !!(this.flags & Constants.BAM_FQCFAIL)\n  }\n\n  /** @returns {boolean} true if the read is an optical or PCR duplicate */\n  isDuplicate() {\n    return !!(this.flags & Constants.BAM_FDUP)\n  }\n\n  /** @returns {boolean} true if this is a supplementary alignment */\n  isSupplementary() {\n    return !!(this.flags & Constants.BAM_FSUPPLEMENTARY)\n  }\n\n  cigar() {\n    if (this.isSegmentUnmapped()) {\n      return\n    }\n\n    const { byteArray, start } = this.bytes\n    const numCigarOps = this.get('_n_cigar_op')\n    let p = start + 36 + this.get('_l_read_name')\n    const seqLen = this.get('seq_length')\n    let cigar = ''\n    let lref = 0\n\n    // check for CG tag by inspecting whether the CIGAR field\n    // contains a clip that consumes entire seqLen\n    let cigop = byteArray.readInt32LE(p)\n    let lop = cigop >> 4\n    let op = CIGAR_DECODER[cigop & 0xf]\n    if (op === 'S' && lop === seqLen) {\n      // if there is a CG the second CIGAR field will\n      // be a N tag the represents the length on ref\n      p += 4\n      cigop = byteArray.readInt32LE(p)\n      lop = cigop >> 4\n      op = CIGAR_DECODER[cigop & 0xf]\n      if (op !== 'N') {\n        console.warn('CG tag with no N tag')\n      }\n      this.data.length_on_ref = lop\n      return this.get('CG')\n    } else {\n      for (let c = 0; c < numCigarOps; ++c) {\n        cigop = byteArray.readInt32LE(p)\n        lop = cigop >> 4\n        op = CIGAR_DECODER[cigop & 0xf]\n        cigar += lop + op\n\n        // soft clip, hard clip, and insertion don't count toward\n        // the length on the reference\n        if (op !== 'H' && op !== 'S' && op !== 'I') {\n          lref += lop\n        }\n\n        p += 4\n      }\n\n      this.data.length_on_ref = lref\n      return cigar\n    }\n  }\n\n  _flags() {}\n\n  length_on_ref() {\n    if (this.data.length_on_ref) {\n      return this.data.length_on_ref\n    } else {\n      this.get('cigar') // the length_on_ref is set as a side effect\n      return this.data.length_on_ref\n    }\n  }\n\n  _n_cigar_op() {\n    return this.get('_flag_nc') & 0xffff\n  }\n\n  _l_read_name() {\n    return this.get('_bin_mq_nl') & 0xff\n  }\n\n  /**\n   * number of bytes in the sequence field\n   */\n  _seq_bytes() {\n    return (this.get('seq_length') + 1) >> 1\n  }\n\n  getReadBases() {\n    return this.seq()\n  }\n\n  seq() {\n    const { byteArray, start } = this.bytes\n    const p =\n      start + 36 + this.get('_l_read_name') + this.get('_n_cigar_op') * 4\n    const seqBytes = this.get('_seq_bytes')\n    const len = this.get('seq_length')\n    let buf = ''\n    let i = 0\n    for (let j = 0; j < seqBytes; ++j) {\n      const sb = byteArray[p + j]\n      buf += SEQRET_DECODER[(sb & 0xf0) >> 4]\n      i++\n      if (i < len) {\n        buf += SEQRET_DECODER[sb & 0x0f]\n        i++\n      }\n    }\n    return buf\n  }\n\n  // adapted from igv.js\n  getPairOrientation() {\n    if (\n      !this.isSegmentUnmapped() &&\n      !this.isMateUnmapped() &&\n      this._refID === this._next_refid()\n    ) {\n      const s1 = this.isReverseComplemented() ? 'R' : 'F'\n      const s2 = this.isMateReverseComplemented() ? 'R' : 'F'\n      let o1 = ' '\n      let o2 = ' '\n      if (this.isRead1()) {\n        o1 = '1'\n        o2 = '2'\n      } else if (this.isRead2()) {\n        o1 = '2'\n        o2 = '1'\n      }\n\n      const tmp = []\n      const isize = this.template_length()\n      if (isize > 0) {\n        tmp[0] = s1\n        tmp[1] = o1\n        tmp[2] = s2\n        tmp[3] = o2\n      } else {\n        tmp[2] = s1\n        tmp[3] = o1\n        tmp[0] = s2\n        tmp[1] = o2\n      }\n      return tmp.join('')\n    }\n    return ''\n  }\n\n  _bin_mq_nl() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 12)\n  }\n\n  _flag_nc() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 16)\n  }\n\n  seq_length() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 20)\n  }\n\n  _next_refid() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 24)\n  }\n\n  _next_pos() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 28)\n  }\n\n  template_length() {\n    return this.bytes.byteArray.readInt32LE(this.bytes.start + 32)\n  }\n\n  toJSON() {\n    const data: { [key: string]: any } = {}\n    for (const k of Object.keys(this)) {\n      if (k.charAt(0) === '_' || k === 'bytes') {\n        continue\n      }\n      //@ts-ignore\n      data[k] = this[k]\n    }\n\n    return data\n  }\n}\n","export function parseHeaderText(text: string) {\n  const lines = text.split(/\\r?\\n/)\n  const data: { tag: string; data: { tag: string; value: string }[] }[] = []\n  for (const line of lines) {\n    const [tag, ...fields] = line.split(/\\t/)\n    if (tag) {\n      data.push({\n        tag: tag.slice(1),\n        data: fields.map(f => {\n          const [fieldTag, value] = f.split(':', 2)\n          return { tag: fieldTag, value }\n        }),\n      })\n    }\n  }\n  return data\n}\n","import { Buffer } from 'buffer'\nimport crc32 from 'buffer-crc32'\nimport { unzip, unzipChunkSlice } from '@gmod/bgzf-filehandle'\nimport { LocalFile, RemoteFile, GenericFilehandle } from 'generic-filehandle'\nimport AbortablePromiseCache from 'abortable-promise-cache'\nimport QuickLRU from 'quick-lru'\n\n// locals\nimport BAI from './bai'\nimport CSI from './csi'\nimport Chunk from './chunk'\nimport BAMFeature from './record'\nimport { parseHeaderText } from './sam'\nimport { checkAbortSignal, timeout, makeOpts, BamOpts, BaseOpts } from './util'\n\nexport const BAM_MAGIC = 21840194\n\nconst blockLen = 1 << 16\n\nasync function gen2array<T>(gen: AsyncIterable<T[]>): Promise<T[]> {\n  let out: T[] = []\n  for await (const x of gen) {\n    out = out.concat(x)\n  }\n  return out\n}\n\ninterface Args {\n  chunk: Chunk\n  opts: BaseOpts\n}\n\nclass NullFilehandle {\n  public read(): Promise<any> {\n    throw new Error('never called')\n  }\n  public stat(): Promise<any> {\n    throw new Error('never called')\n  }\n\n  public readFile(): Promise<any> {\n    throw new Error('never called')\n  }\n\n  public close(): Promise<any> {\n    throw new Error('never called')\n  }\n}\nexport default class BamFile {\n  public renameRefSeq: (a: string) => string\n  public bam: GenericFilehandle\n  public header?: string\n  public chrToIndex?: Record<string, number>\n  public indexToChr?: { refName: string; length: number }[]\n  public yieldThreadTime: number\n  public index?: BAI | CSI\n  public htsget = false\n  public headerP?: ReturnType<BamFile['getHeaderPre']>\n\n  private featureCache = new AbortablePromiseCache<Args, BAMFeature[]>({\n    cache: new QuickLRU({\n      maxSize: 50,\n    }),\n    fill: async (args: Args, signal) => {\n      const { chunk, opts } = args\n      const { data, cpositions, dpositions } = await this._readChunk({\n        chunk,\n        opts: { ...opts, signal },\n      })\n      return this.readBamFeatures(data, cpositions, dpositions, chunk)\n    },\n  })\n\n  constructor({\n    bamFilehandle,\n    bamPath,\n    bamUrl,\n    baiPath,\n    baiFilehandle,\n    baiUrl,\n    csiPath,\n    csiFilehandle,\n    csiUrl,\n    htsget,\n    yieldThreadTime = 100,\n    renameRefSeqs = n => n,\n  }: {\n    bamFilehandle?: GenericFilehandle\n    bamPath?: string\n    bamUrl?: string\n    baiPath?: string\n    baiFilehandle?: GenericFilehandle\n    baiUrl?: string\n    csiPath?: string\n    csiFilehandle?: GenericFilehandle\n    csiUrl?: string\n    renameRefSeqs?: (a: string) => string\n    yieldThreadTime?: number\n    htsget?: boolean\n  }) {\n    this.renameRefSeq = renameRefSeqs\n\n    if (bamFilehandle) {\n      this.bam = bamFilehandle\n    } else if (bamPath) {\n      this.bam = new LocalFile(bamPath)\n    } else if (bamUrl) {\n      this.bam = new RemoteFile(bamUrl)\n    } else if (htsget) {\n      this.htsget = true\n      this.bam = new NullFilehandle()\n    } else {\n      throw new Error('unable to initialize bam')\n    }\n    if (csiFilehandle) {\n      this.index = new CSI({ filehandle: csiFilehandle })\n    } else if (csiPath) {\n      this.index = new CSI({ filehandle: new LocalFile(csiPath) })\n    } else if (csiUrl) {\n      this.index = new CSI({ filehandle: new RemoteFile(csiUrl) })\n    } else if (baiFilehandle) {\n      this.index = new BAI({ filehandle: baiFilehandle })\n    } else if (baiPath) {\n      this.index = new BAI({ filehandle: new LocalFile(baiPath) })\n    } else if (baiUrl) {\n      this.index = new BAI({ filehandle: new RemoteFile(baiUrl) })\n    } else if (bamPath) {\n      this.index = new BAI({ filehandle: new LocalFile(`${bamPath}.bai`) })\n    } else if (bamUrl) {\n      this.index = new BAI({ filehandle: new RemoteFile(`${bamUrl}.bai`) })\n    } else if (htsget) {\n      this.htsget = true\n    } else {\n      throw new Error('unable to infer index format')\n    }\n    this.yieldThreadTime = yieldThreadTime\n  }\n\n  async getHeaderPre(origOpts?: BaseOpts) {\n    const opts = makeOpts(origOpts)\n    if (!this.index) {\n      return\n    }\n    const indexData = await this.index.parse(opts)\n    const ret = indexData.firstDataLine\n      ? indexData.firstDataLine.blockPosition + 65535\n      : undefined\n    let buffer\n    if (ret) {\n      const s = ret + blockLen\n      const res = await this.bam.read(Buffer.alloc(s), 0, s, 0, opts)\n      if (!res.bytesRead) {\n        throw new Error('Error reading header')\n      }\n      buffer = res.buffer.subarray(0, Math.min(res.bytesRead, ret))\n    } else {\n      buffer = (await this.bam.readFile(opts)) as Buffer\n    }\n\n    const uncba = await unzip(buffer)\n\n    if (uncba.readInt32LE(0) !== BAM_MAGIC) {\n      throw new Error('Not a BAM file')\n    }\n    const headLen = uncba.readInt32LE(4)\n\n    this.header = uncba.toString('utf8', 8, 8 + headLen)\n    const { chrToIndex, indexToChr } = await this._readRefSeqs(\n      headLen + 8,\n      65535,\n      opts,\n    )\n    this.chrToIndex = chrToIndex\n    this.indexToChr = indexToChr\n\n    return parseHeaderText(this.header)\n  }\n\n  getHeader(opts?: BaseOpts) {\n    if (!this.headerP) {\n      this.headerP = this.getHeaderPre(opts).catch(e => {\n        this.headerP = undefined\n        throw e\n      })\n    }\n    return this.headerP\n  }\n\n  async getHeaderText(opts: BaseOpts = {}) {\n    await this.getHeader(opts)\n    return this.header\n  }\n\n  // the full length of the refseq block is not given in advance so this grabs\n  // a chunk and doubles it if all refseqs haven't been processed\n  async _readRefSeqs(\n    start: number,\n    refSeqBytes: number,\n    opts?: BaseOpts,\n  ): Promise<{\n    chrToIndex: { [key: string]: number }\n    indexToChr: { refName: string; length: number }[]\n  }> {\n    if (start > refSeqBytes) {\n      return this._readRefSeqs(start, refSeqBytes * 2, opts)\n    }\n    const size = refSeqBytes + blockLen\n    const { bytesRead, buffer } = await this.bam.read(\n      Buffer.alloc(size),\n      0,\n      refSeqBytes,\n      0,\n      opts,\n    )\n    if (!bytesRead) {\n      throw new Error('Error reading refseqs from header')\n    }\n    const uncba = await unzip(\n      buffer.subarray(0, Math.min(bytesRead, refSeqBytes)),\n    )\n    const nRef = uncba.readInt32LE(start)\n    let p = start + 4\n    const chrToIndex: { [key: string]: number } = {}\n    const indexToChr: { refName: string; length: number }[] = []\n    for (let i = 0; i < nRef; i += 1) {\n      const lName = uncba.readInt32LE(p)\n      const refName = this.renameRefSeq(\n        uncba.toString('utf8', p + 4, p + 4 + lName - 1),\n      )\n      const lRef = uncba.readInt32LE(p + lName + 4)\n\n      chrToIndex[refName] = i\n      indexToChr.push({ refName, length: lRef })\n\n      p = p + 8 + lName\n      if (p > uncba.length) {\n        console.warn(\n          `BAM header is very big.  Re-fetching ${refSeqBytes} bytes.`,\n        )\n        return this._readRefSeqs(start, refSeqBytes * 2, opts)\n      }\n    }\n    return { chrToIndex, indexToChr }\n  }\n\n  async getRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    return gen2array(this.streamRecordsForRange(chr, min, max, opts))\n  }\n\n  async *streamRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    await this.getHeader(opts)\n    const chrId = this.chrToIndex?.[chr]\n    if (chrId === undefined || !this.index) {\n      yield []\n    } else {\n      const chunks = await this.index.blocksForRange(chrId, min - 1, max, opts)\n      yield* this._fetchChunkFeatures(chunks, chrId, min, max, opts)\n    }\n  }\n\n  async *_fetchChunkFeatures(\n    chunks: Chunk[],\n    chrId: number,\n    min: number,\n    max: number,\n    opts: BamOpts = {},\n  ) {\n    const { viewAsPairs } = opts\n    const feats = [] as BAMFeature[][]\n    let done = false\n\n    for (const chunk of chunks) {\n      const records = await this.featureCache.get(\n        chunk.toString(),\n        { chunk, opts },\n        opts.signal,\n      )\n\n      const recs = [] as BAMFeature[]\n      for (const feature of records) {\n        if (feature.seq_id() === chrId) {\n          if (feature.get('start') >= max) {\n            // past end of range, can stop iterating\n            done = true\n            break\n          } else if (feature.get('end') >= min) {\n            // must be in range\n            recs.push(feature)\n          }\n        }\n      }\n      feats.push(recs)\n      yield recs\n      if (done) {\n        break\n      }\n    }\n\n    checkAbortSignal(opts.signal)\n    if (viewAsPairs) {\n      yield this.fetchPairs(chrId, feats, opts)\n    }\n  }\n\n  async fetchPairs(chrId: number, feats: BAMFeature[][], opts: BamOpts) {\n    const { pairAcrossChr, maxInsertSize = 200000 } = opts\n    const unmatedPairs: { [key: string]: boolean } = {}\n    const readIds: { [key: string]: number } = {}\n    feats.map(ret => {\n      const readNames: { [key: string]: number } = {}\n      for (const element of ret) {\n        const name = element.name()\n        const id = element.id()\n        if (!readNames[name]) {\n          readNames[name] = 0\n        }\n        readNames[name]++\n        readIds[id] = 1\n      }\n      for (const [k, v] of Object.entries(readNames)) {\n        if (v === 1) {\n          unmatedPairs[k] = true\n        }\n      }\n    })\n\n    const matePromises: Promise<Chunk[]>[] = []\n    feats.map(ret => {\n      for (const f of ret) {\n        const name = f.name()\n        const start = f.get('start')\n        const pnext = f._next_pos()\n        const rnext = f._next_refid()\n        if (\n          this.index &&\n          unmatedPairs[name] &&\n          (pairAcrossChr ||\n            (rnext === chrId && Math.abs(start - pnext) < maxInsertSize))\n        ) {\n          matePromises.push(\n            this.index.blocksForRange(rnext, pnext, pnext + 1, opts),\n          )\n        }\n      }\n    })\n\n    // filter out duplicate chunks (the blocks are lists of chunks, blocks are\n    // concatenated, then filter dup chunks)\n    const map = new Map<string, Chunk>()\n    const res = await Promise.all(matePromises)\n    for (const m of res.flat()) {\n      if (!map.has(m.toString())) {\n        map.set(m.toString(), m)\n      }\n    }\n\n    const mateFeatPromises = await Promise.all(\n      [...map.values()].map(async c => {\n        const { data, cpositions, dpositions, chunk } = await this._readChunk({\n          chunk: c,\n          opts,\n        })\n        const mateRecs = [] as BAMFeature[]\n        for (const feature of await this.readBamFeatures(\n          data,\n          cpositions,\n          dpositions,\n          chunk,\n        )) {\n          if (unmatedPairs[feature.get('name')] && !readIds[feature.id()]) {\n            mateRecs.push(feature)\n          }\n        }\n        return mateRecs\n      }),\n    )\n    return mateFeatPromises.flat()\n  }\n\n  async _readRegion(position: number, size: number, opts: BaseOpts = {}) {\n    const { bytesRead, buffer } = await this.bam.read(\n      Buffer.alloc(size),\n      0,\n      size,\n      position,\n      opts,\n    )\n\n    return buffer.subarray(0, Math.min(bytesRead, size))\n  }\n\n  async _readChunk({ chunk, opts }: { chunk: Chunk; opts: BaseOpts }) {\n    const buffer = await this._readRegion(\n      chunk.minv.blockPosition,\n      chunk.fetchedSize(),\n      opts,\n    )\n\n    const {\n      buffer: data,\n      cpositions,\n      dpositions,\n    } = await unzipChunkSlice(buffer, chunk)\n    return { data, cpositions, dpositions, chunk }\n  }\n\n  async readBamFeatures(\n    ba: Buffer,\n    cpositions: number[],\n    dpositions: number[],\n    chunk: Chunk,\n  ) {\n    let blockStart = 0\n    const sink = [] as BAMFeature[]\n    let pos = 0\n    let last = +Date.now()\n\n    while (blockStart + 4 < ba.length) {\n      const blockSize = ba.readInt32LE(blockStart)\n      const blockEnd = blockStart + 4 + blockSize - 1\n\n      // increment position to the current decompressed status\n      if (dpositions) {\n        while (blockStart + chunk.minv.dataPosition >= dpositions[pos++]) {}\n        pos--\n      }\n\n      // only try to read the feature if we have all the bytes for it\n      if (blockEnd < ba.length) {\n        const feature = new BAMFeature({\n          bytes: {\n            byteArray: ba,\n            start: blockStart,\n            end: blockEnd,\n          },\n          // the below results in an automatically calculated file-offset based\n          // ID if the info for that is available, otherwise crc32 of the\n          // features\n          //\n          // cpositions[pos] refers to actual file offset of a bgzip block\n          // boundaries\n          //\n          // we multiply by (1 <<8) in order to make sure each block has a\n          // \"unique\" address space so that data in that block could never\n          // overlap\n          //\n          // then the blockStart-dpositions is an uncompressed file offset from\n          // that bgzip block boundary, and since the cpositions are multiplied\n          // by (1 << 8) these uncompressed offsets get a unique space\n          //\n          // this has an extra chunk.minv.dataPosition added on because it\n          // blockStart starts at 0 instead of chunk.minv.dataPosition\n          //\n          // the +1 is just to avoid any possible uniqueId 0 but this does not\n          // realistically happen\n          fileOffset:\n            cpositions.length > 0\n              ? cpositions[pos] * (1 << 8) +\n                (blockStart - dpositions[pos]) +\n                chunk.minv.dataPosition +\n                1\n              : // must be slice, not subarray for buffer polyfill on web\n                crc32.signed(ba.slice(blockStart, blockEnd)),\n        })\n\n        sink.push(feature)\n        if (this.yieldThreadTime && +Date.now() - last > this.yieldThreadTime) {\n          await timeout(1)\n          last = +Date.now()\n        }\n      }\n\n      blockStart = blockEnd + 1\n    }\n    return sink\n  }\n\n  async hasRefSeq(seqName: string) {\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined ? false : this.index?.hasRefSeq(seqId)\n  }\n\n  async lineCount(seqName: string) {\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined || !this.index ? 0 : this.index.lineCount(seqId)\n  }\n\n  async indexCov(seqName: string, start?: number, end?: number) {\n    if (!this.index) {\n      return []\n    }\n    await this.index.parse()\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined ? [] : this.index.indexCov(seqId, start, end)\n  }\n\n  async blocksForRange(\n    seqName: string,\n    start: number,\n    end: number,\n    opts?: BaseOpts,\n  ) {\n    if (!this.index) {\n      return []\n    }\n    await this.index.parse()\n    const seqId = this.chrToIndex?.[seqName]\n    return seqId === undefined\n      ? []\n      : this.index.blocksForRange(seqId, start, end, opts)\n  }\n}\n","import { unzip } from '@gmod/bgzf-filehandle'\nimport { Buffer } from 'buffer'\nimport { BaseOpts, BamOpts } from './util'\nimport BamFile, { BAM_MAGIC } from './bamFile'\nimport Chunk from './chunk'\nimport { parseHeaderText } from './sam'\n\ninterface HtsgetChunk {\n  url: string\n  headers?: Record<string, string>\n}\nasync function concat(arr: HtsgetChunk[], opts?: Record<string, any>) {\n  const res = await Promise.all(\n    arr.map(async chunk => {\n      const { url, headers } = chunk\n      if (url.startsWith('data:')) {\n        return Buffer.from(url.split(',')[1], 'base64')\n      } else {\n        //remove referer header, it is not even allowed to be specified\n        // @ts-expect-error\n        //eslint-disable-next-line @typescript-eslint/no-unused-vars\n        const { referer, ...rest } = headers\n        const res = await fetch(url, {\n          ...opts,\n          headers: { ...opts?.headers, ...rest },\n        })\n        if (!res.ok) {\n          throw new Error(\n            `HTTP ${res.status} fetching ${url}: ${await res.text()}`,\n          )\n        }\n        return Buffer.from(await res.arrayBuffer())\n      }\n    }),\n  )\n\n  return Buffer.concat(await Promise.all(res.map(elt => unzip(elt))))\n}\n\nexport default class HtsgetFile extends BamFile {\n  private baseUrl: string\n\n  private trackId: string\n\n  constructor(args: { trackId: string; baseUrl: string }) {\n    super({ htsget: true })\n    this.baseUrl = args.baseUrl\n    this.trackId = args.trackId\n  }\n\n  async *streamRecordsForRange(\n    chr: string,\n    min: number,\n    max: number,\n    opts?: BamOpts,\n  ) {\n    const base = `${this.baseUrl}/${this.trackId}`\n    const url = `${base}?referenceName=${chr}&start=${min}&end=${max}&format=BAM`\n    const chrId = this.chrToIndex?.[chr]\n    if (chrId === undefined) {\n      yield []\n    } else {\n      const result = await fetch(url, { ...opts })\n      if (!result.ok) {\n        throw new Error(\n          `HTTP ${result.status} fetching ${url}: ${await result.text()}`,\n        )\n      }\n      const data = await result.json()\n      const uncba = await concat(data.htsget.urls.slice(1), opts)\n\n      yield* this._fetchChunkFeatures(\n        [\n          // fake stuff to pretend to be a Chunk\n          {\n            buffer: uncba,\n            _fetchedSize: undefined,\n            bin: 0,\n            compareTo() {\n              return 0\n            },\n            toUniqueString() {\n              return `${chr}_${min}_${max}`\n            },\n            fetchedSize() {\n              return 0\n            },\n            minv: {\n              dataPosition: 0,\n              blockPosition: 0,\n              compareTo: () => 0,\n            },\n            maxv: {\n              dataPosition: Number.MAX_SAFE_INTEGER,\n              blockPosition: 0,\n              compareTo: () => 0,\n            },\n            toString() {\n              return `${chr}_${min}_${max}`\n            },\n          },\n        ],\n        chrId,\n        min,\n        max,\n        opts,\n      )\n    }\n  }\n\n  async _readChunk({ chunk }: { chunk: Chunk; opts: BaseOpts }) {\n    if (!chunk.buffer) {\n      throw new Error('expected chunk.buffer in htsget')\n    }\n    return { data: chunk.buffer, cpositions: [], dpositions: [], chunk }\n  }\n\n  async getHeader(opts: BaseOpts = {}) {\n    const url = `${this.baseUrl}/${this.trackId}?referenceName=na&class=header`\n    const result = await fetch(url, opts)\n    if (!result.ok) {\n      throw new Error(\n        `HTTP ${result.status} fetching ${url}: ${await result.text()}`,\n      )\n    }\n    const data = await result.json()\n    const uncba = await concat(data.htsget.urls, opts)\n\n    if (uncba.readInt32LE(0) !== BAM_MAGIC) {\n      throw new Error('Not a BAM file')\n    }\n    const headLen = uncba.readInt32LE(4)\n    const headerText = uncba.toString('utf8', 8, 8 + headLen)\n    const samHeader = parseHeaderText(headerText)\n\n    // use the @SQ lines in the header to figure out the\n    // mapping between ref ref ID numbers and names\n    const idToName: { refName: string; length: number }[] = []\n    const nameToId: Record<string, number> = {}\n    const sqLines = samHeader.filter(l => l.tag === 'SQ')\n    for (const [refId, sqLine] of sqLines.entries()) {\n      let refName = ''\n      let length = 0\n      for (const item of sqLine.data) {\n        if (item.tag === 'SN') {\n          refName = item.value\n        } else if (item.tag === 'LN') {\n          length = +item.value\n        }\n      }\n      nameToId[refName] = refId\n      idToName[refId] = { refName, length }\n    }\n    this.chrToIndex = nameToId\n    this.indexToChr = idToName\n    return samHeader\n  }\n}\n","import { Buffer } from 'buffer'\n//@ts-ignore\nimport { Z_SYNC_FLUSH, Inflate } from 'pako'\n\ninterface VirtualOffset {\n  blockPosition: number\n  dataPosition: number\n}\ninterface Chunk {\n  minv: VirtualOffset\n  maxv: VirtualOffset\n}\n\n// browserify-zlib, which is the zlib shim used by default in webpacked code,\n// does not properly uncompress bgzf chunks that contain more than\n// one bgzf block, so export an unzip function that uses pako directly\n// if we are running in a browser.\nasync function unzip(inputData: Buffer) {\n  try {\n    let strm\n    let pos = 0\n    let i = 0\n    const chunks = []\n    let totalSize = 0\n    let inflator\n    do {\n      const remainingInput = inputData.subarray(pos)\n      inflator = new Inflate()\n      //@ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      pos += strm.next_in\n      chunks[i] = inflator.result as Uint8Array\n      totalSize += chunks[i].length\n      i += 1\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    return Buffer.from(result)\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to pakounzip, except it does extra counting\n// to return the positions of compressed and decompressed\n// data offsets\nasync function unzipChunk(inputData: Buffer) {\n  try {\n    let strm\n    let cpos = 0\n    let dpos = 0\n    const blocks = []\n    const cpositions = []\n    const dpositions = []\n    do {\n      const remainingInput = inputData.slice(cpos)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = Buffer.from(inflator.result)\n      blocks.push(buffer)\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n\n      cpos += strm.next_in\n      dpos += buffer.length\n    } while (strm.avail_in)\n\n    const buffer = Buffer.concat(blocks)\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to unzipChunk above but slices (0,minv.dataPosition) and\n// (maxv.dataPosition,end) off\nasync function unzipChunkSlice(inputData: Buffer, chunk: Chunk) {\n  try {\n    let strm\n    const { minv, maxv } = chunk\n    let cpos = minv.blockPosition\n    let dpos = minv.dataPosition\n    const chunks = []\n    const cpositions = []\n    const dpositions = []\n\n    let totalSize = 0\n    let i = 0\n    do {\n      const remainingInput = inputData.subarray(cpos - minv.blockPosition)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = inflator.result\n      chunks.push(buffer as Uint8Array)\n      let len = buffer.length\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n      if (chunks.length === 1 && minv.dataPosition) {\n        // this is the first chunk, trim it\n        chunks[0] = chunks[0].subarray(minv.dataPosition)\n        len = chunks[0].length\n      }\n      const origCpos = cpos\n      cpos += strm.next_in\n      dpos += len\n\n      if (origCpos >= maxv.blockPosition) {\n        // this is the last chunk, trim it and stop decompressing\n        // note if it is the same block is minv it subtracts that already\n        // trimmed part of the slice length\n\n        chunks[i] = chunks[i].subarray(\n          0,\n          maxv.blockPosition === minv.blockPosition\n            ? maxv.dataPosition - minv.dataPosition + 1\n            : maxv.dataPosition + 1,\n        )\n\n        cpositions.push(cpos)\n        dpositions.push(dpos)\n        totalSize += chunks[i].length\n        break\n      }\n      totalSize += chunks[i].length\n      i++\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    const buffer = Buffer.from(result)\n\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\nfunction nodeUnzip() {\n  throw new Error('nodeUnzip not implemented.')\n}\n\nexport { unzip, unzipChunk, unzipChunkSlice, unzip as pakoUnzip, nodeUnzip }\n","import Long from 'long'\nimport { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// const COMPRESSED_POSITION = 0\nconst UNCOMPRESSED_POSITION = 1\n\nexport default class GziIndex {\n  filehandle: GenericFilehandle\n\n  index?: any\n\n  constructor({\n    filehandle,\n    path,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n  }\n\n  _readLongWithOverflow(buf: Buffer, offset = 0, unsigned = true) {\n    //@ts-ignore\n    const long = Long.fromBytesLE(buf.slice(offset, offset + 8), unsigned)\n    if (\n      long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n      long.lessThan(Number.MIN_SAFE_INTEGER)\n    ) {\n      throw new TypeError('integer overflow')\n    }\n\n    return long.toNumber()\n  }\n\n  _getIndex() {\n    if (!this.index) {\n      this.index = this._readIndex()\n    }\n    return this.index\n  }\n\n  async _readIndex() {\n    let buf = Buffer.allocUnsafe(8)\n    await this.filehandle.read(buf, 0, 8, 0)\n    const numEntries = this._readLongWithOverflow(buf, 0, true)\n    if (!numEntries) {\n      return [[0, 0]]\n    }\n\n    const entries = new Array(numEntries + 1)\n    entries[0] = [0, 0]\n\n    // TODO rewrite this to make an index-index that stays in memory\n    const bufSize = 8 * 2 * numEntries\n    if (bufSize > Number.MAX_SAFE_INTEGER) {\n      throw new TypeError('integer overflow')\n    }\n    buf = Buffer.allocUnsafe(bufSize)\n    await this.filehandle.read(buf, 0, bufSize, 8)\n    for (let entryNumber = 0; entryNumber < numEntries; entryNumber += 1) {\n      const compressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16,\n      )\n      const uncompressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16 + 8,\n      )\n      entries[entryNumber + 1] = [compressedPosition, uncompressedPosition]\n    }\n\n    return entries\n  }\n\n  async getLastBlock() {\n    const entries = await this._getIndex()\n    if (!entries.length) {\n      return undefined\n    }\n    return entries[entries.length - 1]\n  }\n\n  async getRelevantBlocksForRead(length: number, position: number) {\n    const endPosition = position + length\n    if (length === 0) {\n      return []\n    }\n    const entries = await this._getIndex()\n    const relevant = []\n\n    // binary search to find the block that the\n    // read starts in and extend forward from that\n    const compare = (entry: any, nextEntry: any) => {\n      const uncompressedPosition = entry[UNCOMPRESSED_POSITION]\n      const nextUncompressedPosition = nextEntry\n        ? nextEntry[UNCOMPRESSED_POSITION]\n        : Infinity\n      // block overlaps read start\n      if (\n        uncompressedPosition <= position &&\n        nextUncompressedPosition > position\n      ) {\n        return 0\n        // block is before read start\n      }\n      if (uncompressedPosition < position) {\n        return -1\n      }\n      // block is after read start\n      return 1\n    }\n\n    let lowerBound = 0\n    let upperBound = entries.length - 1\n    let searchPosition = Math.floor(entries.length / 2)\n\n    let comparison = compare(\n      entries[searchPosition],\n      entries[searchPosition + 1],\n    )\n    while (comparison !== 0) {\n      if (comparison > 0) {\n        upperBound = searchPosition - 1\n      } else if (comparison < 0) {\n        lowerBound = searchPosition + 1\n      }\n      searchPosition = Math.ceil((upperBound - lowerBound) / 2) + lowerBound\n      comparison = compare(entries[searchPosition], entries[searchPosition + 1])\n    }\n\n    // here's where we read forward\n    relevant.push(entries[searchPosition])\n    let i = searchPosition + 1\n    for (; i < entries.length; i += 1) {\n      relevant.push(entries[i])\n      if (entries[i][UNCOMPRESSED_POSITION] >= endPosition) {\n        break\n      }\n    }\n    if (relevant[relevant.length - 1][UNCOMPRESSED_POSITION] < endPosition) {\n      relevant.push([])\n    }\n    return relevant\n  }\n}\n","import { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// locals\nimport { unzip } from './unzip'\nimport GziIndex from './gziIndex'\n\nexport default class BgzFilehandle {\n  filehandle: GenericFilehandle\n  gzi: GziIndex\n\n  constructor({\n    filehandle,\n    path,\n    gziFilehandle,\n    gziPath,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n    gziFilehandle?: GenericFilehandle\n    gziPath?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n\n    if (!gziFilehandle && !gziPath && !path) {\n      throw new TypeError('either gziFilehandle or gziPath must be defined')\n    }\n\n    this.gzi = new GziIndex({\n      filehandle: gziFilehandle,\n      path: !gziFilehandle && !gziPath && path ? gziPath : `${path}.gzi`,\n    })\n  }\n\n  async stat() {\n    const compressedStat = await this.filehandle.stat()\n    return Object.assign(compressedStat, {\n      size: await this.getUncompressedFileSize(),\n      blocks: undefined,\n      blksize: undefined,\n    })\n  }\n\n  async getUncompressedFileSize() {\n    // read the last block's ISIZE (see gzip RFC),\n    // and add it to its uncompressedPosition\n    const [, uncompressedPosition] = await this.gzi.getLastBlock()\n\n    const { size } = await this.filehandle.stat()\n\n    const buf = Buffer.allocUnsafe(4)\n    // note: there should be a 28-byte EOF marker (an empty block) at\n    // the end of the file, so we skip backward past that\n    const { bytesRead } = await this.filehandle.read(buf, 0, 4, size - 28 - 4)\n    if (bytesRead !== 4) {\n      throw new Error('read error')\n    }\n    const lastBlockUncompressedSize = buf.readUInt32LE(0)\n    return uncompressedPosition + lastBlockUncompressedSize\n  }\n\n  async _readAndUncompressBlock(\n    blockBuffer: Buffer,\n    [compressedPosition]: [number],\n    [nextCompressedPosition]: [number],\n  ) {\n    let next = nextCompressedPosition\n    if (!next) {\n      next = (await this.filehandle.stat()).size\n    }\n\n    // read the compressed data into the block buffer\n    const blockCompressedLength = next - compressedPosition\n\n    await this.filehandle.read(\n      blockBuffer,\n      0,\n      blockCompressedLength,\n      compressedPosition,\n    )\n\n    // uncompress it\n    const unzippedBuffer = await unzip(\n      blockBuffer.slice(0, blockCompressedLength),\n    )\n\n    return unzippedBuffer as Buffer\n  }\n\n  async read(buf: Buffer, offset: number, length: number, position: number) {\n    // get the block positions for this read\n    const blockPositions = await this.gzi.getRelevantBlocksForRead(\n      length,\n      position,\n    )\n    const blockBuffer = Buffer.allocUnsafe(32768 * 2)\n    // uncompress the blocks and read from them one at a time to keep memory usage down\n    let destinationOffset = offset\n    let bytesRead = 0\n    for (\n      let blockNum = 0;\n      blockNum < blockPositions.length - 1;\n      blockNum += 1\n    ) {\n      // eslint-disable-next-line no-await-in-loop\n      const uncompressedBuffer = await this._readAndUncompressBlock(\n        blockBuffer,\n        blockPositions[blockNum],\n        blockPositions[blockNum + 1],\n      )\n      const [, uncompressedPosition] = blockPositions[blockNum]\n      const sourceOffset =\n        uncompressedPosition >= position ? 0 : position - uncompressedPosition\n      const sourceEnd =\n        Math.min(\n          position + length,\n          uncompressedPosition + uncompressedBuffer.length,\n        ) - uncompressedPosition\n      if (sourceOffset >= 0 && sourceOffset < uncompressedBuffer.length) {\n        uncompressedBuffer.copy(buf, destinationOffset, sourceOffset, sourceEnd)\n        destinationOffset += sourceEnd - sourceOffset\n        bytesRead += sourceEnd - sourceOffset\n      }\n    }\n\n    return { bytesRead, buffer: buf }\n  }\n}\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortcontroller_ponyfill_1 = require(\"./abortcontroller-ponyfill\");\nconst AggregateAbortController_1 = __importDefault(require(\"./AggregateAbortController\"));\nconst AggregateStatusReporter_1 = __importDefault(require(\"./AggregateStatusReporter\"));\nclass AbortablePromiseCache {\n    constructor({ fill, cache, }) {\n        if (typeof fill !== 'function') {\n            throw new TypeError('must pass a fill function');\n        }\n        if (typeof cache !== 'object') {\n            throw new TypeError('must pass a cache object');\n        }\n        if (typeof cache.get !== 'function' ||\n            typeof cache.set !== 'function' ||\n            typeof cache.delete !== 'function') {\n            throw new TypeError('cache must implement get(key), set(key, val), and and delete(key)');\n        }\n        this.cache = cache;\n        this.fillCallback = fill;\n    }\n    static isAbortException(exception) {\n        return (\n        // DOMException\n        exception.name === 'AbortError' ||\n            // standard-ish non-DOM abort exception\n            //@ts-ignore\n            exception.code === 'ERR_ABORTED' ||\n            // stringified DOMException\n            exception.message === 'AbortError: aborted' ||\n            // stringified standard-ish exception\n            exception.message === 'Error: aborted');\n    }\n    evict(key, entry) {\n        if (this.cache.get(key) === entry) {\n            this.cache.delete(key);\n        }\n    }\n    fill(key, data, signal, statusCallback) {\n        const aborter = new AggregateAbortController_1.default();\n        const statusReporter = new AggregateStatusReporter_1.default();\n        statusReporter.addCallback(statusCallback);\n        const newEntry = {\n            aborter: aborter,\n            promise: this.fillCallback(data, aborter.signal, (message) => {\n                statusReporter.callback(message);\n            }),\n            settled: false,\n            statusReporter,\n            get aborted() {\n                return this.aborter.signal.aborted;\n            },\n        };\n        newEntry.aborter.addSignal(signal);\n        // remove the fill from the cache when its abortcontroller fires, if still in there\n        newEntry.aborter.signal.addEventListener('abort', () => {\n            if (!newEntry.settled) {\n                this.evict(key, newEntry);\n            }\n        });\n        // chain off the cached promise to record when it settles\n        newEntry.promise\n            .then(() => {\n            newEntry.settled = true;\n        }, () => {\n            newEntry.settled = true;\n            // if the fill throws an error (including abort) and is still in the cache, remove it\n            this.evict(key, newEntry);\n        })\n            .catch(e => {\n            // this will only be reached if there is some kind of\n            // bad bug in this library\n            console.error(e);\n            throw e;\n        });\n        this.cache.set(key, newEntry);\n    }\n    static checkSinglePromise(promise, signal) {\n        // check just this signal for having been aborted, and abort the\n        // promise if it was, regardless of what happened with the cached\n        // response\n        function checkForSingleAbort() {\n            if (signal && signal.aborted) {\n                throw Object.assign(new Error('aborted'), { code: 'ERR_ABORTED' });\n            }\n        }\n        return promise.then(result => {\n            checkForSingleAbort();\n            return result;\n        }, error => {\n            checkForSingleAbort();\n            throw error;\n        });\n    }\n    has(key) {\n        return this.cache.has(key);\n    }\n    /**\n     * Callback for getting status of the pending async\n     *\n     * @callback statusCallback\n     * @param {any} status, current status string or message object\n     */\n    /**\n     * @param {any} key cache key to use for this request\n     * @param {any} data data passed as the first argument to the fill callback\n     * @param {AbortSignal} [signal] optional AbortSignal object that aborts the request\n     * @param {statusCallback} a callback to get the current status of a pending async operation\n     */\n    get(key, data, signal, statusCallback) {\n        if (!signal && data instanceof abortcontroller_ponyfill_1.AbortSignal) {\n            throw new TypeError('second get argument appears to be an AbortSignal, perhaps you meant to pass `null` for the fill data?');\n        }\n        const cacheEntry = this.cache.get(key);\n        if (cacheEntry) {\n            if (cacheEntry.aborted && !cacheEntry.settled) {\n                // if it's aborted but has not realized it yet, evict it and redispatch\n                this.evict(key, cacheEntry);\n                return this.get(key, data, signal, statusCallback);\n            }\n            if (cacheEntry.settled) {\n                // too late to abort, just return it\n                return cacheEntry.promise;\n            }\n            // request is in-flight, add this signal to its list of signals,\n            // or if there is no signal, the aborter will become non-abortable\n            cacheEntry.aborter.addSignal(signal);\n            cacheEntry.statusReporter.addCallback(statusCallback);\n            return AbortablePromiseCache.checkSinglePromise(cacheEntry.promise, signal);\n        }\n        // if we got here, it is not in the cache. fill.\n        this.fill(key, data, signal, statusCallback);\n        return AbortablePromiseCache.checkSinglePromise(\n        //see https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#non-null-assertion-operator-postfix-\n        //eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        this.cache.get(key).promise, signal);\n    }\n    /**\n     * delete the given entry from the cache. if it exists and its fill request has\n     * not yet settled, the fill will be signaled to abort.\n     *\n     * @param {any} key\n     */\n    delete(key) {\n        const cachedEntry = this.cache.get(key);\n        if (cachedEntry) {\n            if (!cachedEntry.settled) {\n                cachedEntry.aborter.abort();\n            }\n            this.cache.delete(key);\n        }\n    }\n    /**\n     * Clear all requests from the cache. Aborts any that have not settled.\n     * @returns {number} count of entries deleted\n     */\n    clear() {\n        // iterate without needing regenerator-runtime\n        const keyIter = this.cache.keys();\n        let deleteCount = 0;\n        for (let result = keyIter.next(); !result.done; result = keyIter.next()) {\n            this.delete(result.value);\n            deleteCount += 1;\n        }\n        return deleteCount;\n    }\n}\nexports.default = AbortablePromiseCache;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortcontroller_ponyfill_1 = require(\"./abortcontroller-ponyfill\");\nclass NullSignal {\n}\n/**\n * aggregates a number of abort signals, will only fire the aggregated\n * abort if all of the input signals have been aborted\n */\nclass AggregateAbortController {\n    constructor() {\n        this.signals = new Set();\n        this.abortController = new abortcontroller_ponyfill_1.AbortController();\n    }\n    /**\n     * @param {AbortSignal} [signal] optional AbortSignal to add. if falsy,\n     *  will be treated as a null-signal, and this abortcontroller will no\n     *  longer be abortable.\n     */\n    //@ts-ignore\n    addSignal(signal = new NullSignal()) {\n        if (this.signal.aborted) {\n            throw new Error('cannot add a signal, already aborted!');\n        }\n        // note that a NullSignal will never fire, so if we\n        // have one this thing will never actually abort\n        this.signals.add(signal);\n        if (signal.aborted) {\n            // handle the abort immediately if it is already aborted\n            // for some reason\n            this.handleAborted(signal);\n        }\n        else if (typeof signal.addEventListener === 'function') {\n            signal.addEventListener('abort', () => {\n                this.handleAborted(signal);\n            });\n        }\n    }\n    handleAborted(signal) {\n        this.signals.delete(signal);\n        if (this.signals.size === 0) {\n            this.abortController.abort();\n        }\n    }\n    get signal() {\n        return this.abortController.signal;\n    }\n    abort() {\n        this.abortController.abort();\n    }\n}\nexports.default = AggregateAbortController;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass AggregateStatusReporter {\n    constructor() {\n        this.callbacks = new Set();\n    }\n    addCallback(callback = () => { }) {\n        this.callbacks.add(callback);\n        callback(this.currentMessage);\n    }\n    callback(message) {\n        this.currentMessage = message;\n        this.callbacks.forEach(elt => {\n            elt(message);\n        });\n    }\n}\nexports.default = AggregateStatusReporter;\n","\"use strict\";\n/* eslint-disable */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AbortSignal = exports.AbortController = void 0;\nconst cjs_ponyfill_1 = require(\"abortcontroller-polyfill/dist/cjs-ponyfill\");\nvar getGlobal = function () {\n    // the only reliable means to get the global object is\n    // `Function('return this')()`\n    // However, this causes CSP violations in Chrome apps.\n    if (typeof self !== 'undefined') {\n        return self;\n    }\n    if (typeof window !== 'undefined') {\n        return window;\n    }\n    if (typeof global !== 'undefined') {\n        return global;\n    }\n    throw new Error('unable to locate global object');\n};\n//@ts-ignore\nlet AbortController = typeof getGlobal().AbortController === 'undefined' ? cjs_ponyfill_1.AbortController : getGlobal().AbortController;\nexports.AbortController = AbortController;\n//@ts-ignore\nlet AbortSignal = typeof getGlobal().AbortController === 'undefined' ? cjs_ponyfill_1.AbortSignal : getGlobal().AbortSignal;\nexports.AbortSignal = AbortSignal;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst AbortablePromiseCache_1 = __importDefault(require(\"./AbortablePromiseCache\"));\nexports.default = AbortablePromiseCache_1.default;\n"],"names":["VirtualOffset","constructor","blockPosition","dataPosition","this","toString","compareTo","b","min","args","i","length","fromBytes","bytes","offset","bigendian","Error","Chunk","minv","maxv","bin","_fetchedSize","toUniqueString","fetchedSize","undefined","timeout","ms","Promise","resolve","setTimeout","optimizeChunks","chunks","lowest","mergedChunks","lastChunk","sort","c0","c1","dif","chunk","push","chunk1","chunk2","parsePseudoBin","lineCount","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","longToNumber","Array","prototype","slice","call","findFirstData","firstDataLine","virtualOffset","parseNameBytes","namesBytes","renameRefSeq","s","currRefId","currNameStart","refIdToName","refNameToId","refName","IndexFile","filehandle","n","BAI","refId","opts","parse","indices","stats","_parse","readFile","readUInt32LE","refCount","readInt32LE","curr","binCount","binIndex","j","binLimit","chunkCount","k","u","v","linearCount","linearIndex","bai","maxBlockSize","indexCov","seqId","start","end","range","seqIdx","e","multiple","roundDown","depths","totalSize","currentPos","score","map","d","blocksForRange","max","indexData","ba","overlappingBins","beg","binChunks","binChunk","nintv","minLin","Math","maxLin","vp","setupP","catch","hasRefSeq","rshift","num","bits","floor","CSI","maxBinNumber","depth","minShift","parseAuxData","formatFlags","coordinateType","format","columnNumbers","ref","metaValue","metaChar","String","fromCharCode","skipLines","nameSectionLength","subarray","buffer","unzip","csiVersion","auxLength","aux","csi","reg2bins","c","l","t","bins","SEQRET_DECODER","split","CIGAR_DECODER","BamRecord","data","_tagList","_allTagsParsed","fileOffset","byteArray","_id","_refID","flags","get","field","_get","toLowerCase","seq_id","_parseTag","_tags","_parseAllTags","tags","isSegmentUnmapped","isPaired","concat","Object","keys","seen","filter","lt","parent","children","id","mq","qual","qualRaw","join","p","lseq","strand","isReverseComplemented","multi_segment_next_segment_strand","isMateUnmapped","isMateReverseComplemented","name","_read_name","nl","tagName","_tagOffset","blockEnd","lcTag","tag","type","value","readInt8","readUInt8","readInt16LE","readUInt16LE","readFloatLE","cc","Btype","limit","cigop","console","warn","_parseCigar","cigar","match","op","toUpperCase","parseInt","isProperlyPaired","isRead1","isRead2","isSecondary","isFailedQc","isDuplicate","isSupplementary","numCigarOps","seqLen","lref","lop","length_on_ref","_flags","_n_cigar_op","_l_read_name","_seq_bytes","getReadBases","seq","seqBytes","len","buf","sb","getPairOrientation","_next_refid","s1","s2","o1","o2","tmp","template_length","_bin_mq_nl","_flag_nc","seq_length","_next_pos","toJSON","charAt","parseHeaderText","text","lines","line","fields","f","fieldTag","BAM_MAGIC","NullFilehandle","read","stat","close","BamFile","bamFilehandle","bamPath","bamUrl","baiPath","baiFilehandle","baiUrl","csiPath","csiFilehandle","csiUrl","htsget","yieldThreadTime","renameRefSeqs","featureCache","cache","maxSize","fill","async","signal","cpositions","dpositions","_readChunk","readBamFeatures","bam","index","getHeaderPre","origOpts","obj","makeOpts","ret","res","Buffer","alloc","bytesRead","uncba","headLen","header","chrToIndex","indexToChr","_readRefSeqs","getHeader","headerP","getHeaderText","refSeqBytes","size","nRef","lName","lRef","getRecordsForRange","chr","gen","out","x","gen2array","streamRecordsForRange","chrId","_fetchChunkFeatures","viewAsPairs","feats","done","records","recs","feature","aborted","DOMException","code","checkAbortSignal","fetchPairs","pairAcrossChr","maxInsertSize","unmatedPairs","readIds","readNames","element","entries","matePromises","pnext","rnext","abs","Map","all","m","flat","has","set","values","mateRecs","_readRegion","position","blockStart","sink","pos","last","Date","now","seqName","arr","url","headers","startsWith","from","referer","rest","fetch","ok","status","arrayBuffer","elt","HtsgetFile","super","baseUrl","trackId","result","json","urls","samHeader","idToName","nameToId","sqLines","sqLine","item","inputData","strm","inflator","remainingInput","Inflate","Z_SYNC_FLUSH","err","msg","next_in","avail_in","Uint8Array","unzipChunkSlice","cpos","dpos","origCpos","GziIndex","path","TypeError","_readLongWithOverflow","unsigned","_getIndex","_readIndex","allocUnsafe","numEntries","bufSize","entryNumber","compressedPosition","uncompressedPosition","getLastBlock","getRelevantBlocksForRead","endPosition","relevant","compare","entry","nextEntry","nextUncompressedPosition","Infinity","lowerBound","upperBound","searchPosition","comparison","ceil","BgzFilehandle","gziFilehandle","gziPath","gzi","compressedStat","assign","getUncompressedFileSize","blocks","blksize","_readAndUncompressBlock","blockBuffer","nextCompressedPosition","next","blockCompressedLength","blockPositions","destinationOffset","blockNum","uncompressedBuffer","sourceOffset","sourceEnd","copy","__importDefault","mod","__esModule","defineProperty","exports","abortcontroller_ponyfill_1","AggregateAbortController_1","AggregateStatusReporter_1","AbortablePromiseCache","delete","fillCallback","isAbortException","exception","message","evict","key","statusCallback","aborter","default","statusReporter","addCallback","newEntry","promise","callback","settled","addSignal","addEventListener","then","error","checkSinglePromise","checkForSingleAbort","AbortSignal","cacheEntry","cachedEntry","abort","clear","keyIter","deleteCount","NullSignal","signals","Set","abortController","AbortController","add","handleAborted","callbacks","currentMessage","forEach","cjs_ponyfill_1","getGlobal","self","window","g","AbortablePromiseCache_1"],"sourceRoot":""}