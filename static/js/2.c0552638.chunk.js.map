{"version":3,"sources":["../../../node_modules/@gmod/tabix/esm/tabixIndexedFile.js","../../../node_modules/quick-lru/index.js","../../../node_modules/@babel/runtime/helpers/objectWithoutPropertiesLoose.js","../../../node_modules/@gmod/tabix/esm/index.js","../../../node_modules/@gmod/tabix/esm/util.js","../../../node_modules/@babel/runtime/helpers/objectWithoutProperties.js","../../../node_modules/@gmod/tabix/esm/tbi.js","../../../node_modules/@gmod/tabix/esm/virtualOffset.js","../../../node_modules/@gmod/tabix/esm/chunk.js","../../../node_modules/@gmod/tabix/esm/indexFile.js","../../../node_modules/@gmod/tabix/esm/csi.js"],"names":["__importDefault","this","mod","__esModule","Object","defineProperty","exports","value","abortable_promise_cache_1","require","quick_lru_1","generic_filehandle_1","bgzf_filehandle_1","util_1","tbi_1","csi_1","timeout","time","Promise","resolve","setTimeout","TabixIndexedFile","path","filehandle","tbiPath","tbiFilehandle","csiPath","csiFilehandle","chunkSizeLimit","renameRefSeqs","n","chunkCacheSize","TypeError","LocalFile","index","default","renameRefSeq","chunkCache","cache","maxSize","Math","floor","fill","readChunk","bind","refName","start","end","opts","options","callback","lineCallback","undefined","getMetadata","metadata","checkAbortSignal","signal","maxRefLength","blocksForRange","chunks","i","length","size","fetchedSize","Error","toLocaleString","last","Date","now","chunkNum","previousStartCoordinate","c","get","toString","buffer","cpositions","dpositions","lines","TextDecoder","decode","split","pop","blockStart","minv","dataPosition","pos","line","checkLine","startCoordinate","overlaps","trim","firstDataLine","metaChar","maxBlockSize","maxFetch","blockPosition","_readRegion","bytes","unzip","console","error","code","lastNewline","newlineByte","charCodeAt","metaByte","slice","getHeaderBuffer","refIdToName","regionRefName","regionStart","regionEnd","columnNumbers","coordinateType","format","charAt","ref","maxColumn","max","currentColumnNumber","currentColumnStart","refSeq","Infinity","parseInt","_getVcfEnd","info","endCoordinate","isTRA","indexOf","prevChar","j","valueEnd","lineCount","position","compressedSize","read","Buffer","alloc","bytesRead","chunk","compressedData","unzipChunkSlice","QuickLRU","Map","oldCache","_size","key","set","has","delete","_set","deleted","clear","item","oldCacheSize","keys","Symbol","iterator","module","source","excluded","target","sourceKeys","CSI","TBI","tabixIndexedFile_1","optimizeChunks","canMergeBlocks","abortBreakPoint","longToNumber","long","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","AbortError","aborted","DOMException","e","chunk1","chunk2","maxv","lowest","mergedChunks","lastChunk","sort","c0","c1","dif","forEach","compareTo","push","objectWithoutPropertiesLoose","getOwnPropertySymbols","sourceSymbolKeys","prototype","propertyIsEnumerable","call","__createBinding","create","o","m","k","k2","enumerable","__setModuleDefault","v","__importStar","result","hasOwnProperty","long_1","virtualOffset_1","chunk_1","indexFile_1","TBI_MAGIC","reg2bins","beg","TabixIndex","parse","indexData","refId","refNameToId","indices","stats","readFile","readUInt32LE","refCount","readInt32LE","formatFlags","metaValue","maxBinNumber","depth","String","fromCharCode","skipLines","nameSectionLength","_parseNameBytes","currOffset","Array","map","binCount","binIndex","bin","chunkCount","parsePseudoBin","u","fromBytes","_findFirstData","linearCount","linearIndex","offset","fromBytesLE","namesBytes","currRefId","currNameStart","min","ba","warn","overlappingBins","binChunks","nintv","minLin","maxLin","vp","VirtualOffset","b","args","bigendian","Chunk","_fetchedSize","toUniqueString","IndexFile","rest","currentFdl","virtualOffset","_parseCache","_parse","seqId","CSI1_MAGIC","CSI2_MAGIC","rshift","num","bits","minShift","auxLength","csiVersion","aux","parseAuxData","loffset","csi","l","t","s","bins"],"mappings":"sHAAA,Y,+DACIA,EAAmBC,MAAQA,KAAKD,iBAAoB,SAAUE,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,IAExDE,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,IAAMC,EAA4BR,EAAgBS,EAAQ,MACpDC,EAAcV,EAAgBS,EAAQ,MACtCE,EAAuBF,EAAQ,KAC/BG,EAAoBH,EAAQ,KAC5BI,EAASJ,EAAQ,KACjBK,EAAQd,EAAgBS,EAAQ,MAChCM,EAAQf,EAAgBS,EAAQ,MACtC,SAASO,EAAQC,GACb,OAAO,IAAIC,SAAQ,SAAAC,GACfC,WAAWD,EAASF,M,IAGtBI,E,WAgBF,cAAoK,IAAtJC,EAAsJ,EAAtJA,KAAMC,EAAgJ,EAAhJA,WAAYC,EAAoI,EAApIA,QAASC,EAA2H,EAA3HA,cAAeC,EAA4G,EAA5GA,QAASC,EAAmG,EAAnGA,cAAmG,IAApFC,sBAAoF,MAAnE,IAAmE,MAAzDC,qBAAyD,MAAzC,SAAAC,GAAC,OAAIA,GAAoC,MAAjCC,sBAAiC,MAAhB,EAAI,KAAJ,IAAI,EAAK,IAAO,EAChK,GADgK,UAC5JR,EACAtB,KAAKsB,WAAaA,MAEjB,KAAID,EAIL,MAAM,IAAIU,UAAU,0CAHpB/B,KAAKsB,WAAa,IAAIZ,EAAqBsB,UAAUX,GAKzD,GAAIG,EACAxB,KAAKiC,MAAQ,IAAIpB,EAAMqB,QAAQ,CAC3BZ,WAAYE,EACZI,uBAGH,GAAIF,EACL1B,KAAKiC,MAAQ,IAAInB,EAAMoB,QAAQ,CAC3BZ,WAAYI,EACZE,uBAGH,GAAIL,EACLvB,KAAKiC,MAAQ,IAAIpB,EAAMqB,QAAQ,CAC3BZ,WAAY,IAAIZ,EAAqBsB,UAAUT,GAC/CK,uBAGH,GAAIH,EACLzB,KAAKiC,MAAQ,IAAInB,EAAMoB,QAAQ,CAC3BZ,WAAY,IAAIZ,EAAqBsB,UAAUP,GAC/CG,sBAGH,KAAIP,EAOL,MAAM,IAAIU,UAAU,yEANpB/B,KAAKiC,MAAQ,IAAIpB,EAAMqB,QAAQ,CAC3BZ,WAAY,IAAIZ,EAAqBsB,UAAzB,UAAsCX,EAAtC,SACZO,kBAMR5B,KAAK2B,eAAiBA,EACtB3B,KAAKmC,aAAeP,EACpB5B,KAAKoC,WAAa,IAAI7B,EAA0B2B,QAAQ,CACpDG,MAAO,IAAI5B,EAAYyB,QAAQ,CAC3BI,QAASC,KAAKC,MAAMV,EAAiB,SAEzCW,KAAMzC,KAAK0C,UAAUC,KAAK3C,Q,6DAUlC,WAAe4C,EAASC,EAAOC,EAAKC,GAApC,oHAEQC,EAAU,GAEM,qBAATD,EAJf,sBAKc,IAAIhB,UAAU,kCAL5B,UAOwB,oBAATgB,EACPE,EAAWF,GAGXC,EAAUD,EACVE,EAAWF,EAAKG,mBAEJC,IAAZP,EAdR,sBAec,IAAIb,UAAU,0CAf5B,UAiBSkB,EAjBT,sBAkBc,IAAIlB,UAAU,kCAlB5B,wBAoB2B/B,KAAKiC,MAAMmB,YAAYJ,GApBlD,WAoBUK,EApBV,QAqBI,EAAIzC,EAAO0C,kBAAkBC,GACxBV,IACDA,EAAQ,GAEPC,IACDA,EAAMO,EAASG,cAEbX,GAASC,EA5BnB,uBA6Bc,IAAIf,UAAU,8EA7B5B,WA+BQc,IAAUC,EA/BlB,oEAkCyB9C,KAAKiC,MAAMwB,eAAeb,EAASC,EAAOC,EAAKE,GAlCxE,QAkCUU,EAlCV,QAmCI,EAAI9C,EAAO0C,kBAAkBC,GAGpBI,EAAI,EAtCjB,aAsCoBA,EAAID,EAAOE,QAtC/B,uBAuCcC,EAAOH,EAAOC,GAAGG,eACZ9D,KAAK2B,gBAxCxB,uBAyCkB,IAAIoC,MAAJ,oCAAuCF,EAAKG,iBAA5C,4CAAgGhE,KAAK2B,eAAeqC,iBAApH,MAzClB,QAsCuCL,GAAK,EAtC5C,wBA6CQM,EAAOC,KAAKC,MACPC,EAAW,EA9CxB,aA8C2BA,EAAWV,EAAOE,QA9C7C,wBA+CYS,OA/CZ,EAgDcC,EAAIZ,EAAOU,GAhDzB,UAiDyDpE,KAAKoC,WAAWmC,IAAID,EAAEE,WAAYF,EAAGf,GAjD9F,iBAiDgBkB,EAjDhB,EAiDgBA,OAAQC,EAjDxB,EAiDwBA,WAAYC,EAjDpC,EAiDoCA,YACtBC,GAAgC,qBAAhBC,YAChB,IAAIA,YAAY,SAASC,OAAOL,GAChCA,EAAOD,YAAYO,MAAM,OACzBC,OACN,EAAIpE,EAAO0C,kBAAkBC,GACzB0B,EAAaX,EAAEY,KAAKC,aACpBC,OAxDZ,EAyDiBzB,EAAI,EAzDrB,aAyDwBA,EAAIiB,EAAMhB,QAzDlC,iBA2DY,IADMyB,EAAOT,EAAMjB,GACdyB,EAAM,EAAGH,GAAcN,EAAWS,GAAMA,GAAO,GA3DhE,KA6DkDpF,KAAKsF,UAAUjC,EAAUT,EAASC,EAAOC,EAAKuC,GAA5EE,EA7DpB,EA6DoBA,gBAAiBC,EA7DrC,EA6DqCA,gBAEOrC,IAA5BkB,QACoBlB,IAApBoC,GACAlB,EAA0BkB,GAjE1C,uBAkEsB,IAAIxB,MAAJ,gDAAmDM,EAAnD,cAAgFkB,EAAhF,2CAlEtB,WAoEYlB,EAA0BkB,GACtBC,EArEhB,iBAsEgBvC,EAASoC,EAAKI,OASd,IAAAf,EAAWU,IAAmBH,EAAaN,EAAWS,KA/EtE,kCAiFyCjC,IAApBoC,GAAiCA,GAAmBzC,GAjFzE,sDAuFYmC,GAAcI,EAAKzB,OAAS,IAExBK,EAAOC,KAAKC,MAAQ,KAzFpC,wBA0FgBF,EAAOC,KAAKC,OACZ,EAAIvD,EAAO0C,kBAAkBC,GA3F7C,UA4FsBxC,EAAQ,GA5F9B,QAyD0C4C,GAAK,EAzD/C,wBA8CqDS,GAAY,EA9CjE,iE,iHAiGA,qGAAkBrB,EAAlB,+BAAyB,GAAzB,kBACW/C,KAAKiC,MAAMmB,YAAYL,IADlC,gD,8GAUA,yHAAsBA,EAAtB,+BAA6B,GAA7B,SAC4D/C,KAAKoD,YAAYL,GAD7E,uBACY2C,EADZ,EACYA,cAAeC,EAD3B,EAC2BA,SAAUC,EADrC,EACqCA,cACjC,EAAIhF,EAAO0C,kBAAkBP,EAAKQ,QAC5BsC,EAAWH,GAAiBA,EAAcI,cAC1CJ,EAAcI,cAAgBF,EAC9BA,EALV,UAQsB5F,KAAK+F,YAAY,EAAGF,EAAU9C,GARpD,eAQQiD,EARR,QASI,EAAIpF,EAAO0C,kBAAkBP,EAAKQ,QATtC,qBAWsB,EAAI5C,EAAkBsF,OAAOD,GAXnD,QAWQA,EAXR,gEAcQE,QAAQC,MAAR,MACM,IAAIpC,MAAJ,oCAEuB,KAAEqC,KAFzB,yBAE8CP,EAF9C,oBAfd,YAoBQF,EApBR,iBAsBYU,GAAe,EACbC,EAAc,KAAKC,WAAW,GAC9BC,EAAWb,EAASY,WAAW,GAC5B5C,EAAI,EAzBrB,aAyBwBA,EAAIqC,EAAMpC,QAzBlC,oBA0BgBD,IAAM0C,EAAc,GAAKL,EAAMrC,KAAO6C,EA1BtD,qDA6BgBR,EAAMrC,KAAO2C,IACbD,EAAc1C,GA9B9B,QAyB0CA,GAAK,EAzB/C,wBAiCQqC,EAAQA,EAAMS,MAAM,EAAGJ,EAAc,GAjC7C,iCAmCWL,GAnCX,2D,wGA2CA,uGAAgBjD,EAAhB,+BAAuB,GAAvB,SACwB/C,KAAK0G,gBAAgB3D,GAD7C,cACUiD,EADV,QAEI,EAAIpF,EAAO0C,kBAAkBP,EAAKQ,QAFtC,kBAGWyC,EAAMxB,SAAS,SAH1B,gD,wHAaA,uGAAgCzB,EAAhC,+BAAuC,GAAvC,SAC2B/C,KAAKoD,YAAYL,GAD5C,cACUM,EADV,yBAEWA,EAASsD,aAFpB,gD,6EAcA,WAAgEC,EAAeC,EAAaC,EAAWzB,GAAM,IAAjG0B,EAAiG,EAAjGA,cAAepB,EAAkF,EAAlFA,SAAUqB,EAAwE,EAAxEA,eAAgBC,EAAwD,EAAxDA,OAEjD,GAAI5B,EAAK6B,OAAO,KAAOvB,EACnB,MAAO,CAAEH,UAAU,GAGvB,IAAM2B,EAAoBJ,EAApBI,IAAKtE,EAAekE,EAAflE,MAAOC,EAAQiE,EAARjE,IACbqE,IACDA,EAAM,GAELtE,IACDA,EAAQ,GAEPC,IACDA,EAAM,GAEK,QAAXmE,IACAnE,EAAM,GAUV,IARA,IAAMsE,EAAY7E,KAAK8E,IAAIF,EAAKtE,EAAOC,GAInCwE,EAAsB,EACtBC,EAAqB,EACrBC,EAAS,GACTjC,GAAmBkC,IACd9D,EAAI,EAAGA,EAAI0B,EAAKzB,OAAS,EAAGD,GAAK,EACtC,GAAgB,OAAZ0B,EAAK1B,IAAeA,IAAM0B,EAAKzB,OAAQ,CACvC,GAAI0D,IAAwBH,GACxB,GAAInH,KAAKmC,aAAakD,EAAKoB,MAAMc,EAAoB5D,MACjDiD,EACA,MAAO,CAAEpB,UAAU,QAGtB,GAAI8B,IAAwBzE,EAAO,CAMpC,GALA0C,EAAkBmC,SAASrC,EAAKoB,MAAMc,EAAoB5D,GAAI,IAEvC,mBAAnBqD,IACAzB,GAAmB,GAEnBA,GAAmBuB,EACnB,MAAO,CAAEvB,kBAAiBC,UAAU,GAExC,IAAY,IAAR1C,GAAaA,IAAQD,IAEjB0C,EAAkB,GAAKsB,EACvB,MAAO,CAAEtB,kBAAiBC,UAAU,QAI3C,GAAe,QAAXyB,GAA4C,IAAxBK,EACzBE,EAASnC,EAAKoB,MAAMc,EAAoB5D,QAEvC,GAAI2D,IAAwBxE,EAAK,CASlC,IANe,QAAXmE,EACgBjH,KAAK2H,WAAWpC,EAAiBiC,EAAQnC,EAAKoB,MAAMc,EAAoB5D,IAGxE+D,SAASrC,EAAKoB,MAAMc,EAAoB5D,GAAI,MAE3CkD,EACjB,MAAO,CAAErB,UAAU,GAK3B,GAFA+B,EAAqB5D,EAAI,GACzB2D,GAAuB,GACGF,EACtB,MAIZ,MAAO,CAAE7B,kBAAiBC,UAAU,K,wBAExC,SAAWD,EAAiBiC,EAAQI,GAChC,IAAIC,EAAgBtC,EAAkBiC,EAAO5D,OAMvCkE,GAAwC,IAAhCF,EAAKG,QAAQ,cAC3B,GAAgB,MAAZH,EAAK,IAAeE,GAcnB,GAAIA,EACL,OAAOvC,EAAkB,OAbzB,IADA,IAAIyC,EAAW,IACNC,EAAI,EAAGA,EAAIL,EAAKhE,OAAQqE,GAAK,EAAG,CACrC,GAAiB,MAAbD,GAA6C,SAAzBJ,EAAKnB,MAAMwB,EAAGA,EAAI,GAAe,CACrD,IAAIC,EAAWN,EAAKG,QAAQ,IAAKE,IACf,IAAdC,IACAA,EAAWN,EAAKhE,QAEpBiE,EAAgBH,SAASE,EAAKnB,MAAMwB,EAAI,EAAGC,GAAW,IACtD,MAEJF,EAAWJ,EAAKK,GAMxB,OAAOJ,I,kDAOX,WAAgBjF,GAAhB,wFAAyBG,EAAzB,+BAAgC,GAAhC,kBACW/C,KAAKiC,MAAMkG,UAAUvF,EAASG,IADzC,gD,2GAGA,WAAkBqF,EAAUC,GAA5B,8FAA4CtF,EAA5C,+BAAmD,GAAnD,SACwC/C,KAAKsB,WAAWgH,KAAKC,EAAOC,MAAMH,GAAiB,EAAGA,EAAgBD,EAAUrF,GADxH,uBACY0F,EADZ,EACYA,UAAWhE,EADvB,EACuBA,OADvB,kBAEWgE,EAAYJ,EAAiB5D,EAAOgC,MAAM,EAAGgC,GAAahE,GAFrE,gD,2GAUA,WAAgBiE,GAAhB,0FAAuB3F,EAAvB,+BAA8B,GAA9B,SAGiC/C,KAAK+F,YAAY2C,EAAMxD,KAAKY,cAAe4C,EAAM5E,cAAef,GAHjG,cAGU4F,EAHV,mCAKe,EAAIhI,EAAkBiI,iBAAiBD,EAAgBD,IALtE,sCAQc,IAAI3E,MAAJ,oCAAuC2E,EAAMlE,WAA7C,mBARd,yD,8DAYJnE,EAAQ6B,QAAUd,I,0IChZZyH,E,YACL,aAA0B,IAAd7F,EAAc,uDAAJ,GACrB,GADyB,YACnBA,EAAQV,SAAWU,EAAQV,QAAU,GAC1C,MAAM,IAAIP,UAAU,6CAGrB/B,KAAKsC,QAAUU,EAAQV,QACvBtC,KAAKqC,MAAQ,IAAIyG,IACjB9I,KAAK+I,SAAW,IAAID,IACpB9I,KAAKgJ,MAAQ,E,8BAGd,SAAKC,EAAK3I,GACTN,KAAKqC,MAAM6G,IAAID,EAAK3I,GACpBN,KAAKgJ,QAEDhJ,KAAKgJ,OAAShJ,KAAKsC,UACtBtC,KAAKgJ,MAAQ,EACbhJ,KAAK+I,SAAW/I,KAAKqC,MACrBrC,KAAKqC,MAAQ,IAAIyG,O,iBAInB,SAAIG,GACH,GAAIjJ,KAAKqC,MAAM8G,IAAIF,GAClB,OAAOjJ,KAAKqC,MAAMkC,IAAI0E,GAGvB,GAAIjJ,KAAK+I,SAASI,IAAIF,GAAM,CAC3B,IAAM3I,EAAQN,KAAK+I,SAASxE,IAAI0E,GAGhC,OAFAjJ,KAAK+I,SAASK,OAAOH,GACrBjJ,KAAKqJ,KAAKJ,EAAK3I,GACRA,K,iBAIT,SAAI2I,EAAK3I,GAOR,OANIN,KAAKqC,MAAM8G,IAAIF,GAClBjJ,KAAKqC,MAAM6G,IAAID,EAAK3I,GAEpBN,KAAKqJ,KAAKJ,EAAK3I,GAGTN,O,iBAGR,SAAIiJ,GACH,OAAOjJ,KAAKqC,MAAM8G,IAAIF,IAAQjJ,KAAK+I,SAASI,IAAIF,K,kBAGjD,SAAKA,GACJ,OAAIjJ,KAAKqC,MAAM8G,IAAIF,GACXjJ,KAAKqC,MAAMkC,IAAI0E,GAGnBjJ,KAAK+I,SAASI,IAAIF,GACdjJ,KAAK+I,SAASxE,IAAI0E,QAD1B,I,oBAKD,SAAOA,GACN,IAAMK,EAAUtJ,KAAKqC,MAAM+G,OAAOH,GAKlC,OAJIK,GACHtJ,KAAKgJ,QAGChJ,KAAK+I,SAASK,OAAOH,IAAQK,I,mBAGrC,WACCtJ,KAAKqC,MAAMkH,QACXvJ,KAAK+I,SAASQ,QACdvJ,KAAKgJ,MAAQ,I,0BAGd,4FACqBhJ,MADrB,wDAEE,OAFF,eACaiJ,EADb,cAEQA,EAFR,qM,4BAMA,4FACyBjJ,MADzB,wDAEE,OAFF,eACeM,EADf,cAEQA,EAFR,qM,qBAMA,oGACoBN,KAAKqC,OADzB,wDAEE,OADUmH,EADZ,iBAEQA,EAFR,iJAKoBxJ,KAAK+I,UALzB,8DAKYS,EALZ,YAMgBA,EANhB,GAMSP,EANT,KAOOjJ,KAAKqC,MAAM8G,IAAIF,GAPtB,iBAQG,OARH,UAQSO,EART,uN,gBAaA,WACC,IADU,EACNC,EAAe,EADT,IAEQzJ,KAAK+I,SAASW,QAFtB,IAEV,2BAAwC,KAA7BT,EAA6B,QAClCjJ,KAAKqC,MAAM8G,IAAIF,IACnBQ,KAJQ,8BAQV,OAAOzJ,KAAKgJ,MAAQS,M,GArBlBE,OAAOC,UAyBXC,EAAOxJ,QAAUwI,G,kBCnGjBgB,EAAOxJ,QAfP,SAAuCyJ,EAAQC,GAC7C,GAAc,MAAVD,EAAgB,MAAO,GAC3B,IAEIb,EAAKtF,EAFLqG,EAAS,GACTC,EAAa9J,OAAOuJ,KAAKI,GAG7B,IAAKnG,EAAI,EAAGA,EAAIsG,EAAWrG,OAAQD,IACjCsF,EAAMgB,EAAWtG,GACboG,EAAShC,QAAQkB,IAAQ,IAC7Be,EAAOf,GAAOa,EAAOb,IAGvB,OAAOe,GAGuCH,EAAOxJ,QAAQH,YAAa,EAAM2J,EAAOxJ,QAAiB,QAAIwJ,EAAOxJ,S,iCCdrH,IAAIN,EAAmBC,MAAQA,KAAKD,iBAAoB,SAAUE,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,IAExDE,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtDD,EAAQ6J,IAAM7J,EAAQ8J,IAAM9J,EAAQe,sBAAmB,EACvD,IAAMgJ,EAAqBrK,EAAgBS,EAAQ,OACnDH,EAAQe,iBAAmBgJ,EAAmBlI,QAC9C,IAAMrB,EAAQd,EAAgBS,EAAQ,MACtCH,EAAQ8J,IAAMtJ,EAAMqB,QACpB,IAAMpB,EAAQf,EAAgBS,EAAQ,MACtCH,EAAQ6J,IAAMpJ,EAAMoB,S,mJCVpB/B,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtDD,EAAQgK,eAAiBhK,EAAQiK,eAAiBjK,EAAQkK,gBAAkBlK,EAAQiD,iBAAmBjD,EAAQmK,kBAAe,EAQ9HnK,EAAQmK,aAPR,SAAsBC,GAClB,GAAIA,EAAKC,YAAYC,OAAOC,mBACxBH,EAAKI,SAASF,OAAOG,kBACrB,MAAM,IAAI/G,MAAM,oBAEpB,OAAO0G,EAAKM,Y,IAGVC,E,mGAAmBjH,QAazB,SAAST,EAAiBC,GACtB,GAAKA,GAGDA,EAAO0H,QAAS,CAEhB,GAA4B,qBAAjBC,aAEP,MAAM,IAAIA,aAAa,UAAW,cAGlC,IAAMC,EAAI,IAAIH,EAAW,WAEzB,MADAG,EAAE/E,KAAO,cACH+E,G,gCAWlB,WAA+B5H,GAA/B,+EACUtC,QAAQC,UADlB,OAEIoC,EAAiBC,GAFrB,4C,sBAKA,SAAS+G,EAAec,EAAQC,GAC5B,OAAQA,EAAOnG,KAAKY,cAAgBsF,EAAOE,KAAKxF,cAAgB,MAC5DuF,EAAOC,KAAKxF,cAAgBsF,EAAOlG,KAAKY,cAAgB,IAdhEzF,EAAQiD,iBAAmBA,EAW3BjD,EAAQkK,gB,4CAKRlK,EAAQiK,eAAiBA,EAwCzBjK,EAAQgK,eAvCR,SAAwB3G,EAAQ6H,GAC5B,IAAMC,EAAe,GACjBC,EAAY,KAChB,OAAsB,IAAlB/H,EAAOE,OACAF,GAEXA,EAAOgI,MAAK,SAAUC,EAAIC,GACtB,IAAMC,EAAMF,EAAGzG,KAAKY,cAAgB8F,EAAG1G,KAAKY,cAC5C,OAAY,IAAR+F,EACOA,EAGAF,EAAGzG,KAAKC,aAAeyG,EAAG1G,KAAKC,gBAG9CzB,EAAOoI,SAAQ,SAAApD,KACN6C,GAAU7C,EAAM4C,KAAKS,UAAUR,GAAU,KACxB,OAAdE,GACAD,EAAaQ,KAAKtD,GAClB+C,EAAY/C,GAGR4B,EAAemB,EAAW/C,GACtBA,EAAM4C,KAAKS,UAAUN,EAAUH,MAAQ,IACvCG,EAAUH,KAAO5C,EAAM4C,OAI3BE,EAAaQ,KAAKtD,GAClB+C,EAAY/C,OAQrB8C,K,oBC/FX,IAAIS,EAA+B,EAAQ,KAqB3CpC,EAAOxJ,QAnBP,SAAkCyJ,EAAQC,GACxC,GAAc,MAAVD,EAAgB,MAAO,GAC3B,IACIb,EAAKtF,EADLqG,EAASiC,EAA6BnC,EAAQC,GAGlD,GAAI5J,OAAO+L,sBAAuB,CAChC,IAAIC,EAAmBhM,OAAO+L,sBAAsBpC,GAEpD,IAAKnG,EAAI,EAAGA,EAAIwI,EAAiBvI,OAAQD,IACvCsF,EAAMkD,EAAiBxI,GACnBoG,EAAShC,QAAQkB,IAAQ,GACxB9I,OAAOiM,UAAUC,qBAAqBC,KAAKxC,EAAQb,KACxDe,EAAOf,GAAOa,EAAOb,IAIzB,OAAOe,GAGkCH,EAAOxJ,QAAQH,YAAa,EAAM2J,EAAOxJ,QAAiB,QAAIwJ,EAAOxJ,S,oKCpB5GkM,EAAmBvM,MAAQA,KAAKuM,kBAAqBpM,OAAOqM,OAAU,SAASC,EAAGC,EAAGC,EAAGC,QAC7EzJ,IAAPyJ,IAAkBA,EAAKD,GAC3BxM,OAAOC,eAAeqM,EAAGG,EAAI,CAAEC,YAAY,EAAMtI,IAAK,WAAa,OAAOmI,EAAEC,OAC1E,SAASF,EAAGC,EAAGC,EAAGC,QACTzJ,IAAPyJ,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,KAEVG,EAAsB9M,MAAQA,KAAK8M,qBAAwB3M,OAAOqM,OAAU,SAASC,EAAGM,GACxF5M,OAAOC,eAAeqM,EAAG,UAAW,CAAEI,YAAY,EAAMvM,MAAOyM,KAC9D,SAASN,EAAGM,GACbN,EAAC,QAAcM,IAEfC,EAAgBhN,MAAQA,KAAKgN,cAAiB,SAAU/M,GACxD,GAAIA,GAAOA,EAAIC,WAAY,OAAOD,EAClC,IAAIgN,EAAS,GACb,GAAW,MAAPhN,EAAa,IAAK,IAAI0M,KAAK1M,EAAe,YAAN0M,GAAmBxM,OAAOiM,UAAUc,eAAeZ,KAAKrM,EAAK0M,IAAIJ,EAAgBU,EAAQhN,EAAK0M,GAEtI,OADAG,EAAmBG,EAAQhN,GACpBgN,GAEPlN,EAAmBC,MAAQA,KAAKD,iBAAoB,SAAUE,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,IAExDE,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,IAAM6M,EAASpN,EAAgBS,EAAQ,MACjC4M,EAAkBJ,EAAaxM,EAAQ,MACvC6M,EAAUtN,EAAgBS,EAAQ,MAClCG,EAAoBH,EAAQ,KAC5BI,EAASJ,EAAQ,KACjB8M,EAAcvN,EAAgBS,EAAQ,MACtC+M,EAAY,SAKlB,SAASC,EAASC,EAAK3K,GAGnB,MAAO,CACH,CAAC,EAAG,GACJ,CAAC,IAJL2K,GAAO,IAIU,IAAK,IAHtB3K,GAAO,IAG2B,KAC9B,CAAC,GAAK2K,GAAO,IAAK,GAAK3K,GAAO,KAC9B,CAAC,IAAM2K,GAAO,IAAK,IAAM3K,GAAO,KAChC,CAAC,KAAO2K,GAAO,IAAK,KAAO3K,GAAO,KAClC,CAAC,MAAQ2K,GAAO,IAAK,MAAQ3K,GAAO,M,IAGtC4K,E,kJACF,WAAgB9K,GAAhB,8FAAyBG,EAAzB,+BAAgC,GAAhC,SAC4B/C,KAAK2N,MAAM5K,GADvC,UACU6K,EADV,iDAGgB,GAHhB,UAKUC,EAAQD,EAAUE,YAAYlL,GACxBgL,EAAUG,QAAQF,GANlC,2CAQgB,GARhB,aAUYG,EAAUJ,EAAUG,QAAQF,GAA5BG,OAVZ,0CAYeA,EAAM7F,WAZrB,kCAcY,GAdZ,iD,sGAkBA,kJAAapF,EAAb,+BAAoB,GAApB,KAC4BpC,EAAkBsF,MAD9C,SAC4DjG,KAAKsB,WAAW2M,SAASlL,GADrF,4DACUiD,EADV,QAEI,EAAIpF,EAAO0C,kBAAkBP,EAAKQ,QAE9ByC,EAAMkI,aAAa,KAAOX,EAJlC,uBAKc,IAAIxJ,MAAM,kBALxB,WASUoK,EAAWnI,EAAMoI,YAAY,GAC7BC,EAAcrI,EAAMoI,YAAY,GAChCpH,EAA+B,MAAdqH,EAAwB,uBAAyB,iBAMlEpH,EALa,CACf,EAAG,UACH,EAAG,MACH,EAAG,OAEiC,GAAdoH,GAjB9B,uBAmBc,IAAItK,MAAJ,4CAA+CsK,IAnB7D,eAqBUtH,EAAgB,CAClBI,IAAKnB,EAAMoI,YAAY,IACvBvL,MAAOmD,EAAMoI,YAAY,IACzBtL,IAAKkD,EAAMoI,YAAY,KAErBE,EAAYtI,EAAMoI,YAAY,IAE9BG,IAAiB,GAAoB,IADrCC,EAAQ,GACwB,IAAW,GAAK,EAChDhL,EA7BV,SA6ByB,EAAM,GAAa,EAARgL,GAC1B7I,EAAW2I,EAAYG,OAAOC,aAAaJ,GAAa,KACxDK,EAAY3I,EAAMoI,YAAY,IAE9BQ,EAAoB5I,EAAMoI,YAAY,IAjChD,EAkCyCpO,KAAK6O,gBAAgB7I,EAAMS,MAAM,GAAI,GAAKmI,IAAvEd,EAlCZ,EAkCYA,YAAanH,EAlCzB,EAkCyBA,YAEjBmI,EAAa,GAAKF,EAEhBb,EAAU,IAAIgB,MAAMZ,GAAU1L,KAAK,GAAGuM,KAAI,WAE5C,IAAMC,EAAWjJ,EAAMoI,YAAYU,GACnCA,GAAc,EAGd,IAFA,IACId,EADEkB,EAAW,GAERjH,EAAI,EAAGA,EAAIgH,EAAUhH,GAAK,EAAG,CAClC,IAAMkH,EAAMnJ,EAAMkI,aAAaY,GAE/B,GADAA,GAAc,EACVK,EAAMZ,EAAe,EACrB,MAAM,IAAIxK,MAAM,8DAEf,GAAIoL,IAAQZ,EAAe,EAAG,CAC/B,IAAMa,EAAapJ,EAAMoI,YAAYU,GACrCA,GAAc,EACK,IAAfM,IACApB,EAAQ,EAAKqB,eAAerJ,EAAO8I,IAEvCA,GAAc,GAAKM,MAElB,CACD,IAAMA,EAAapJ,EAAMoI,YAAYU,GACrCA,GAAc,EAEd,IADA,IAAMpL,EAAS,IAAIqL,MAAMK,GAChBzC,EAAI,EAAGA,EAAIyC,EAAYzC,GAAK,EAAG,CACpC,IAAM2C,GAAI,EAAIlC,EAAgBmC,WAAWvJ,EAAO8I,GAC1C/B,GAAI,EAAIK,EAAgBmC,WAAWvJ,EAAO8I,EAAa,GAC7DA,GAAc,GACdpJ,EAAgB,EAAK8J,eAAe9J,EAAe4J,GACnD5L,EAAOiJ,GAAK,IAAIU,EAAQnL,QAAQoN,EAAGvC,EAAGoC,GAE1CD,EAASC,GAAOzL,GAIxB,IAAM+L,EAAczJ,EAAMoI,YAAYU,GACtCA,GAAc,EAEd,IADA,IAAMY,EAAc,IAAIX,MAAMU,GACrB9C,EAAI,EAAGA,EAAI8C,EAAa9C,GAAK,EAClC+C,EAAY/C,IAAK,EAAIS,EAAgBmC,WAAWvJ,EAAO8I,GACvDA,GAAc,EACdpJ,EAAgB,EAAK8J,eAAe9J,EAAegK,EAAY/C,IAEnE,MAAO,CAAEuC,WAAUQ,cAAa1B,YAjFxC,kBAmFW,CACHD,UACApI,WACA4I,eACA/K,eACAmL,YACAjJ,gBACAqB,gBACAC,iBACAC,SACAN,cACAmH,cACAlI,aAAc,QA/FtB,iD,kFAkGA,SAAeI,EAAO2J,GAElB,MAAO,CAAExH,WADS,EAAIvH,EAAO4J,cAAc2C,EAAOjL,QAAQ0N,YAAY5J,EAAMS,MAAMkJ,EAAS,GAAIA,EAAS,KAAK,O,6BAGjH,SAAgBE,GAKZ,IAJA,IAAIC,EAAY,EACZC,EAAgB,EACdpJ,EAAc,GACdmH,EAAc,GACXnK,EAAI,EAAGA,EAAIkM,EAAWjM,OAAQD,GAAK,EACxC,IAAKkM,EAAWlM,GAAI,CAChB,GAAIoM,EAAgBpM,EAAG,CACnB,IAAIf,EAAUiN,EAAWrL,SAAS,OAAQuL,EAAepM,GACzDf,EAAU5C,KAAKmC,aAAaS,GAC5B+D,EAAYmJ,GAAalN,EACzBkL,EAAYlL,GAAWkN,EAE3BC,EAAgBpM,EAAI,EACpBmM,GAAa,EAGrB,MAAO,CAAEhC,cAAanH,iB,uDAE1B,WAAqB/D,EAASoN,EAAK3I,GAAnC,8HAAwCtE,EAAxC,+BAA+C,GACvCiN,EAAM,IACNA,EAAM,GAFd,SAI4BhQ,KAAK2N,MAAM5K,GAJvC,UAIU6K,EAJV,gDAMe,IANf,UAQUC,EAAQD,EAAUE,YAAYlL,GAC9BqN,EAAKrC,EAAUG,QAAQF,GATjC,0CAWe,IAXf,SAasBoC,EAAGP,YAAY9L,OAC3BqM,EAAGP,YAAYM,GA1KN,IA0K+BC,EAAGP,YAAY9L,OACnDqM,EAAGP,YAAY9L,OAAS,EACxBoM,GA5KK,IA6KT,IAAI5C,EAAgBlL,QAAQ,EAAG,KAEjCgE,QAAQgK,KAAK,4CAGXC,EAAkB3C,EAASwC,EAAK3I,GAChC3D,EAAS,GAvBnB,IAyB+ByM,GAzB/B,IAyBI,2BACI,IADwC,eAAhCtN,EAAgC,KAAzBC,EAAyB,KAC/BqM,EAAMtM,EAAOsM,GAAOrM,EAAKqM,IAC9B,GAAIc,EAAGf,SAASC,GAEZ,IADMiB,EAAYH,EAAGf,SAASC,GACrB7K,EAAI,EAAGA,EAAI8L,EAAUxM,SAAUU,EACpCZ,EAAOsI,KAAK,IAAIqB,EAAQnL,QAAQkO,EAAU9L,GAAGY,KAAMkL,EAAU9L,GAAGgH,KAAM6D,IA9B1F,8BAyCI,IAJMkB,EAAQJ,EAAGP,YAAY9L,OACzB2H,EAAS,KACP+E,EAAS/N,KAAKyN,IAAIA,GAAO,GAAIK,EAAQ,GACrCE,EAAShO,KAAKyN,IAAI3I,GAAO,GAAIgJ,EAAQ,GAClC1M,EAAI2M,EAAQ3M,GAAK4M,IAAU5M,GAC1B6M,EAAKP,EAAGP,YAAY/L,OAEjB4H,GAAUiF,EAAGzE,UAAUR,GAAU,KAClCA,EAASiF,GA7CzB,0BAiDW,EAAI5P,EAAOyJ,gBAAgB3G,EAAQ6H,IAjD9C,iD,gEA5IqB+B,EAAYpL,SAgMrC7B,EAAQ6B,QAAUwL,G,uEC9OlBvN,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtDD,EAAQkP,eAAY,E,IACdkB,E,WACF,WAAY3K,EAAeX,GAAc,UACrCnF,KAAK8F,cAAgBA,EACrB9F,KAAKmF,aAAeA,E,kCAExB,WACI,gBAAUnF,KAAK8F,cAAf,YAAgC9F,KAAKmF,gB,uBAEzC,SAAUuL,GACN,OAAQ1Q,KAAK8F,cAAgB4K,EAAE5K,eAAiB9F,KAAKmF,aAAeuL,EAAEvL,gB,kBAE1E,WAAoB,IAChB,IAAI6K,EACArM,EAAI,EAFQ,mBAANgN,EAAM,yBAANA,EAAM,gBAGhB,MAAQX,EAAKrM,GAAK,EACdqM,EAAMW,EAAKhN,GAEf,KAAOA,EAAIgN,EAAK/M,OAAQD,GAAK,EACrBqM,EAAIjE,UAAU4E,EAAKhN,IAAM,IACzBqM,EAAMW,EAAKhN,IAGnB,OAAOqM,M,KAGf3P,EAAQ6B,QAAUuO,EAYlBpQ,EAAQkP,UAXR,SAAmBvJ,GAAsC,IAA/B2J,EAA+B,uDAAtB,EAAGiB,EAAmB,wDACrD,GAAIA,EACA,MAAM,IAAI7M,MAAM,mDAEpB,OAAO,IAAI0M,EAAkC,cAApBzK,EAAM2J,EAAS,GAChB,WAApB3J,EAAM2J,EAAS,GACK,SAApB3J,EAAM2J,EAAS,GACK,MAApB3J,EAAM2J,EAAS,GACK,IAApB3J,EAAM2J,EAAS,GACf3J,EAAM2J,EAAS,GAAK3J,EAAM2J,EAAS,IAAM,EAAK3J,EAAM2J,M,uECrC5DxP,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,I,IAEhDuQ,E,WAOF,WAAY3L,EAAMoG,EAAM6D,GAA8B,IAAzBrL,EAAyB,4DAAXX,EAAW,UAClDnD,KAAKkF,KAAOA,EACZlF,KAAKsL,KAAOA,EACZtL,KAAKmP,IAAMA,EACXnP,KAAK8Q,aAAehN,E,wCAExB,WACI,gBAAU9D,KAAKkF,KAAf,aAAwBlF,KAAKsL,KAA7B,iBAA0CtL,KAAKmP,IAA/C,yBAAmEnP,KAAK8D,cAAxE,O,sBAEJ,WACI,OAAO9D,KAAK+Q,mB,uBAEhB,SAAUL,GACN,OAAQ1Q,KAAKkF,KAAK6G,UAAU2E,EAAExL,OAC1BlF,KAAKsL,KAAKS,UAAU2E,EAAEpF,OACtBtL,KAAKmP,IAAMuB,EAAEvB,M,yBAErB,WACI,YAA0BhM,IAAtBnD,KAAK8Q,aACE9Q,KAAK8Q,aAET9Q,KAAKsL,KAAKxF,cAAV,MAAsC9F,KAAKkF,KAAKY,kB,KAG/DzF,EAAQ6B,QAAU2O,G,+HCjCd9Q,EAAmBC,MAAQA,KAAKD,iBAAoB,SAAUE,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,IAExDE,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,IAAMC,EAA4BR,EAAgBS,EAAQ,MACpDC,EAAcV,EAAgBS,EAAQ,MACtCwQ,E,WAKF,cAAuD,IAAzC1P,EAAyC,EAAzCA,WAAyC,IAA7BM,qBAA6B,MAAb,SAACC,GAAD,OAAOA,GAAM,YACnD7B,KAAKsB,WAAaA,EAClBtB,KAAKmC,aAAeP,E,gEAExB,yGAAkBmB,EAAlB,+BAAyB,GAAzB,SAEuC/C,KAAK2N,MAAM5K,GAFlD,yBAEYgL,QAAYkD,EAFxB,yBAGWA,GAHX,gD,kFAKA,SAAeC,EAAYC,GACvB,OAAID,EACOA,EAAWnF,UAAUoF,GAAiB,EACvCA,EACAD,EAGCC,I,8CAGf,4GAAYpO,EAAZ,+BAAmB,GACV/C,KAAKoR,cACNpR,KAAKoR,YAAc,IAAI7Q,EAA0B2B,QAAQ,CACrDG,MAAO,IAAI5B,EAAYyB,QAAQ,CAAEI,QAAS,IAC1CG,KAAM,kBAAM,EAAK4O,OAAOtO,OAJpC,kBAOW/C,KAAKoR,YAAY7M,IAAI,QAAS,UAAMpB,IAP/C,gD,wGASA,WAAgBmO,GAAhB,wFAAuBvO,EAAvB,+BAA8B,GAA9B,SACqB/C,KAAK2N,MAAM5K,GADhC,eAC+CuO,EAD/C,YACuCvD,QADvC,gCACyD,GADzD,uCAC6DmB,UAD7D,gD,8DAIJ7O,EAAQ6B,QAAU8O,G,qLC3CdzE,EAAmBvM,MAAQA,KAAKuM,kBAAqBpM,OAAOqM,OAAU,SAASC,EAAGC,EAAGC,EAAGC,QAC7EzJ,IAAPyJ,IAAkBA,EAAKD,GAC3BxM,OAAOC,eAAeqM,EAAGG,EAAI,CAAEC,YAAY,EAAMtI,IAAK,WAAa,OAAOmI,EAAEC,OAC1E,SAASF,EAAGC,EAAGC,EAAGC,QACTzJ,IAAPyJ,IAAkBA,EAAKD,GAC3BF,EAAEG,GAAMF,EAAEC,KAEVG,EAAsB9M,MAAQA,KAAK8M,qBAAwB3M,OAAOqM,OAAU,SAASC,EAAGM,GACxF5M,OAAOC,eAAeqM,EAAG,UAAW,CAAEI,YAAY,EAAMvM,MAAOyM,KAC9D,SAASN,EAAGM,GACbN,EAAC,QAAcM,IAEfC,EAAgBhN,MAAQA,KAAKgN,cAAiB,SAAU/M,GACxD,GAAIA,GAAOA,EAAIC,WAAY,OAAOD,EAClC,IAAIgN,EAAS,GACb,GAAW,MAAPhN,EAAa,IAAK,IAAI0M,KAAK1M,EAAe,YAAN0M,GAAmBxM,OAAOiM,UAAUc,eAAeZ,KAAKrM,EAAK0M,IAAIJ,EAAgBU,EAAQhN,EAAK0M,GAEtI,OADAG,EAAmBG,EAAQhN,GACpBgN,GAEPlN,EAAmBC,MAAQA,KAAKD,iBAAoB,SAAUE,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,IAExDE,OAAOC,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,IAAM6M,EAASpN,EAAgBS,EAAQ,MACjCG,EAAoBH,EAAQ,KAC5B4M,EAAkBJ,EAAaxM,EAAQ,MACvC6M,EAAUtN,EAAgBS,EAAQ,MAClCI,EAASJ,EAAQ,KACjB8M,EAAcvN,EAAgBS,EAAQ,MACtC+Q,EAAa,SACbC,EAAa,SAInB,SAASC,EAAOC,EAAKC,GACjB,OAAOpP,KAAKC,MAAMkP,EAAM,KAAH,IAAG,EAAKC,I,IAE3BzH,E,8BACF,WAAYyG,GAAM,wBACd,cAAMA,IACDpC,aAAe,EACpB,EAAKC,MAAQ,EACb,EAAKoD,SAAW,EAJF,E,8DAMlB,WAAgBhP,GAAhB,8FAAyBG,EAAzB,+BAAgC,GAAhC,SAC4B/C,KAAK2N,MAAM5K,GADvC,UACU6K,EADV,iDAGgB,GAHhB,UAKUC,EAAQD,EAAUE,YAAYlL,GACxBgL,EAAUG,QAAQF,GANlC,2CAQgB,GARhB,aAUYG,EAAUJ,EAAUG,QAAQF,GAA5BG,OAVZ,0CAYeA,EAAM7F,WAZrB,kCAcY,GAdZ,iD,wGAgBA,kFACU,IAAIpE,MAAM,uCADpB,2C,gFAIA,SAAaiC,EAAO2J,EAAQkC,GACxB,GAAIA,EAAY,GACZ,MAAO,CACHlL,YAAa,GACbmH,YAAa,IAGrB,IAAMO,EAAcrI,EAAMoI,YAAYuB,GAChC3I,EAA+B,MAAdqH,EAAwB,uBAAyB,iBAClEpH,EAAS,CAAE,EAAG,UAAW,EAAG,MAAO,EAAG,OAAsB,GAAdoH,GACpD,IAAKpH,EACD,MAAM,IAAIlD,MAAJ,4CAA+CsK,IAEzD,IAAMtH,EAAgB,CAClBI,IAAKnB,EAAMoI,YAAYuB,EAAS,GAChC9M,MAAOmD,EAAMoI,YAAYuB,EAAS,GAClC7M,IAAKkD,EAAMoI,YAAYuB,EAAS,KAE9BrB,EAAYtI,EAAMoI,YAAYuB,EAAS,IACvChK,EAAW2I,EAAYG,OAAOC,aAAaJ,GAAa,GACxDK,EAAY3I,EAAMoI,YAAYuB,EAAS,IACvCf,EAAoB5I,EAAMoI,YAAYuB,EAAS,IACrD,EAAqC3P,KAAK6O,gBAAgB7I,EAAMS,MAAMkJ,EAAS,GAAIA,EAAS,GAAKf,IACjG,MAAO,CACHjI,YAFJ,EAAQA,YAGJmH,YAHJ,EAAqBA,YAIjBa,YACAhJ,WACAoB,gBACAE,SACAD,oB,6BAGR,SAAgB6I,GAKZ,IAJA,IAAIC,EAAY,EACZC,EAAgB,EACdpJ,EAAc,GACdmH,EAAc,GACXnK,EAAI,EAAGA,EAAIkM,EAAWjM,OAAQD,GAAK,EACxC,IAAKkM,EAAWlM,GAAI,CAChB,GAAIoM,EAAgBpM,EAAG,CACnB,IAAIf,EAAUiN,EAAWrL,SAAS,OAAQuL,EAAepM,GACzDf,EAAU5C,KAAKmC,aAAaS,GAC5B+D,EAAYmJ,GAAalN,EACzBkL,EAAYlL,GAAWkN,EAE3BC,EAAgBpM,EAAI,EACpBmM,GAAa,EAGrB,MAAO,CAAEhC,cAAanH,iB,+CAG1B,8HAAa5D,EAAb,+BAAoB,GAApB,KAC4BpC,EAAkBsF,MAD9C,SAC4DjG,KAAKsB,WAAW2M,SAASlL,GADrF,6DACUiD,EADV,QAIckI,aAAa,KAAOqD,EAJlC,iBAKQO,EAAa,EALrB,2BAOa9L,EAAMkI,aAAa,KAAOsD,EAPvC,iBAQQM,EAAa,EARrB,8BAWc,IAAI/N,MAAM,kBAXxB,eAcI/D,KAAK4R,SAAW5L,EAAMoI,YAAY,GAClCpO,KAAKwO,MAAQxI,EAAMoI,YAAY,GAC/BpO,KAAKuO,eAAiB,GAAyB,GAAlBvO,KAAKwO,MAAQ,IAAW,GAAK,EACpDhL,EAjBV,SAiByB,EAAMxD,KAAK4R,SAAwB,EAAb5R,KAAKwO,OAC1CqD,EAAY7L,EAAMoI,YAAY,IAChC2D,EAAM,CACNpL,YAAa,GACbmH,YAAa,IAEb+D,IACAE,EAAM/R,KAAKgS,aAAahM,EAAO,GAAI6L,IAEjC1D,EAAWnI,EAAMoI,YAAY,GAAKyD,GAGpC/C,EAAa,GAAK+C,EAAY,EAC5B9D,EAAU,IAAIgB,MAAMZ,GAAU1L,KAAK,GAAGuM,KAAI,WAE5C,IAAMC,EAAWjJ,EAAMoI,YAAYU,GACnCA,GAAc,EAGd,IAFA,IACId,EADEkB,EAAW,GAERjH,EAAI,EAAGA,EAAIgH,EAAUhH,GAAK,EAAG,CAClC,IAAMkH,EAAMnJ,EAAMkI,aAAaY,GAC/B,GAAIK,EAAM,EAAKZ,aAGXP,EAAQ,EAAKqB,eAAerJ,EAAO8I,EAAa,GAChDA,GAAc,OAEb,CACD,IAAMmD,GAAU,EAAI7E,EAAgBmC,WAAWvJ,EAAO8I,EAAa,GACnEpJ,EAAgB,EAAK8J,eAAe9J,EAAeuM,GACnD,IAAM7C,EAAapJ,EAAMoI,YAAYU,EAAa,IAClDA,GAAc,GAEd,IADA,IAAMpL,EAAS,IAAIqL,MAAMK,GAChBzC,EAAI,EAAGA,EAAIyC,EAAYzC,GAAK,EAAG,CACpC,IAAM2C,GAAI,EAAIlC,EAAgBmC,WAAWvJ,EAAO8I,GAC1C/B,GAAI,EAAIK,EAAgBmC,WAAWvJ,EAAO8I,EAAa,GAC7DA,GAAc,GAEdpL,EAAOiJ,GAAK,IAAIU,EAAQnL,QAAQoN,EAAGvC,EAAGoC,GAE1CD,EAASC,GAAOzL,GAGxB,MAAO,CAAEwL,WAAUlB,YA5D3B,yBA+DW+D,GA/DX,IAgEQG,KAAK,EACL/D,WACAvI,aAAc,MACdF,gBACAoM,aACA/D,UACAS,MAAOxO,KAAKwO,MACZD,aAAcvO,KAAKuO,aACnB/K,kBAxER,iD,kFA2EA,SAAewC,EAAO2J,GAElB,MAAO,CAAExH,WADS,EAAIvH,EAAO4J,cAAc2C,EAAOjL,QAAQ0N,YAAYb,MAAM3C,UAAU3F,MAAM6F,KAAKtG,EAAO2J,EAAS,GAAIA,EAAS,KAAK,O,uDAGvI,WAAqB/M,EAASoN,EAAK3I,GAAnC,kHAAwCtE,EAAxC,+BAA+C,GACvCiN,EAAM,IACNA,EAAM,GAFd,SAI4BhQ,KAAK2N,MAAM5K,GAJvC,UAIU6K,EAJV,gDAMe,IANf,UAQUC,EAAQD,EAAUE,YAAYlL,GAC9BqN,EAAKrC,EAAUG,QAAQF,GATjC,0CAWe,IAXf,QAcUsC,EAAkBnQ,KAAKwN,SAASwC,EAAK3I,GACrC3D,EAAS,GAfnB,IAiB+ByM,GAjB/B,IAiBI,2BACI,IADwC,eAAhCtN,EAAgC,KAAzBC,EAAyB,KAC/BqM,EAAMtM,EAAOsM,GAAOrM,EAAKqM,IAC9B,GAAIc,EAAGf,SAASC,GAEZ,IADMiB,EAAYH,EAAGf,SAASC,GACrB7K,EAAI,EAAGA,EAAI8L,EAAUxM,SAAUU,EACpCZ,EAAOsI,KAAK,IAAIqB,EAAQnL,QAAQkO,EAAU9L,GAAGY,KAAMkL,EAAU9L,GAAGgH,KAAM6D,IAtB1F,wDA2BW,EAAIvO,EAAOyJ,gBAAgB3G,EAAQ,IAAI0J,EAAgBlL,QAAQ,EAAG,KA3B7E,iD,iFAgCA,SAASuL,EAAK3K,IACV2K,GAAO,GACG,IACNA,EAAM,GAEN3K,EAAM,KAAH,IAAG,EAAK,MACXA,EAAM,KAAH,IAAG,EAAK,KAEfA,GAAO,EAKP,IAJA,IA9Ma6O,EA8MTQ,EAAI,EACJC,EAAI,EACJC,EAAIrS,KAAK4R,SAAwB,EAAb5R,KAAKwO,MACvB8D,EAAO,GACNH,GAAKnS,KAAKwO,MAAO6D,GAAK,EAAGD,IAlNnBT,EAkNsC,EAAJQ,EAAH,EAjNnC,KAAH,IAAG,EAAKR,IAiNyCQ,GAAK,EAAG,CAC3D,IAAMzB,EAAI0B,EAAIX,EAAOhE,EAAK4E,GACpBlH,EAAIiH,EAAIX,EAAO3O,EAAKuP,GAC1B,GAAIlH,EAAIuF,EAAI4B,EAAK1O,OAAS5D,KAAKuO,aAC3B,MAAM,IAAIxK,MAAJ,gBAAmB0J,EAAnB,YAA0B3K,EAA1B,2DAAgF9C,KAAK4R,SAArF,mBAAwG5R,KAAKwO,MAA7G,6DAEV8D,EAAKtG,KAAK,CAAC0E,EAAGvF,IAElB,OAAOmH,M,GApNGhF,EAAYpL,SAuN9B7B,EAAQ6B,QAAUgI","file":"static/js/2.c0552638.chunk.js","sourcesContent":["\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortable_promise_cache_1 = __importDefault(require(\"abortable-promise-cache\"));\nconst quick_lru_1 = __importDefault(require(\"quick-lru\"));\nconst generic_filehandle_1 = require(\"generic-filehandle\");\nconst bgzf_filehandle_1 = require(\"@gmod/bgzf-filehandle\");\nconst util_1 = require(\"./util\");\nconst tbi_1 = __importDefault(require(\"./tbi\"));\nconst csi_1 = __importDefault(require(\"./csi\"));\nfunction timeout(time) {\n    return new Promise(resolve => {\n        setTimeout(resolve, time);\n    });\n}\nclass TabixIndexedFile {\n    /**\n     * @param {object} args\n     * @param {string} [args.path]\n     * @param {filehandle} [args.filehandle]\n     * @param {string} [args.tbiPath]\n     * @param {filehandle} [args.tbiFilehandle]\n     * @param {string} [args.csiPath]\n     * @param {filehandle} [args.csiFilehandle]\n     * @param {chunkSizeLimit} default 50MiB\n     * @param {function} [args.renameRefSeqs] optional function with sig `string => string` to transform\n     * reference sequence names for the purpose of indexing and querying. note that the data that is returned is\n     * not altered, just the names of the reference sequences that are used for querying.\n     * @param {number} [args.chunkCacheSize] maximum size in bytes of the chunk cache. default 5MB\n     * @param {number} [args.blockCacheSize] maximum size in bytes of the block cache. default 5MB\n     */\n    constructor({ path, filehandle, tbiPath, tbiFilehandle, csiPath, csiFilehandle, chunkSizeLimit = 50000000, renameRefSeqs = n => n, chunkCacheSize = 5 * 2 ** 20, }) {\n        if (filehandle) {\n            this.filehandle = filehandle;\n        }\n        else if (path) {\n            this.filehandle = new generic_filehandle_1.LocalFile(path);\n        }\n        else {\n            throw new TypeError('must provide either filehandle or path');\n        }\n        if (tbiFilehandle) {\n            this.index = new tbi_1.default({\n                filehandle: tbiFilehandle,\n                renameRefSeqs,\n            });\n        }\n        else if (csiFilehandle) {\n            this.index = new csi_1.default({\n                filehandle: csiFilehandle,\n                renameRefSeqs,\n            });\n        }\n        else if (tbiPath) {\n            this.index = new tbi_1.default({\n                filehandle: new generic_filehandle_1.LocalFile(tbiPath),\n                renameRefSeqs,\n            });\n        }\n        else if (csiPath) {\n            this.index = new csi_1.default({\n                filehandle: new generic_filehandle_1.LocalFile(csiPath),\n                renameRefSeqs,\n            });\n        }\n        else if (path) {\n            this.index = new tbi_1.default({\n                filehandle: new generic_filehandle_1.LocalFile(`${path}.tbi`),\n                renameRefSeqs,\n            });\n        }\n        else {\n            throw new TypeError('must provide one of tbiFilehandle, tbiPath, csiFilehandle, or csiPath');\n        }\n        this.chunkSizeLimit = chunkSizeLimit;\n        this.renameRefSeq = renameRefSeqs;\n        this.chunkCache = new abortable_promise_cache_1.default({\n            cache: new quick_lru_1.default({\n                maxSize: Math.floor(chunkCacheSize / (1 << 16)),\n            }),\n            fill: this.readChunk.bind(this),\n        });\n    }\n    /**\n     * @param {string} refName name of the reference sequence\n     * @param {number} start start of the region (in 0-based half-open coordinates)\n     * @param {number} end end of the region (in 0-based half-open coordinates)\n     * @param {function|object} lineCallback callback called for each line in the region. can also pass a object param containing obj.lineCallback, obj.signal, etc\n     * @returns {Promise} resolved when the whole read is finished, rejected on error\n     */\n    async getLines(refName, start, end, opts) {\n        let signal;\n        let options = {};\n        let callback;\n        if (typeof opts === 'undefined') {\n            throw new TypeError('line callback must be provided');\n        }\n        if (typeof opts === 'function') {\n            callback = opts;\n        }\n        else {\n            options = opts;\n            callback = opts.lineCallback;\n        }\n        if (refName === undefined) {\n            throw new TypeError('must provide a reference sequence name');\n        }\n        if (!callback) {\n            throw new TypeError('line callback must be provided');\n        }\n        const metadata = await this.index.getMetadata(options);\n        (0, util_1.checkAbortSignal)(signal);\n        if (!start) {\n            start = 0;\n        }\n        if (!end) {\n            end = metadata.maxRefLength;\n        }\n        if (!(start <= end)) {\n            throw new TypeError('invalid start and end coordinates. start must be less than or equal to end');\n        }\n        if (start === end) {\n            return;\n        }\n        const chunks = await this.index.blocksForRange(refName, start, end, options);\n        (0, util_1.checkAbortSignal)(signal);\n        // check the chunks for any that are over the size limit.  if\n        // any are, don't fetch any of them\n        for (let i = 0; i < chunks.length; i += 1) {\n            const size = chunks[i].fetchedSize();\n            if (size > this.chunkSizeLimit) {\n                throw new Error(`Too much data. Chunk size ${size.toLocaleString()} bytes exceeds chunkSizeLimit of ${this.chunkSizeLimit.toLocaleString()}.`);\n            }\n        }\n        // now go through each chunk and parse and filter the lines out of it\n        let last = Date.now();\n        for (let chunkNum = 0; chunkNum < chunks.length; chunkNum += 1) {\n            let previousStartCoordinate;\n            const c = chunks[chunkNum];\n            const { buffer, cpositions, dpositions } = await this.chunkCache.get(c.toString(), c, signal);\n            const lines = (typeof TextDecoder !== 'undefined'\n                ? new TextDecoder('utf-8').decode(buffer)\n                : buffer.toString()).split('\\n');\n            lines.pop();\n            (0, util_1.checkAbortSignal)(signal);\n            let blockStart = c.minv.dataPosition;\n            let pos;\n            for (let i = 0; i < lines.length; i += 1) {\n                const line = lines[i];\n                for (pos = 0; blockStart >= dpositions[pos]; pos += 1) { }\n                // filter the line for whether it is within the requested range\n                const { startCoordinate, overlaps } = this.checkLine(metadata, refName, start, end, line);\n                // do a small check just to make sure that the lines are really sorted by start coordinate\n                if (previousStartCoordinate !== undefined &&\n                    startCoordinate !== undefined &&\n                    previousStartCoordinate > startCoordinate) {\n                    throw new Error(`Lines not sorted by start coordinate (${previousStartCoordinate} > ${startCoordinate}), this file is not usable with Tabix.`);\n                }\n                previousStartCoordinate = startCoordinate;\n                if (overlaps) {\n                    callback(line.trim(), \n                    // cpositions[pos] refers to actual file offset of a bgzip block boundaries\n                    //\n                    // we multiply by (1 <<8) in order to make sure each block has a \"unique\"\n                    // address space so that data in that block could never overlap\n                    //\n                    // then the blockStart-dpositions is an uncompressed file offset from\n                    // that bgzip block boundary, and since the cpositions are multiplied by\n                    // (1 << 8) these uncompressed offsets get a unique space\n                    cpositions[pos] * (1 << 8) + (blockStart - dpositions[pos]));\n                }\n                else if (startCoordinate !== undefined && startCoordinate >= end) {\n                    // the lines were overlapping the region, but now have stopped, so\n                    // we must be at the end of the relevant data and we can stop\n                    // processing data now\n                    return;\n                }\n                blockStart += line.length + 1;\n                // yield if we have emitted beyond the yield limit\n                if (last - Date.now() > 500) {\n                    last = Date.now();\n                    (0, util_1.checkAbortSignal)(signal);\n                    await timeout(1);\n                }\n            }\n        }\n    }\n    async getMetadata(opts = {}) {\n        return this.index.getMetadata(opts);\n    }\n    /**\n     * get a buffer containing the \"header\" region of\n     * the file, which are the bytes up to the first\n     * non-meta line\n     *\n     * @returns {Promise} for a buffer\n     */\n    async getHeaderBuffer(opts = {}) {\n        const { firstDataLine, metaChar, maxBlockSize } = await this.getMetadata(opts);\n        (0, util_1.checkAbortSignal)(opts.signal);\n        const maxFetch = firstDataLine && firstDataLine.blockPosition\n            ? firstDataLine.blockPosition + maxBlockSize\n            : maxBlockSize;\n        // TODO: what if we don't have a firstDataLine, and the header\n        // actually takes up more than one block? this case is not covered here\n        let bytes = await this._readRegion(0, maxFetch, opts);\n        (0, util_1.checkAbortSignal)(opts.signal);\n        try {\n            bytes = await (0, bgzf_filehandle_1.unzip)(bytes);\n        }\n        catch (e) {\n            console.error(e);\n            throw new Error(\n            //@ts-ignore\n            `error decompressing block ${e.code} at 0 (length ${maxFetch}) ${e}`);\n        }\n        // trim off lines after the last non-meta line\n        if (metaChar) {\n            // trim backward from the end\n            let lastNewline = -1;\n            const newlineByte = '\\n'.charCodeAt(0);\n            const metaByte = metaChar.charCodeAt(0);\n            for (let i = 0; i < bytes.length; i += 1) {\n                if (i === lastNewline + 1 && bytes[i] !== metaByte) {\n                    break;\n                }\n                if (bytes[i] === newlineByte) {\n                    lastNewline = i;\n                }\n            }\n            bytes = bytes.slice(0, lastNewline + 1);\n        }\n        return bytes;\n    }\n    /**\n     * get a string containing the \"header\" region of the\n     * file, is the portion up to the first non-meta line\n     *\n     * @returns {Promise} for a string\n     */\n    async getHeader(opts = {}) {\n        const bytes = await this.getHeaderBuffer(opts);\n        (0, util_1.checkAbortSignal)(opts.signal);\n        return bytes.toString('utf8');\n    }\n    /**\n     * get an array of reference sequence names, in the order in which\n     * they occur in the file.\n     *\n     * reference sequence renaming is not applied to these names.\n     *\n     * @returns {Promise} for an array of string sequence names\n     */\n    async getReferenceSequenceNames(opts = {}) {\n        const metadata = await this.getMetadata(opts);\n        return metadata.refIdToName;\n    }\n    /**\n     * @param {object} metadata metadata object from the parsed index,\n     * containing columnNumbers, metaChar, and format\n     * @param {string} regionRefName\n     * @param {number} regionStart region start coordinate (0-based-half-open)\n     * @param {number} regionEnd region end coordinate (0-based-half-open)\n     * @param {array[string]} line\n     * @returns {object} like `{startCoordinate, overlaps}`. overlaps is boolean,\n     * true if line is a data line that overlaps the given region\n     */\n    checkLine({ columnNumbers, metaChar, coordinateType, format, }, regionRefName, regionStart, regionEnd, line) {\n        // skip meta lines\n        if (line.charAt(0) === metaChar) {\n            return { overlaps: false };\n        }\n        // check ref/start/end using column metadata from index\n        let { ref, start, end } = columnNumbers;\n        if (!ref) {\n            ref = 0;\n        }\n        if (!start) {\n            start = 0;\n        }\n        if (!end) {\n            end = 0;\n        }\n        if (format === 'VCF') {\n            end = 8;\n        }\n        const maxColumn = Math.max(ref, start, end);\n        // this code is kind of complex, but it is fairly fast.\n        // basically, we want to avoid doing a split, because if the lines are really long\n        // that could lead to us allocating a bunch of extra memory, which is slow\n        let currentColumnNumber = 1; // cols are numbered starting at 1 in the index metadata\n        let currentColumnStart = 0;\n        let refSeq = '';\n        let startCoordinate = -Infinity;\n        for (let i = 0; i < line.length + 1; i += 1) {\n            if (line[i] === '\\t' || i === line.length) {\n                if (currentColumnNumber === ref) {\n                    if (this.renameRefSeq(line.slice(currentColumnStart, i)) !==\n                        regionRefName) {\n                        return { overlaps: false };\n                    }\n                }\n                else if (currentColumnNumber === start) {\n                    startCoordinate = parseInt(line.slice(currentColumnStart, i), 10);\n                    // we convert to 0-based-half-open\n                    if (coordinateType === '1-based-closed') {\n                        startCoordinate -= 1;\n                    }\n                    if (startCoordinate >= regionEnd) {\n                        return { startCoordinate, overlaps: false };\n                    }\n                    if (end === 0 || end === start) {\n                        // if we have no end, we assume the feature is 1 bp long\n                        if (startCoordinate + 1 <= regionStart) {\n                            return { startCoordinate, overlaps: false };\n                        }\n                    }\n                }\n                else if (format === 'VCF' && currentColumnNumber === 4) {\n                    refSeq = line.slice(currentColumnStart, i);\n                }\n                else if (currentColumnNumber === end) {\n                    let endCoordinate;\n                    // this will never match if there is no end column\n                    if (format === 'VCF') {\n                        endCoordinate = this._getVcfEnd(startCoordinate, refSeq, line.slice(currentColumnStart, i));\n                    }\n                    else {\n                        endCoordinate = parseInt(line.slice(currentColumnStart, i), 10);\n                    }\n                    if (endCoordinate <= regionStart) {\n                        return { overlaps: false };\n                    }\n                }\n                currentColumnStart = i + 1;\n                currentColumnNumber += 1;\n                if (currentColumnNumber > maxColumn) {\n                    break;\n                }\n            }\n        }\n        return { startCoordinate, overlaps: true };\n    }\n    _getVcfEnd(startCoordinate, refSeq, info) {\n        let endCoordinate = startCoordinate + refSeq.length;\n        // ignore TRA features as they specify CHR2 and END\n        // as being on a different chromosome\n        // if CHR2 is on the same chromosome, still ignore it\n        // because there should be another pairwise feature\n        // at the end of this one\n        const isTRA = info.indexOf('SVTYPE=TRA') !== -1;\n        if (info[0] !== '.' && !isTRA) {\n            let prevChar = ';';\n            for (let j = 0; j < info.length; j += 1) {\n                if (prevChar === ';' && info.slice(j, j + 4) === 'END=') {\n                    let valueEnd = info.indexOf(';', j);\n                    if (valueEnd === -1) {\n                        valueEnd = info.length;\n                    }\n                    endCoordinate = parseInt(info.slice(j + 4, valueEnd), 10);\n                    break;\n                }\n                prevChar = info[j];\n            }\n        }\n        else if (isTRA) {\n            return startCoordinate + 1;\n        }\n        return endCoordinate;\n    }\n    /**\n     * return the approximate number of data lines in the given reference sequence\n     * @param {string} refSeq reference sequence name\n     * @returns {Promise} for number of data lines present on that reference sequence\n     */\n    async lineCount(refName, opts = {}) {\n        return this.index.lineCount(refName, opts);\n    }\n    async _readRegion(position, compressedSize, opts = {}) {\n        const { bytesRead, buffer } = await this.filehandle.read(Buffer.alloc(compressedSize), 0, compressedSize, position, opts);\n        return bytesRead < compressedSize ? buffer.slice(0, bytesRead) : buffer;\n    }\n    /**\n     * read and uncompress the data in a chunk (composed of one or more\n     * contiguous bgzip blocks) of the file\n     * @param {Chunk} chunk\n     * @returns {Promise} for a string chunk of the file\n     */\n    async readChunk(chunk, opts = {}) {\n        // fetch the uncompressed data, uncompress carefully a block at a time,\n        // and stop when done\n        const compressedData = await this._readRegion(chunk.minv.blockPosition, chunk.fetchedSize(), opts);\n        try {\n            return (0, bgzf_filehandle_1.unzipChunkSlice)(compressedData, chunk);\n        }\n        catch (e) {\n            throw new Error(`error decompressing chunk ${chunk.toString()} ${e}`);\n        }\n    }\n}\nexports.default = TabixIndexedFile;\n","'use strict';\n\nclass QuickLRU {\n\tconstructor(options = {}) {\n\t\tif (!(options.maxSize && options.maxSize > 0)) {\n\t\t\tthrow new TypeError('`maxSize` must be a number greater than 0');\n\t\t}\n\n\t\tthis.maxSize = options.maxSize;\n\t\tthis.cache = new Map();\n\t\tthis.oldCache = new Map();\n\t\tthis._size = 0;\n\t}\n\n\t_set(key, value) {\n\t\tthis.cache.set(key, value);\n\t\tthis._size++;\n\n\t\tif (this._size >= this.maxSize) {\n\t\t\tthis._size = 0;\n\t\t\tthis.oldCache = this.cache;\n\t\t\tthis.cache = new Map();\n\t\t}\n\t}\n\n\tget(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this.cache.get(key);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\tconst value = this.oldCache.get(key);\n\t\t\tthis.oldCache.delete(key);\n\t\t\tthis._set(key, value);\n\t\t\treturn value;\n\t\t}\n\t}\n\n\tset(key, value) {\n\t\tif (this.cache.has(key)) {\n\t\t\tthis.cache.set(key, value);\n\t\t} else {\n\t\t\tthis._set(key, value);\n\t\t}\n\n\t\treturn this;\n\t}\n\n\thas(key) {\n\t\treturn this.cache.has(key) || this.oldCache.has(key);\n\t}\n\n\tpeek(key) {\n\t\tif (this.cache.has(key)) {\n\t\t\treturn this.cache.get(key);\n\t\t}\n\n\t\tif (this.oldCache.has(key)) {\n\t\t\treturn this.oldCache.get(key);\n\t\t}\n\t}\n\n\tdelete(key) {\n\t\tconst deleted = this.cache.delete(key);\n\t\tif (deleted) {\n\t\t\tthis._size--;\n\t\t}\n\n\t\treturn this.oldCache.delete(key) || deleted;\n\t}\n\n\tclear() {\n\t\tthis.cache.clear();\n\t\tthis.oldCache.clear();\n\t\tthis._size = 0;\n\t}\n\n\t* keys() {\n\t\tfor (const [key] of this) {\n\t\t\tyield key;\n\t\t}\n\t}\n\n\t* values() {\n\t\tfor (const [, value] of this) {\n\t\t\tyield value;\n\t\t}\n\t}\n\n\t* [Symbol.iterator]() {\n\t\tfor (const item of this.cache) {\n\t\t\tyield item;\n\t\t}\n\n\t\tfor (const item of this.oldCache) {\n\t\t\tconst [key] = item;\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\tyield item;\n\t\t\t}\n\t\t}\n\t}\n\n\tget size() {\n\t\tlet oldCacheSize = 0;\n\t\tfor (const key of this.oldCache.keys()) {\n\t\t\tif (!this.cache.has(key)) {\n\t\t\t\toldCacheSize++;\n\t\t\t}\n\t\t}\n\n\t\treturn this._size + oldCacheSize;\n\t}\n}\n\nmodule.exports = QuickLRU;\n","function _objectWithoutPropertiesLoose(source, excluded) {\n  if (source == null) return {};\n  var target = {};\n  var sourceKeys = Object.keys(source);\n  var key, i;\n\n  for (i = 0; i < sourceKeys.length; i++) {\n    key = sourceKeys[i];\n    if (excluded.indexOf(key) >= 0) continue;\n    target[key] = source[key];\n  }\n\n  return target;\n}\n\nmodule.exports = _objectWithoutPropertiesLoose, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.CSI = exports.TBI = exports.TabixIndexedFile = void 0;\nconst tabixIndexedFile_1 = __importDefault(require(\"./tabixIndexedFile\"));\nexports.TabixIndexedFile = tabixIndexedFile_1.default;\nconst tbi_1 = __importDefault(require(\"./tbi\"));\nexports.TBI = tbi_1.default;\nconst csi_1 = __importDefault(require(\"./csi\"));\nexports.CSI = csi_1.default;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.optimizeChunks = exports.canMergeBlocks = exports.abortBreakPoint = exports.checkAbortSignal = exports.longToNumber = void 0;\nfunction longToNumber(long) {\n    if (long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n        long.lessThan(Number.MIN_SAFE_INTEGER)) {\n        throw new Error('integer overflow');\n    }\n    return long.toNumber();\n}\nexports.longToNumber = longToNumber;\nclass AbortError extends Error {\n}\n/**\n * Properly check if the given AbortSignal is aborted.\n * Per the standard, if the signal reads as aborted,\n * this function throws either a DOMException AbortError, or a regular error\n * with a `code` attribute set to `ERR_ABORTED`.\n *\n * For convenience, passing `undefined` is a no-op\n *\n * @param {AbortSignal} [signal] an AbortSignal, or anything with an `aborted` attribute\n * @returns nothing\n */\nfunction checkAbortSignal(signal) {\n    if (!signal) {\n        return;\n    }\n    if (signal.aborted) {\n        // console.log('bam aborted!')\n        if (typeof DOMException !== 'undefined') {\n            // eslint-disable-next-line  no-undef\n            throw new DOMException('aborted', 'AbortError');\n        }\n        else {\n            const e = new AbortError('aborted');\n            e.code = 'ERR_ABORTED';\n            throw e;\n        }\n    }\n}\nexports.checkAbortSignal = checkAbortSignal;\n/**\n * Skips to the next tick, then runs `checkAbortSignal`.\n * Await this to inside an otherwise synchronous loop to\n * provide a place to break when an abort signal is received.\n * @param {AbortSignal} signal\n */\nasync function abortBreakPoint(signal) {\n    await Promise.resolve();\n    checkAbortSignal(signal);\n}\nexports.abortBreakPoint = abortBreakPoint;\nfunction canMergeBlocks(chunk1, chunk2) {\n    return (chunk2.minv.blockPosition - chunk1.maxv.blockPosition < 65000 &&\n        chunk2.maxv.blockPosition - chunk1.minv.blockPosition < 5000000);\n}\nexports.canMergeBlocks = canMergeBlocks;\nfunction optimizeChunks(chunks, lowest) {\n    const mergedChunks = [];\n    let lastChunk = null;\n    if (chunks.length === 0) {\n        return chunks;\n    }\n    chunks.sort(function (c0, c1) {\n        const dif = c0.minv.blockPosition - c1.minv.blockPosition;\n        if (dif !== 0) {\n            return dif;\n        }\n        else {\n            return c0.minv.dataPosition - c1.minv.dataPosition;\n        }\n    });\n    chunks.forEach(chunk => {\n        if (!lowest || chunk.maxv.compareTo(lowest) > 0) {\n            if (lastChunk === null) {\n                mergedChunks.push(chunk);\n                lastChunk = chunk;\n            }\n            else {\n                if (canMergeBlocks(lastChunk, chunk)) {\n                    if (chunk.maxv.compareTo(lastChunk.maxv) > 0) {\n                        lastChunk.maxv = chunk.maxv;\n                    }\n                }\n                else {\n                    mergedChunks.push(chunk);\n                    lastChunk = chunk;\n                }\n            }\n        }\n        // else {\n        //   console.log(`skipping chunk ${chunk}`)\n        // }\n    });\n    return mergedChunks;\n}\nexports.optimizeChunks = optimizeChunks;\n","var objectWithoutPropertiesLoose = require(\"./objectWithoutPropertiesLoose.js\");\n\nfunction _objectWithoutProperties(source, excluded) {\n  if (source == null) return {};\n  var target = objectWithoutPropertiesLoose(source, excluded);\n  var key, i;\n\n  if (Object.getOwnPropertySymbols) {\n    var sourceSymbolKeys = Object.getOwnPropertySymbols(source);\n\n    for (i = 0; i < sourceSymbolKeys.length; i++) {\n      key = sourceSymbolKeys[i];\n      if (excluded.indexOf(key) >= 0) continue;\n      if (!Object.prototype.propertyIsEnumerable.call(source, key)) continue;\n      target[key] = source[key];\n    }\n  }\n\n  return target;\n}\n\nmodule.exports = _objectWithoutProperties, module.exports.__esModule = true, module.exports[\"default\"] = module.exports;","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst long_1 = __importDefault(require(\"long\"));\nconst virtualOffset_1 = __importStar(require(\"./virtualOffset\"));\nconst chunk_1 = __importDefault(require(\"./chunk\"));\nconst bgzf_filehandle_1 = require(\"@gmod/bgzf-filehandle\");\nconst util_1 = require(\"./util\");\nconst indexFile_1 = __importDefault(require(\"./indexFile\"));\nconst TBI_MAGIC = 21578324; // TBI\\1\nconst TAD_LIDX_SHIFT = 14;\n/**\n * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n */\nfunction reg2bins(beg, end) {\n    beg += 1; // < convert to 1-based closed\n    end -= 1;\n    return [\n        [0, 0],\n        [1 + (beg >> 26), 1 + (end >> 26)],\n        [9 + (beg >> 23), 9 + (end >> 23)],\n        [73 + (beg >> 20), 73 + (end >> 20)],\n        [585 + (beg >> 17), 585 + (end >> 17)],\n        [4681 + (beg >> 14), 4681 + (end >> 14)],\n    ];\n}\nclass TabixIndex extends indexFile_1.default {\n    async lineCount(refName, opts = {}) {\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return -1;\n        }\n        const refId = indexData.refNameToId[refName];\n        const idx = indexData.indices[refId];\n        if (!idx) {\n            return -1;\n        }\n        const { stats } = indexData.indices[refId];\n        if (stats) {\n            return stats.lineCount;\n        }\n        return -1;\n    }\n    // memoize\n    // fetch and parse the index\n    async _parse(opts = {}) {\n        const bytes = await (0, bgzf_filehandle_1.unzip)((await this.filehandle.readFile(opts)));\n        (0, util_1.checkAbortSignal)(opts.signal);\n        // check TBI magic numbers\n        if (bytes.readUInt32LE(0) !== TBI_MAGIC /* \"TBI\\1\" */) {\n            throw new Error('Not a TBI file');\n            // TODO: do we need to support big-endian TBI files?\n        }\n        // number of reference sequences in the index\n        const refCount = bytes.readInt32LE(4);\n        const formatFlags = bytes.readInt32LE(8);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const formatOpts = {\n            0: 'generic',\n            1: 'SAM',\n            2: 'VCF',\n        };\n        const format = formatOpts[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: bytes.readInt32LE(12),\n            start: bytes.readInt32LE(16),\n            end: bytes.readInt32LE(20),\n        };\n        const metaValue = bytes.readInt32LE(24);\n        const depth = 5;\n        const maxBinNumber = ((1 << ((depth + 1) * 3)) - 1) / 7;\n        const maxRefLength = 2 ** (14 + depth * 3);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : null;\n        const skipLines = bytes.readInt32LE(28);\n        // read sequence dictionary\n        const nameSectionLength = bytes.readInt32LE(32);\n        const { refNameToId, refIdToName } = this._parseNameBytes(bytes.slice(36, 36 + nameSectionLength));\n        // read the indexes for each reference sequence\n        let currOffset = 36 + nameSectionLength;\n        let firstDataLine;\n        const indices = new Array(refCount).fill(0).map(() => {\n            // the binning index\n            const binCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const binIndex = {};\n            let stats;\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = bytes.readUInt32LE(currOffset);\n                currOffset += 4;\n                if (bin > maxBinNumber + 1) {\n                    throw new Error('tabix index contains too many bins, please use a CSI index');\n                }\n                else if (bin === maxBinNumber + 1) {\n                    const chunkCount = bytes.readInt32LE(currOffset);\n                    currOffset += 4;\n                    if (chunkCount === 2) {\n                        stats = this.parsePseudoBin(bytes, currOffset);\n                    }\n                    currOffset += 16 * chunkCount;\n                }\n                else {\n                    const chunkCount = bytes.readInt32LE(currOffset);\n                    currOffset += 4;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = (0, virtualOffset_1.fromBytes)(bytes, currOffset);\n                        const v = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 8);\n                        currOffset += 16;\n                        firstDataLine = this._findFirstData(firstDataLine, u);\n                        chunks[k] = new chunk_1.default(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            // the linear index\n            const linearCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const linearIndex = new Array(linearCount);\n            for (let k = 0; k < linearCount; k += 1) {\n                linearIndex[k] = (0, virtualOffset_1.fromBytes)(bytes, currOffset);\n                currOffset += 8;\n                firstDataLine = this._findFirstData(firstDataLine, linearIndex[k]);\n            }\n            return { binIndex, linearIndex, stats };\n        });\n        return {\n            indices,\n            metaChar,\n            maxBinNumber,\n            maxRefLength,\n            skipLines,\n            firstDataLine,\n            columnNumbers,\n            coordinateType,\n            format,\n            refIdToName,\n            refNameToId,\n            maxBlockSize: 1 << 16,\n        };\n    }\n    parsePseudoBin(bytes, offset) {\n        const lineCount = (0, util_1.longToNumber)(long_1.default.fromBytesLE(bytes.slice(offset + 16, offset + 24), true));\n        return { lineCount };\n    }\n    _parseNameBytes(namesBytes) {\n        let currRefId = 0;\n        let currNameStart = 0;\n        const refIdToName = [];\n        const refNameToId = {};\n        for (let i = 0; i < namesBytes.length; i += 1) {\n            if (!namesBytes[i]) {\n                if (currNameStart < i) {\n                    let refName = namesBytes.toString('utf8', currNameStart, i);\n                    refName = this.renameRefSeq(refName);\n                    refIdToName[currRefId] = refName;\n                    refNameToId[refName] = currRefId;\n                }\n                currNameStart = i + 1;\n                currRefId += 1;\n            }\n        }\n        return { refNameToId, refIdToName };\n    }\n    async blocksForRange(refName, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return [];\n        }\n        const refId = indexData.refNameToId[refName];\n        const ba = indexData.indices[refId];\n        if (!ba) {\n            return [];\n        }\n        const minOffset = ba.linearIndex.length\n            ? ba.linearIndex[min >> TAD_LIDX_SHIFT >= ba.linearIndex.length\n                ? ba.linearIndex.length - 1\n                : min >> TAD_LIDX_SHIFT]\n            : new virtualOffset_1.default(0, 0);\n        if (!minOffset) {\n            console.warn('querying outside of possible tabix range');\n        }\n        // const { linearIndex, binIndex } = indexes\n        const overlappingBins = reg2bins(min, max); // List of bin #s that overlap min, max\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                if (ba.binIndex[bin]) {\n                    const binChunks = ba.binIndex[bin];\n                    for (let c = 0; c < binChunks.length; ++c) {\n                        chunks.push(new chunk_1.default(binChunks[c].minv, binChunks[c].maxv, bin));\n                    }\n                }\n            }\n        }\n        // Use the linear index to find minimum file position of chunks that could\n        // contain alignments in the region\n        const nintv = ba.linearIndex.length;\n        let lowest = null;\n        const minLin = Math.min(min >> 14, nintv - 1);\n        const maxLin = Math.min(max >> 14, nintv - 1);\n        for (let i = minLin; i <= maxLin; ++i) {\n            const vp = ba.linearIndex[i];\n            if (vp) {\n                if (!lowest || vp.compareTo(lowest) < 0) {\n                    lowest = vp;\n                }\n            }\n        }\n        return (0, util_1.optimizeChunks)(chunks, lowest);\n    }\n}\nexports.default = TabixIndex;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.fromBytes = void 0;\nclass VirtualOffset {\n    constructor(blockPosition, dataPosition) {\n        this.blockPosition = blockPosition; // < offset of the compressed data block\n        this.dataPosition = dataPosition; // < offset into the uncompressed data\n    }\n    toString() {\n        return `${this.blockPosition}:${this.dataPosition}`;\n    }\n    compareTo(b) {\n        return (this.blockPosition - b.blockPosition || this.dataPosition - b.dataPosition);\n    }\n    static min(...args) {\n        let min;\n        let i = 0;\n        for (; !min; i += 1) {\n            min = args[i];\n        }\n        for (; i < args.length; i += 1) {\n            if (min.compareTo(args[i]) > 0) {\n                min = args[i];\n            }\n        }\n        return min;\n    }\n}\nexports.default = VirtualOffset;\nfunction fromBytes(bytes, offset = 0, bigendian = false) {\n    if (bigendian) {\n        throw new Error('big-endian virtual file offsets not implemented');\n    }\n    return new VirtualOffset(bytes[offset + 7] * 0x10000000000 +\n        bytes[offset + 6] * 0x100000000 +\n        bytes[offset + 5] * 0x1000000 +\n        bytes[offset + 4] * 0x10000 +\n        bytes[offset + 3] * 0x100 +\n        bytes[offset + 2], (bytes[offset + 1] << 8) | bytes[offset]);\n}\nexports.fromBytes = fromBytes;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\n// little class representing a chunk in the index\nclass Chunk {\n    /**\n     * @param {VirtualOffset} minv\n     * @param {VirtualOffset} maxv\n     * @param {number} bin\n     * @param {number} [fetchedSize]\n     */\n    constructor(minv, maxv, bin, fetchedSize = undefined) {\n        this.minv = minv;\n        this.maxv = maxv;\n        this.bin = bin;\n        this._fetchedSize = fetchedSize;\n    }\n    toUniqueString() {\n        return `${this.minv}..${this.maxv} (bin ${this.bin}, fetchedSize ${this.fetchedSize()})`;\n    }\n    toString() {\n        return this.toUniqueString();\n    }\n    compareTo(b) {\n        return (this.minv.compareTo(b.minv) ||\n            this.maxv.compareTo(b.maxv) ||\n            this.bin - b.bin);\n    }\n    fetchedSize() {\n        if (this._fetchedSize !== undefined) {\n            return this._fetchedSize;\n        }\n        return this.maxv.blockPosition + (1 << 16) - this.minv.blockPosition;\n    }\n}\nexports.default = Chunk;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortable_promise_cache_1 = __importDefault(require(\"abortable-promise-cache\"));\nconst quick_lru_1 = __importDefault(require(\"quick-lru\"));\nclass IndexFile {\n    /**\n     * @param {filehandle} filehandle\n     * @param {function} [renameRefSeqs]\n     */\n    constructor({ filehandle, renameRefSeqs = (n) => n, }) {\n        this.filehandle = filehandle;\n        this.renameRefSeq = renameRefSeqs;\n    }\n    async getMetadata(opts = {}) {\n        // eslint-disable-next-line @typescript-eslint/no-unused-vars\n        const { indices, ...rest } = await this.parse(opts);\n        return rest;\n    }\n    _findFirstData(currentFdl, virtualOffset) {\n        if (currentFdl) {\n            return currentFdl.compareTo(virtualOffset) > 0\n                ? virtualOffset\n                : currentFdl;\n        }\n        else {\n            return virtualOffset;\n        }\n    }\n    async parse(opts = {}) {\n        if (!this._parseCache) {\n            this._parseCache = new abortable_promise_cache_1.default({\n                cache: new quick_lru_1.default({ maxSize: 1 }),\n                fill: () => this._parse(opts),\n            });\n        }\n        return this._parseCache.get('index', null, undefined);\n    }\n    async hasRefSeq(seqId, opts = {}) {\n        return !!((await this.parse(opts)).indices[seqId] || {}).binIndex;\n    }\n}\nexports.default = IndexFile;\n","\"use strict\";\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    Object.defineProperty(o, k2, { enumerable: true, get: function() { return m[k]; } });\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst long_1 = __importDefault(require(\"long\"));\nconst bgzf_filehandle_1 = require(\"@gmod/bgzf-filehandle\");\nconst virtualOffset_1 = __importStar(require(\"./virtualOffset\"));\nconst chunk_1 = __importDefault(require(\"./chunk\"));\nconst util_1 = require(\"./util\");\nconst indexFile_1 = __importDefault(require(\"./indexFile\"));\nconst CSI1_MAGIC = 21582659; // CSI\\1\nconst CSI2_MAGIC = 38359875; // CSI\\2\nfunction lshift(num, bits) {\n    return num * 2 ** bits;\n}\nfunction rshift(num, bits) {\n    return Math.floor(num / 2 ** bits);\n}\nclass CSI extends indexFile_1.default {\n    constructor(args) {\n        super(args);\n        this.maxBinNumber = 0;\n        this.depth = 0;\n        this.minShift = 0;\n    }\n    async lineCount(refName, opts = {}) {\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return -1;\n        }\n        const refId = indexData.refNameToId[refName];\n        const idx = indexData.indices[refId];\n        if (!idx) {\n            return -1;\n        }\n        const { stats } = indexData.indices[refId];\n        if (stats) {\n            return stats.lineCount;\n        }\n        return -1;\n    }\n    async indexCov() {\n        throw new Error('CSI indexes do not support indexcov');\n        return [];\n    }\n    parseAuxData(bytes, offset, auxLength) {\n        if (auxLength < 30) {\n            return {\n                refIdToName: [],\n                refNameToId: {},\n            };\n        }\n        const formatFlags = bytes.readInt32LE(offset);\n        const coordinateType = formatFlags & 0x10000 ? 'zero-based-half-open' : '1-based-closed';\n        const format = { 0: 'generic', 1: 'SAM', 2: 'VCF' }[formatFlags & 0xf];\n        if (!format) {\n            throw new Error(`invalid Tabix preset format flags ${formatFlags}`);\n        }\n        const columnNumbers = {\n            ref: bytes.readInt32LE(offset + 4),\n            start: bytes.readInt32LE(offset + 8),\n            end: bytes.readInt32LE(offset + 12),\n        };\n        const metaValue = bytes.readInt32LE(offset + 16);\n        const metaChar = metaValue ? String.fromCharCode(metaValue) : '';\n        const skipLines = bytes.readInt32LE(offset + 20);\n        const nameSectionLength = bytes.readInt32LE(offset + 24);\n        const { refIdToName, refNameToId } = this._parseNameBytes(bytes.slice(offset + 28, offset + 28 + nameSectionLength));\n        return {\n            refIdToName,\n            refNameToId,\n            skipLines,\n            metaChar,\n            columnNumbers,\n            format,\n            coordinateType,\n        };\n    }\n    _parseNameBytes(namesBytes) {\n        let currRefId = 0;\n        let currNameStart = 0;\n        const refIdToName = [];\n        const refNameToId = {};\n        for (let i = 0; i < namesBytes.length; i += 1) {\n            if (!namesBytes[i]) {\n                if (currNameStart < i) {\n                    let refName = namesBytes.toString('utf8', currNameStart, i);\n                    refName = this.renameRefSeq(refName);\n                    refIdToName[currRefId] = refName;\n                    refNameToId[refName] = currRefId;\n                }\n                currNameStart = i + 1;\n                currRefId += 1;\n            }\n        }\n        return { refNameToId, refIdToName };\n    }\n    // fetch and parse the index\n    async _parse(opts = {}) {\n        const bytes = await (0, bgzf_filehandle_1.unzip)((await this.filehandle.readFile(opts)));\n        // check TBI magic numbers\n        let csiVersion;\n        if (bytes.readUInt32LE(0) === CSI1_MAGIC) {\n            csiVersion = 1;\n        }\n        else if (bytes.readUInt32LE(0) === CSI2_MAGIC) {\n            csiVersion = 2;\n        }\n        else {\n            throw new Error('Not a CSI file');\n            // TODO: do we need to support big-endian CSI files?\n        }\n        this.minShift = bytes.readInt32LE(4);\n        this.depth = bytes.readInt32LE(8);\n        this.maxBinNumber = ((1 << ((this.depth + 1) * 3)) - 1) / 7;\n        const maxRefLength = 2 ** (this.minShift + this.depth * 3);\n        const auxLength = bytes.readInt32LE(12);\n        let aux = {\n            refIdToName: [],\n            refNameToId: {},\n        };\n        if (auxLength) {\n            aux = this.parseAuxData(bytes, 16, auxLength);\n        }\n        const refCount = bytes.readInt32LE(16 + auxLength);\n        // read the indexes for each reference sequence\n        let firstDataLine;\n        let currOffset = 16 + auxLength + 4;\n        const indices = new Array(refCount).fill(0).map(() => {\n            // the binning index\n            const binCount = bytes.readInt32LE(currOffset);\n            currOffset += 4;\n            const binIndex = {};\n            let stats; // < provided by parsing a pseudo-bin, if present\n            for (let j = 0; j < binCount; j += 1) {\n                const bin = bytes.readUInt32LE(currOffset);\n                if (bin > this.maxBinNumber) {\n                    // this is a fake bin that actually has stats information\n                    // about the reference sequence in it\n                    stats = this.parsePseudoBin(bytes, currOffset + 4);\n                    currOffset += 4 + 8 + 4 + 16 + 16;\n                }\n                else {\n                    const loffset = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 4);\n                    firstDataLine = this._findFirstData(firstDataLine, loffset);\n                    const chunkCount = bytes.readInt32LE(currOffset + 12);\n                    currOffset += 16;\n                    const chunks = new Array(chunkCount);\n                    for (let k = 0; k < chunkCount; k += 1) {\n                        const u = (0, virtualOffset_1.fromBytes)(bytes, currOffset);\n                        const v = (0, virtualOffset_1.fromBytes)(bytes, currOffset + 8);\n                        currOffset += 16;\n                        // this._findFirstData(data, u)\n                        chunks[k] = new chunk_1.default(u, v, bin);\n                    }\n                    binIndex[bin] = chunks;\n                }\n            }\n            return { binIndex, stats };\n        });\n        return {\n            ...aux,\n            csi: true,\n            refCount,\n            maxBlockSize: 1 << 16,\n            firstDataLine,\n            csiVersion,\n            indices,\n            depth: this.depth,\n            maxBinNumber: this.maxBinNumber,\n            maxRefLength,\n        };\n    }\n    parsePseudoBin(bytes, offset) {\n        const lineCount = (0, util_1.longToNumber)(long_1.default.fromBytesLE(Array.prototype.slice.call(bytes, offset + 28, offset + 36), true));\n        return { lineCount };\n    }\n    async blocksForRange(refName, min, max, opts = {}) {\n        if (min < 0) {\n            min = 0;\n        }\n        const indexData = await this.parse(opts);\n        if (!indexData) {\n            return [];\n        }\n        const refId = indexData.refNameToId[refName];\n        const ba = indexData.indices[refId];\n        if (!ba) {\n            return [];\n        }\n        // const { linearIndex, binIndex } = indexes\n        const overlappingBins = this.reg2bins(min, max); // List of bin #s that overlap min, max\n        const chunks = [];\n        // Find chunks in overlapping bins.  Leaf bins (< 4681) are not pruned\n        for (const [start, end] of overlappingBins) {\n            for (let bin = start; bin <= end; bin++) {\n                if (ba.binIndex[bin]) {\n                    const binChunks = ba.binIndex[bin];\n                    for (let c = 0; c < binChunks.length; ++c) {\n                        chunks.push(new chunk_1.default(binChunks[c].minv, binChunks[c].maxv, bin));\n                    }\n                }\n            }\n        }\n        return (0, util_1.optimizeChunks)(chunks, new virtualOffset_1.default(0, 0));\n    }\n    /**\n     * calculate the list of bins that may overlap with region [beg,end) (zero-based half-open)\n     */\n    reg2bins(beg, end) {\n        beg -= 1; // < convert to 1-based closed\n        if (beg < 1) {\n            beg = 1;\n        }\n        if (end > 2 ** 50) {\n            end = 2 ** 34;\n        } // 17 GiB ought to be enough for anybody\n        end -= 1;\n        let l = 0;\n        let t = 0;\n        let s = this.minShift + this.depth * 3;\n        const bins = [];\n        for (; l <= this.depth; s -= 3, t += lshift(1, l * 3), l += 1) {\n            const b = t + rshift(beg, s);\n            const e = t + rshift(end, s);\n            if (e - b + bins.length > this.maxBinNumber) {\n                throw new Error(`query ${beg}-${end} is too large for current binning scheme (shift ${this.minShift}, depth ${this.depth}), try a smaller query or a coarser index binning scheme`);\n            }\n            bins.push([b, e]);\n        }\n        return bins;\n    }\n}\nexports.default = CSI;\n"],"sourceRoot":""}