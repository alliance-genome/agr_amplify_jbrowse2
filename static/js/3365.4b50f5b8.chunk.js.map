{"version":3,"file":"static/js/3365.4b50f5b8.chunk.js","mappings":"yMAiBAA,eAAeC,EAAMC,GACnB,IACE,IAAIC,EACAC,EAAM,EACNC,EAAI,EACR,MAAMC,EAAS,GACf,IACIC,EADAC,EAAY,EAEhB,EAAG,CACD,MAAMC,EAAiBP,EAAUQ,SAASN,GAK1C,GAJAG,EAAW,IAAI,EAAAI,UAEXR,QAASI,GACbA,EAASK,KAAKH,EAAgB,EAAAI,cAC1BN,EAASO,IACX,MAAM,IAAIC,MAAMR,EAASS,KAG3BZ,GAAOD,EAAKc,QACZX,EAAOD,GAAKE,EAASW,OACrBV,GAAaF,EAAOD,GAAGc,OACvBd,GAAK,C,OACEF,EAAKiB,UAEd,MAAMF,EAAS,IAAIG,WAAWb,GAC9B,IAAK,IAAIH,EAAI,EAAGiB,EAAS,EAAGjB,EAAIC,EAAOa,OAAQd,IAC7Ca,EAAOK,IAAIjB,EAAOD,GAAIiB,GACtBA,GAAUhB,EAAOD,GAAGc,OAEtB,OAAO,EAAAK,OAAOC,KAAKP,E,CACnB,MAAOQ,GAEP,GAAI,GAAGA,IAAIC,MAAM,0BACf,MAAM,IAAIZ,MACR,4DAGJ,MAAMW,C,CAEV,CAgDA1B,eAAe4B,EAAgB1B,EAAmB2B,GAChD,IACE,IAAI1B,EACJ,MAAM,KAAE2B,EAAI,KAAEC,GAASF,EACvB,IAAIG,EAAOF,EAAKG,cACZC,EAAOJ,EAAKK,aAChB,MAAM7B,EAAS,GACT8B,EAAa,GACbC,EAAa,GAEnB,IAAI7B,EAAY,EACZH,EAAI,EACR,EAAG,CACD,MAAMI,EAAiBP,EAAUQ,SAASsB,EAAOF,EAAKG,eAChD1B,EAAW,IAAI,EAAAI,QAIrB,KAFIR,QAASI,GACbA,EAASK,KAAKH,EAAgB,EAAAI,cAC1BN,EAASO,IACX,MAAM,IAAIC,MAAMR,EAASS,KAG3B,MAAMsB,EAAS/B,EAASW,OACxBZ,EAAOM,KAAK0B,GACZ,IAAIC,EAAMD,EAAOnB,OAEjBiB,EAAWxB,KAAKoB,GAChBK,EAAWzB,KAAKsB,GACM,IAAlB5B,EAAOa,QAAgBW,EAAKK,eAE9B7B,EAAO,GAAKA,EAAO,GAAGI,SAASoB,EAAKK,cACpCI,EAAMjC,EAAO,GAAGa,QAElB,MAAMqB,EAAWR,EAIjB,GAHAA,GAAQ7B,EAAKc,QACbiB,GAAQK,EAEJC,GAAYT,EAAKE,cAAe,CAKlC3B,EAAOD,GAAKC,EAAOD,GAAGK,SACpB,EACAqB,EAAKE,gBAAkBH,EAAKG,cACxBF,EAAKI,aAAeL,EAAKK,aAAe,EACxCJ,EAAKI,aAAe,GAG1BC,EAAWxB,KAAKoB,GAChBK,EAAWzB,KAAKsB,GAChB1B,GAAaF,EAAOD,GAAGc,OACvB,K,CAEFX,GAAaF,EAAOD,GAAGc,OACvBd,G,OACOF,EAAKiB,UAEd,MAAMF,EAAS,IAAIG,WAAWb,GAC9B,IAAK,IAAIH,EAAI,EAAGiB,EAAS,EAAGjB,EAAIC,EAAOa,OAAQd,IAC7Ca,EAAOK,IAAIjB,EAAOD,GAAIiB,GACtBA,GAAUhB,EAAOD,GAAGc,OAItB,MAAO,CAAEmB,OAFM,EAAAd,OAAOC,KAAKP,GAEVkB,aAAYC,a,CAC7B,MAAOX,GAEP,GAAI,GAAGA,IAAIC,MAAM,0BACf,MAAM,IAAIZ,MACR,4DAGJ,MAAMW,C,CAEV,C,wBC5Ke,MAAMe,EAKnB,WAAAC,EAAY,WACVC,EAAU,KACVC,IAKA,GAAID,EACFE,KAAKF,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIE,UAAU,6CAFpBD,KAAKF,WAAa,IAAI,KAAUC,E,CAIpC,CAEA,qBAAAG,CAAsBC,EAAa1B,EAAS,EAAG2B,GAAW,GAExD,MAAMC,EAAO,gBAAiBF,EAAIG,MAAM7B,EAAQA,EAAS,GAAI2B,GAC7D,GACEC,EAAKE,YAAYC,OAAOC,mBACxBJ,EAAKK,SAASF,OAAOG,kBAErB,MAAM,IAAIV,UAAU,oBAGtB,OAAOI,EAAKO,UACd,CAEA,SAAAC,GAIE,OAHKb,KAAKc,QACRd,KAAKc,MAAQd,KAAKe,cAEbf,KAAKc,KACd,CAEA,gBAAMC,GACJ,IAAIZ,EAAM,EAAAxB,OAAOqC,YAAY,SACvBhB,KAAKF,WAAWmB,KAAKd,EAAK,EAAG,EAAG,GACtC,MAAMe,EAAalB,KAAKE,sBAAsBC,EAAK,GAAG,GACtD,IAAKe,EACH,MAAO,CAAC,CAAC,EAAG,IAGd,MAAMC,EAAU,IAAIC,MAAMF,EAAa,GACvCC,EAAQ,GAAK,CAAC,EAAG,GAGjB,MAAME,EAAU,GAAQH,EACxB,GAAIG,EAAUb,OAAOC,iBACnB,MAAM,IAAIR,UAAU,oBAEtBE,EAAM,EAAAxB,OAAOqC,YAAYK,SACnBrB,KAAKF,WAAWmB,KAAKd,EAAK,EAAGkB,EAAS,GAC5C,IAAK,IAAIC,EAAc,EAAGA,EAAcJ,EAAYI,GAAe,EAAG,CACpE,MAAMC,EAAqBvB,KAAKE,sBAC9BC,EACc,GAAdmB,GAEIE,EAAuBxB,KAAKE,sBAChCC,EACc,GAAdmB,EAAmB,GAErBH,EAAQG,EAAc,GAAK,CAACC,EAAoBC,E,CAGlD,OAAOL,CACT,CAEA,kBAAMM,GACJ,MAAMN,QAAgBnB,KAAKa,YAC3B,GAAKM,EAAQ7C,OAGb,OAAO6C,EAAQA,EAAQ7C,OAAS,EAClC,CAEA,8BAAMoD,CAAyBpD,EAAgBqD,GAC7C,MAAMC,EAAcD,EAAWrD,EAC/B,GAAe,IAAXA,EACF,MAAO,GAET,MAAM6C,QAAgBnB,KAAKa,YACrBgB,EAAW,GAIXC,EAAU,CAACC,EAAYC,KAC3B,MAAMR,EAAuBO,EA/FL,GAgGlBE,EAA2BD,EAC7BA,EAjGoB,GAkGpBE,IAEJ,OACEV,GAAwBG,GACxBM,EAA2BN,EAEpB,EAGLH,EAAuBG,GACjB,EAGH,CAAC,EAGV,IAAIQ,EAAa,EACbC,EAAajB,EAAQ7C,OAAS,EAC9B+D,EAAiBC,KAAKC,MAAMpB,EAAQ7C,OAAS,GAE7CkE,EAAaV,EACfX,EAAQkB,GACRlB,EAAQkB,EAAiB,IAE3B,KAAsB,IAAfG,GACDA,EAAa,EACfJ,EAAaC,EAAiB,EACrBG,EAAa,IACtBL,EAAaE,EAAiB,GAEhCA,EAAiBC,KAAKG,MAAML,EAAaD,GAAc,GAAKA,EAC5DK,EAAaV,EAAQX,EAAQkB,GAAiBlB,EAAQkB,EAAiB,IAIzER,EAAS9D,KAAKoD,EAAQkB,IACtB,IAAI7E,EAAI6E,EAAiB,EACzB,KAAO7E,EAAI2D,EAAQ7C,SACjBuD,EAAS9D,KAAKoD,EAAQ3D,MAClB2D,EAAQ3D,GAzIY,IAyIiBoE,IAFhBpE,GAAK,GAShC,OAHIqE,EAASA,EAASvD,OAAS,GA7IL,GA6IiCsD,GACzDC,EAAS9D,KAAK,IAET8D,CACT,EC/Ia,MAAMa,EAInB,WAAA7C,EAAY,WACVC,EAAU,KACVC,EAAI,cACJ4C,EAAa,QACbC,IAOA,GAAI9C,EACFE,KAAKF,WAAaA,MACb,KAAIC,EAGT,MAAM,IAAIE,UAAU,6CAFpBD,KAAKF,WAAa,IAAI,KAAUC,E,CAKlC,IAAK4C,IAAkBC,IAAY7C,EACjC,MAAM,IAAIE,UAAU,mDAGtBD,KAAK6C,IAAM,IAAIjD,EAAS,CACtBE,WAAY6C,EACZ5C,KAAO4C,GAAkBC,IAAW7C,EAAiB,GAAGA,QAAb6C,GAE/C,CAEA,UAAME,GACJ,MAAMC,QAAuB/C,KAAKF,WAAWgD,OAC7C,OAAOE,OAAOC,OAAOF,EAAgB,CACnCG,WAAYlD,KAAKmD,0BACjBC,YAAQC,EACRC,aAASD,GAEb,CAEA,6BAAMF,GAGJ,MAAO,CAAE3B,SAA8BxB,KAAK6C,IAAIpB,gBAE1C,KAAEyB,SAAelD,KAAKF,WAAWgD,OAEjC3C,EAAM,EAAAxB,OAAOqC,YAAY,IAGzB,UAAEuC,SAAoBvD,KAAKF,WAAWmB,KAAKd,EAAK,EAAG,EAAG+C,EAAO,GAAK,GACxE,GAAkB,IAAdK,EACF,MAAM,IAAIrF,MAAM,cAGlB,OAAOsD,EAD2BrB,EAAIqD,aAAa,EAErD,CAEA,6BAAMC,CACJC,GACCnC,IACAoC,IAED,IAAIC,EAAOD,EACNC,IACHA,SAAc5D,KAAKF,WAAWgD,QAAQI,MAIxC,MAAMW,EAAwBD,EAAOrC,EAcrC,aAZMvB,KAAKF,WAAWmB,KACpByC,EACA,EACAG,EACAtC,SAI2BnE,EAC3BsG,EAAYpD,MAAM,EAAGuD,GAIzB,CAEA,UAAM5C,CAAKd,EAAa1B,EAAgBH,EAAgBqD,GAEtD,MAAMmC,QAAuB9D,KAAK6C,IAAInB,yBACpCpD,EACAqD,GAEI+B,EAAc,EAAA/E,OAAOqC,YAAY,OAEvC,IAAI+C,EAAoBtF,EACpB8E,EAAY,EAChB,IACE,IAAIS,EAAW,EACfA,EAAWF,EAAexF,OAAS,EACnC0F,GAAY,EACZ,CAEA,MAAMC,QAA2BjE,KAAKyD,wBACpCC,EACAI,EAAeE,GACfF,EAAeE,EAAW,KAErB,CAAExC,GAAwBsC,EAAeE,GAC1CE,EACJ1C,GAAwBG,EAAW,EAAIA,EAAWH,EAC9C2C,EACJ7B,KAAK8B,IACHzC,EAAWrD,EACXkD,EAAuByC,EAAmB3F,QACxCkD,EACF0C,GAAgB,GAAKA,EAAeD,EAAmB3F,SACzD2F,EAAmBI,KAAKlE,EAAK4D,EAAmBG,EAAcC,GAC9DJ,GAAqBI,EAAYD,EACjCX,GAAaY,EAAYD,E,CAI7B,MAAO,CAAEX,YAAW9D,OAAQU,EAC9B,E,oFCvHF,SAASmE,EAAWC,EAAiBhH,GACnC,OACEgH,EAAI9F,OACJ8F,EAAIC,UAAYlC,KAAKC,MAAMhF,EAAMgH,EAAIE,YACpClH,EAAMgH,EAAIE,UAEf,CAwCe,MAAMC,EAKnB,WAAA7E,EAAY,MACV8E,EAAK,IACLC,EAAG,KACH7E,EAAI,QACJ8E,IAOA,GAAIF,EACF3E,KAAK2E,MAAQA,MACR,KAAI5E,EAGT,MAAM,IAAI7B,MAAM,0DAFhB8B,KAAK2E,MAAQ,IAAI,KAAU5E,E,CAK7B,GAAI6E,EACF5E,KAAK4E,IAAMA,OACN,GAAIC,EACT7E,KAAK4E,IAAM,IAAI,KAAUC,OACpB,KAAI9E,EAGT,MAAM,IAAI7B,MAAM,qDAFhB8B,KAAK4E,IAAM,IAAI,KAAU,GAAG7E,Q,CAIhC,CAEA,iBAAM+E,CAAYC,GAIhB,OAHK/E,KAAKgF,UACRhF,KAAKgF,QA3EX7H,eAAuByH,EAAwBG,GAC7C,MAAME,QAAaL,EAAIM,SAASH,GAChC,IAAME,IAAQA,EAAK3G,OACjB,MAAM,IAAIJ,MAAM,4CAGlB,IACIiH,EADAC,EAAY,EAEhB,MAAMC,EAAOJ,EACVK,SAAS,QACTC,MAAM,SACNC,QAAOC,GAAQ,KAAKC,KAAKD,KACzBE,KAAIF,GAAQA,EAAKF,MAAM,QACvBC,QAAOI,GAAkB,KAAXA,EAAI,KAClBD,KAAIC,IACET,GAAWA,EAAQU,OAASD,EAAI,KACnCT,EAAU,CAAEU,KAAMD,EAAI,GAAIE,GAAIV,GAC9BA,GAAa,GAGR,CACLU,GAAIX,EAAQW,GACZD,KAAMD,EAAI,GACVtH,QAASsH,EAAI,GACbG,MAAO,EACPC,KAAMJ,EAAI,GACVnH,QAASmH,EAAI,GACbnB,YAAamB,EAAI,GACjBpB,WAAYoB,EAAI,OAItB,MAAO,CACLC,KAAM7C,OAAOiD,YAAYZ,EAAKM,KAAI5D,GAAS,CAACA,EAAM8D,KAAM9D,MACxD+D,GAAI9C,OAAOiD,YAAYZ,EAAKM,KAAI5D,GAAS,CAACA,EAAM+D,GAAI/D,MAExD,CAuCqBmE,CAAQlG,KAAK4E,IAAKG,IAE5B/E,KAAKgF,OACd,CAQA,sBAAMmB,CAAiBpB,GACrB,OAAO/B,OAAOoD,YAAYpG,KAAK8E,YAAYC,IAAOc,KACpD,CAQA,sBAAMQ,CAAiBtB,GACrB,MAAMuB,EAAe,CAAC,EAChB/B,QAAYvE,KAAK8E,YAAYC,GAC7BwB,EAAOvD,OAAOwD,OAAOjC,EAAIuB,IAC/B,IAAK,IAAItI,EAAI,EAAGA,EAAI+I,EAAKjI,OAAQd,GAAK,EACpC8I,EAAaC,EAAK/I,GAAGqI,MAAQU,EAAK/I,GAAGc,OAEvC,OAAOgI,CACT,CAQA,qBAAMG,CAAgBC,EAAiB3B,G,MAErC,OAAwB,QAAjB,SADW/E,KAAK8E,YAAYC,IACxBc,KAAKa,UAAQ,eAAEpI,MAC5B,CAOA,0BAAMqI,CAAqBd,EAAcd,GACvC,eAAgB/E,KAAK8E,YAAYC,IAAOc,KAAKA,EAC/C,CAQA,qBAAMe,CACJC,EACAzC,EACA0C,EACA/B,GAEA,MAAMgC,SAAoB/G,KAAK8E,YAAYC,IAAOe,GAAGe,GACrD,GAAKE,EAGL,OAAO/G,KAAKgH,qBAAqBD,EAAY3C,EAAK0C,EAAK/B,EACzD,CAOA,uBAAMkC,CACJP,EACAtC,EACA0C,EACA/B,GAEA,MAAMgC,SAAoB/G,KAAK8E,YAAYC,IAAOc,KAAKa,GACvD,GAAKK,EAIL,OAAO/G,KAAKgH,qBAAqBD,EAAY3C,EAAK0C,EAAK/B,EACzD,CAGA,iBAAMmC,CACJR,EACAtC,EACA0C,EACA/B,GAEA,OAAO/E,KAAKiH,kBAAkBP,EAAStC,EAAK0C,EAAK/B,EACnD,CAEA,0BAAMiC,CACJD,EACA3C,EAAM,EACN0C,EACA/B,GAEA,IAAIiB,EAAMc,EACV,GAAI1C,EAAM,EACR,MAAM,IAAInE,UAAU,qCAKtB,SAHYoD,IAAR2C,GAAqBA,EAAMe,EAAWzI,UACxC0H,EAAMe,EAAWzI,QAEf8F,GAAO4B,EACT,MAAO,GAGT,MAAMrE,EAAW2C,EAAWyC,EAAY3C,GAClC+C,EAAU7C,EAAWyC,EAAYf,GAAOrE,EAExCyF,EAAWzI,EAAOqC,YAAYmG,GAEpC,aADMnH,KAAK2E,MAAM1D,KAAKmG,EAAU,EAAGD,EAASxF,EAAUoD,GAC/CqC,EAAS9B,SAAS,QAAQ+B,QAAQ,OAAQ,GACnD,ECtNa,MAAMC,UAA0B5C,EAC7C,WAAA7E,EAAY,MACV8E,EAAK,KACL5E,EAAI,IACJ6E,EAAG,QACHC,EAAO,IACPhC,EAAG,QACHD,IASA2E,MAAM,CAAE5C,QAAO5E,OAAM6E,MAAKC,YACtBF,GAAS9B,EACX7C,KAAK2E,MAAQ,IAAI,KAAe,CAC9B7E,WAAY6E,EACZhC,cAAeE,IAER9C,GAAQ6C,IACjB5C,KAAK2E,MAAQ,IAAI,KAAe,CAAE5E,OAAM6C,YAE5C,E,wBC5BF,IAAI4E,EAAmBxH,MAAQA,KAAKwH,iBAAoB,SAAUC,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,EACxD,EACAzE,OAAO2E,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,MAAMC,EAA6B,EAAQ,OACrCC,EAA6BP,EAAgB,EAAQ,QACrDQ,EAA4BR,EAAgB,EAAQ,QAC1D,MAAMS,EACF,WAAApI,EAAY,KAAEqI,EAAI,MAAEC,IAChB,GAAoB,mBAATD,EACP,MAAM,IAAIjI,UAAU,6BAExB,GAAqB,iBAAVkI,EACP,MAAM,IAAIlI,UAAU,4BAExB,GAAyB,mBAAdkI,EAAMC,KACQ,mBAAdD,EAAMzJ,KACW,mBAAjByJ,EAAME,OACb,MAAM,IAAIpI,UAAU,qEAExBD,KAAKmI,MAAQA,EACbnI,KAAKsI,aAAeJ,CACxB,CACA,uBAAOK,CAAiBC,GACpB,MAEmB,eAAnBA,EAAU3C,MAGa,gBAAnB2C,EAAUC,MAEY,wBAAtBD,EAAUE,SAEY,mBAAtBF,EAAUE,OAClB,CACA,KAAAC,CAAMC,EAAK7G,GACH/B,KAAKmI,MAAMC,IAAIQ,KAAS7G,GACxB/B,KAAKmI,MAAME,OAAOO,EAE1B,CACA,IAAAV,CAAKU,EAAKvD,EAAMwD,EAAQC,GACpB,MAAMC,EAAU,IAAIhB,EAA2BiB,QACzCC,EAAiB,IAAIjB,EAA0BgB,QACrDC,EAAeC,YAAYJ,GAC3B,MAAMK,EAAW,CACbJ,QAASA,EACTK,QAASpJ,KAAKsI,aAAajD,EAAM0D,EAAQF,QAASH,IAC9CO,EAAeI,SAASX,EAAQ,IAEpCY,SAAS,EACTL,iBACA,WAAIM,GACA,OAAOvJ,KAAK+I,QAAQF,OAAOU,OAC/B,GAEJJ,EAASJ,QAAQS,UAAUX,GAE3BM,EAASJ,QAAQF,OAAOY,iBAAiB,SAAS,KACzCN,EAASG,SACVtJ,KAAK2I,MAAMC,EAAKO,EACpB,IAGJA,EAASC,QACJM,MAAK,KACNP,EAASG,SAAU,CAAI,IACxB,KACCH,EAASG,SAAU,EAEnBtJ,KAAK2I,MAAMC,EAAKO,EAAS,IAExBQ,OAAM9K,IAIP,MADA+K,QAAQC,MAAMhL,GACRA,CAAC,IAEXmB,KAAKmI,MAAMzJ,IAAIkK,EAAKO,EACxB,CACA,yBAAOW,CAAmBV,EAASP,GAI/B,SAASkB,IACL,GAAIlB,GAAUA,EAAOU,QACjB,MAAMvG,OAAOC,OAAO,IAAI/E,MAAM,WAAY,CAAEuK,KAAM,eAE1D,CACA,OAAOW,EAAQM,MAAKrL,IAChB0L,IACO1L,KACRwL,IAEC,MADAE,IACMF,CAAK,GAEnB,CACA,GAAAG,CAAIpB,GACA,OAAO5I,KAAKmI,MAAM6B,IAAIpB,EAC1B,CAaA,GAAAR,CAAIQ,EAAKvD,EAAMwD,EAAQC,GACnB,IAAKD,GAAUxD,aAAgByC,EAA2BmC,YACtD,MAAM,IAAIhK,UAAU,yGAExB,MAAMiK,EAAalK,KAAKmI,MAAMC,IAAIQ,GAClC,OAAIsB,EACIA,EAAWX,UAAYW,EAAWZ,SAElCtJ,KAAK2I,MAAMC,EAAKsB,GACTlK,KAAKoI,IAAIQ,EAAKvD,EAAMwD,EAAQC,IAEnCoB,EAAWZ,QAEJY,EAAWd,SAItBc,EAAWnB,QAAQS,UAAUX,GAC7BqB,EAAWjB,eAAeC,YAAYJ,GAC/Bb,EAAsB6B,mBAAmBI,EAAWd,QAASP,KAGxE7I,KAAKkI,KAAKU,EAAKvD,EAAMwD,EAAQC,GACtBb,EAAsB6B,mBAG7B9J,KAAKmI,MAAMC,IAAIQ,GAAKQ,QAASP,GACjC,CAOA,OAAOD,GACH,MAAMuB,EAAcnK,KAAKmI,MAAMC,IAAIQ,GAC/BuB,IACKA,EAAYb,SACba,EAAYpB,QAAQqB,QAExBpK,KAAKmI,MAAME,OAAOO,GAE1B,CAKA,KAAAyB,GAEI,MAAMC,EAAUtK,KAAKmI,MAAM/B,OAC3B,IAAImE,EAAc,EAClB,IAAK,IAAIlM,EAASiM,EAAQ1G,QAASvF,EAAOmM,KAAMnM,EAASiM,EAAQ1G,OAC7D5D,KAAKqI,OAAOhK,EAAOwJ,OACnB0C,GAAe,EAEnB,OAAOA,CACX,EAEJ3C,EAAA,QAAkBK,C,kBCzKlBjF,OAAO2E,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,MAAMC,EAA6B,EAAQ,OAC3C,MAAM2C,GAgDN7C,EAAA,QA1CA,MACI,WAAA/H,GACIG,KAAK0K,QAAU,IAAIC,IACnB3K,KAAK4K,gBAAkB,IAAI9C,EAA2B+C,eAC1D,CAOA,SAAArB,CAAUX,EAAS,IAAI4B,GACnB,GAAIzK,KAAK6I,OAAOU,QACZ,MAAM,IAAIrL,MAAM,yCAIpB8B,KAAK0K,QAAQI,IAAIjC,GACbA,EAAOU,QAGPvJ,KAAK+K,cAAclC,GAEqB,mBAA5BA,EAAOY,kBACnBZ,EAAOY,iBAAiB,SAAS,KAC7BzJ,KAAK+K,cAAclC,EAAO,GAGtC,CACA,aAAAkC,CAAclC,GACV7I,KAAK0K,QAAQrC,OAAOQ,GACM,IAAtB7I,KAAK0K,QAAQxH,MACblD,KAAK4K,gBAAgBR,OAE7B,CACA,UAAIvB,GACA,OAAO7I,KAAK4K,gBAAgB/B,MAChC,CACA,KAAAuB,GACIpK,KAAK4K,gBAAgBR,OACzB,E,gBChDJpH,OAAO2E,eAAeC,EAAS,aAAc,CAAEC,OAAO,IAgBtDD,EAAA,QAfA,MACI,WAAA/H,GACIG,KAAKgL,UAAY,IAAIL,GACzB,CACA,WAAAzB,CAAYG,EAAW,UACnBrJ,KAAKgL,UAAUF,IAAIzB,GACnBA,EAASrJ,KAAKiL,eAClB,CACA,QAAA5B,CAASX,GACL1I,KAAKiL,eAAiBvC,EACtB1I,KAAKgL,UAAUE,SAAQC,IACnBA,EAAIzC,EAAQ,GAEpB,E,kBCbJ1F,OAAO2E,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtDD,EAAQqC,YAAcrC,EAAQiD,qBAAkB,EAChD,MAAMO,EAAiB,EAAQ,OAC/B,IAAIC,EAAY,WAIZ,GAAoB,oBAATC,KACP,OAAOA,KAEX,GAAsB,oBAAXC,OACP,OAAOA,OAEX,QAAsB,IAAX,EAAAC,EACP,OAAO,EAAAA,EAEX,MAAM,IAAItN,MAAM,iCACpB,EAEA,IAAI2M,OAAyD,IAAhCQ,IAAYR,gBAAkCO,EAAeP,gBAAkBQ,IAAYR,gBACxHjD,EAAQiD,gBAAkBA,EAE1B,IAAIZ,OAAqD,IAAhCoB,IAAYR,gBAAkCO,EAAenB,YAAcoB,IAAYpB,YAChHrC,EAAQqC,YAAcA,C,uBCxBtB,IAAIzC,EAAmBxH,MAAQA,KAAKwH,iBAAoB,SAAUC,GAC9D,OAAQA,GAAOA,EAAIC,WAAcD,EAAM,CAAE,QAAWA,EACxD,EACAzE,OAAO2E,eAAeC,EAAS,aAAc,CAAEC,OAAO,IACtD,MAAM4D,EAA0BjE,EAAgB,EAAQ,QACxDI,EAAA,QAAkB6D,EAAwBzC,O","sources":["../../../node_modules/@gmod/bgzf-filehandle/src/unzip-pako.ts","../../../node_modules/@gmod/bgzf-filehandle/src/gziIndex.ts","../../../node_modules/@gmod/bgzf-filehandle/src/bgzFilehandle.ts","../../../node_modules/@gmod/indexedfasta/src/indexedFasta.ts","../../../node_modules/@gmod/indexedfasta/src/bgzipIndexedFasta.ts","../../../node_modules/abortable-promise-cache/esm/AbortablePromiseCache.js","../../../node_modules/abortable-promise-cache/esm/AggregateAbortController.js","../../../node_modules/abortable-promise-cache/esm/AggregateStatusReporter.js","../../../node_modules/abortable-promise-cache/esm/abortcontroller-ponyfill.js","../../../node_modules/abortable-promise-cache/esm/index.js"],"sourcesContent":["import { Buffer } from 'buffer'\n//@ts-ignore\nimport { Z_SYNC_FLUSH, Inflate } from 'pako'\n\ninterface VirtualOffset {\n  blockPosition: number\n  dataPosition: number\n}\ninterface Chunk {\n  minv: VirtualOffset\n  maxv: VirtualOffset\n}\n\n// browserify-zlib, which is the zlib shim used by default in webpacked code,\n// does not properly uncompress bgzf chunks that contain more than\n// one bgzf block, so export an unzip function that uses pako directly\n// if we are running in a browser.\nasync function unzip(inputData: Buffer) {\n  try {\n    let strm\n    let pos = 0\n    let i = 0\n    const chunks = []\n    let totalSize = 0\n    let inflator\n    do {\n      const remainingInput = inputData.subarray(pos)\n      inflator = new Inflate()\n      //@ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      pos += strm.next_in\n      chunks[i] = inflator.result as Uint8Array\n      totalSize += chunks[i].length\n      i += 1\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    return Buffer.from(result)\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to pakounzip, except it does extra counting\n// to return the positions of compressed and decompressed\n// data offsets\nasync function unzipChunk(inputData: Buffer) {\n  try {\n    let strm\n    let cpos = 0\n    let dpos = 0\n    const blocks = []\n    const cpositions = []\n    const dpositions = []\n    do {\n      const remainingInput = inputData.slice(cpos)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = Buffer.from(inflator.result)\n      blocks.push(buffer)\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n\n      cpos += strm.next_in\n      dpos += buffer.length\n    } while (strm.avail_in)\n\n    const buffer = Buffer.concat(blocks)\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\n// similar to unzipChunk above but slices (0,minv.dataPosition) and\n// (maxv.dataPosition,end) off\nasync function unzipChunkSlice(inputData: Buffer, chunk: Chunk) {\n  try {\n    let strm\n    const { minv, maxv } = chunk\n    let cpos = minv.blockPosition\n    let dpos = minv.dataPosition\n    const chunks = []\n    const cpositions = []\n    const dpositions = []\n\n    let totalSize = 0\n    let i = 0\n    do {\n      const remainingInput = inputData.subarray(cpos - minv.blockPosition)\n      const inflator = new Inflate()\n      // @ts-ignore\n      ;({ strm } = inflator)\n      inflator.push(remainingInput, Z_SYNC_FLUSH)\n      if (inflator.err) {\n        throw new Error(inflator.msg)\n      }\n\n      const buffer = inflator.result\n      chunks.push(buffer as Uint8Array)\n      let len = buffer.length\n\n      cpositions.push(cpos)\n      dpositions.push(dpos)\n      if (chunks.length === 1 && minv.dataPosition) {\n        // this is the first chunk, trim it\n        chunks[0] = chunks[0].subarray(minv.dataPosition)\n        len = chunks[0].length\n      }\n      const origCpos = cpos\n      cpos += strm.next_in\n      dpos += len\n\n      if (origCpos >= maxv.blockPosition) {\n        // this is the last chunk, trim it and stop decompressing\n        // note if it is the same block is minv it subtracts that already\n        // trimmed part of the slice length\n\n        chunks[i] = chunks[i].subarray(\n          0,\n          maxv.blockPosition === minv.blockPosition\n            ? maxv.dataPosition - minv.dataPosition + 1\n            : maxv.dataPosition + 1,\n        )\n\n        cpositions.push(cpos)\n        dpositions.push(dpos)\n        totalSize += chunks[i].length\n        break\n      }\n      totalSize += chunks[i].length\n      i++\n    } while (strm.avail_in)\n\n    const result = new Uint8Array(totalSize)\n    for (let i = 0, offset = 0; i < chunks.length; i++) {\n      result.set(chunks[i], offset)\n      offset += chunks[i].length\n    }\n    const buffer = Buffer.from(result)\n\n    return { buffer, cpositions, dpositions }\n  } catch (e) {\n    //cleanup error message\n    if (`${e}`.match(/incorrect header check/)) {\n      throw new Error(\n        'problem decompressing block: incorrect gzip header check',\n      )\n    }\n    throw e\n  }\n}\n\nfunction nodeUnzip() {\n  throw new Error('nodeUnzip not implemented.')\n}\n\nexport { unzip, unzipChunk, unzipChunkSlice, unzip as pakoUnzip, nodeUnzip }\n","import Long from 'long'\nimport { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// const COMPRESSED_POSITION = 0\nconst UNCOMPRESSED_POSITION = 1\n\nexport default class GziIndex {\n  filehandle: GenericFilehandle\n\n  index?: any\n\n  constructor({\n    filehandle,\n    path,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n  }\n\n  _readLongWithOverflow(buf: Buffer, offset = 0, unsigned = true) {\n    //@ts-ignore\n    const long = Long.fromBytesLE(buf.slice(offset, offset + 8), unsigned)\n    if (\n      long.greaterThan(Number.MAX_SAFE_INTEGER) ||\n      long.lessThan(Number.MIN_SAFE_INTEGER)\n    ) {\n      throw new TypeError('integer overflow')\n    }\n\n    return long.toNumber()\n  }\n\n  _getIndex() {\n    if (!this.index) {\n      this.index = this._readIndex()\n    }\n    return this.index\n  }\n\n  async _readIndex() {\n    let buf = Buffer.allocUnsafe(8)\n    await this.filehandle.read(buf, 0, 8, 0)\n    const numEntries = this._readLongWithOverflow(buf, 0, true)\n    if (!numEntries) {\n      return [[0, 0]]\n    }\n\n    const entries = new Array(numEntries + 1)\n    entries[0] = [0, 0]\n\n    // TODO rewrite this to make an index-index that stays in memory\n    const bufSize = 8 * 2 * numEntries\n    if (bufSize > Number.MAX_SAFE_INTEGER) {\n      throw new TypeError('integer overflow')\n    }\n    buf = Buffer.allocUnsafe(bufSize)\n    await this.filehandle.read(buf, 0, bufSize, 8)\n    for (let entryNumber = 0; entryNumber < numEntries; entryNumber += 1) {\n      const compressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16,\n      )\n      const uncompressedPosition = this._readLongWithOverflow(\n        buf,\n        entryNumber * 16 + 8,\n      )\n      entries[entryNumber + 1] = [compressedPosition, uncompressedPosition]\n    }\n\n    return entries\n  }\n\n  async getLastBlock() {\n    const entries = await this._getIndex()\n    if (!entries.length) {\n      return undefined\n    }\n    return entries[entries.length - 1]\n  }\n\n  async getRelevantBlocksForRead(length: number, position: number) {\n    const endPosition = position + length\n    if (length === 0) {\n      return []\n    }\n    const entries = await this._getIndex()\n    const relevant = []\n\n    // binary search to find the block that the\n    // read starts in and extend forward from that\n    const compare = (entry: any, nextEntry: any) => {\n      const uncompressedPosition = entry[UNCOMPRESSED_POSITION]\n      const nextUncompressedPosition = nextEntry\n        ? nextEntry[UNCOMPRESSED_POSITION]\n        : Infinity\n      // block overlaps read start\n      if (\n        uncompressedPosition <= position &&\n        nextUncompressedPosition > position\n      ) {\n        return 0\n        // block is before read start\n      }\n      if (uncompressedPosition < position) {\n        return -1\n      }\n      // block is after read start\n      return 1\n    }\n\n    let lowerBound = 0\n    let upperBound = entries.length - 1\n    let searchPosition = Math.floor(entries.length / 2)\n\n    let comparison = compare(\n      entries[searchPosition],\n      entries[searchPosition + 1],\n    )\n    while (comparison !== 0) {\n      if (comparison > 0) {\n        upperBound = searchPosition - 1\n      } else if (comparison < 0) {\n        lowerBound = searchPosition + 1\n      }\n      searchPosition = Math.ceil((upperBound - lowerBound) / 2) + lowerBound\n      comparison = compare(entries[searchPosition], entries[searchPosition + 1])\n    }\n\n    // here's where we read forward\n    relevant.push(entries[searchPosition])\n    let i = searchPosition + 1\n    for (; i < entries.length; i += 1) {\n      relevant.push(entries[i])\n      if (entries[i][UNCOMPRESSED_POSITION] >= endPosition) {\n        break\n      }\n    }\n    if (relevant[relevant.length - 1][UNCOMPRESSED_POSITION] < endPosition) {\n      relevant.push([])\n    }\n    return relevant\n  }\n}\n","import { Buffer } from 'buffer'\nimport { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\n// locals\nimport { unzip } from './unzip'\nimport GziIndex from './gziIndex'\n\nexport default class BgzFilehandle {\n  filehandle: GenericFilehandle\n  gzi: GziIndex\n\n  constructor({\n    filehandle,\n    path,\n    gziFilehandle,\n    gziPath,\n  }: {\n    filehandle?: GenericFilehandle\n    path?: string\n    gziFilehandle?: GenericFilehandle\n    gziPath?: string\n  }) {\n    if (filehandle) {\n      this.filehandle = filehandle\n    } else if (path) {\n      this.filehandle = new LocalFile(path)\n    } else {\n      throw new TypeError('either filehandle or path must be defined')\n    }\n\n    if (!gziFilehandle && !gziPath && !path) {\n      throw new TypeError('either gziFilehandle or gziPath must be defined')\n    }\n\n    this.gzi = new GziIndex({\n      filehandle: gziFilehandle,\n      path: !gziFilehandle && !gziPath && path ? gziPath : `${path}.gzi`,\n    })\n  }\n\n  async stat() {\n    const compressedStat = await this.filehandle.stat()\n    return Object.assign(compressedStat, {\n      size: await this.getUncompressedFileSize(),\n      blocks: undefined,\n      blksize: undefined,\n    })\n  }\n\n  async getUncompressedFileSize() {\n    // read the last block's ISIZE (see gzip RFC),\n    // and add it to its uncompressedPosition\n    const [, uncompressedPosition] = await this.gzi.getLastBlock()\n\n    const { size } = await this.filehandle.stat()\n\n    const buf = Buffer.allocUnsafe(4)\n    // note: there should be a 28-byte EOF marker (an empty block) at\n    // the end of the file, so we skip backward past that\n    const { bytesRead } = await this.filehandle.read(buf, 0, 4, size - 28 - 4)\n    if (bytesRead !== 4) {\n      throw new Error('read error')\n    }\n    const lastBlockUncompressedSize = buf.readUInt32LE(0)\n    return uncompressedPosition + lastBlockUncompressedSize\n  }\n\n  async _readAndUncompressBlock(\n    blockBuffer: Buffer,\n    [compressedPosition]: [number],\n    [nextCompressedPosition]: [number],\n  ) {\n    let next = nextCompressedPosition\n    if (!next) {\n      next = (await this.filehandle.stat()).size\n    }\n\n    // read the compressed data into the block buffer\n    const blockCompressedLength = next - compressedPosition\n\n    await this.filehandle.read(\n      blockBuffer,\n      0,\n      blockCompressedLength,\n      compressedPosition,\n    )\n\n    // uncompress it\n    const unzippedBuffer = await unzip(\n      blockBuffer.slice(0, blockCompressedLength),\n    )\n\n    return unzippedBuffer as Buffer\n  }\n\n  async read(buf: Buffer, offset: number, length: number, position: number) {\n    // get the block positions for this read\n    const blockPositions = await this.gzi.getRelevantBlocksForRead(\n      length,\n      position,\n    )\n    const blockBuffer = Buffer.allocUnsafe(32768 * 2)\n    // uncompress the blocks and read from them one at a time to keep memory usage down\n    let destinationOffset = offset\n    let bytesRead = 0\n    for (\n      let blockNum = 0;\n      blockNum < blockPositions.length - 1;\n      blockNum += 1\n    ) {\n      // eslint-disable-next-line no-await-in-loop\n      const uncompressedBuffer = await this._readAndUncompressBlock(\n        blockBuffer,\n        blockPositions[blockNum],\n        blockPositions[blockNum + 1],\n      )\n      const [, uncompressedPosition] = blockPositions[blockNum]\n      const sourceOffset =\n        uncompressedPosition >= position ? 0 : position - uncompressedPosition\n      const sourceEnd =\n        Math.min(\n          position + length,\n          uncompressedPosition + uncompressedBuffer.length,\n        ) - uncompressedPosition\n      if (sourceOffset >= 0 && sourceOffset < uncompressedBuffer.length) {\n        uncompressedBuffer.copy(buf, destinationOffset, sourceOffset, sourceEnd)\n        destinationOffset += sourceEnd - sourceOffset\n        bytesRead += sourceEnd - sourceOffset\n      }\n    }\n\n    return { bytesRead, buffer: buf }\n  }\n}\n","import { LocalFile, GenericFilehandle } from 'generic-filehandle'\n\ninterface BaseOpts {\n  signal?: AbortSignal\n}\n\ninterface IndexEntry {\n  offset: number\n  lineBytes: number\n  lineLength: number\n  length: number\n}\n\nfunction _faiOffset(idx: IndexEntry, pos: number) {\n  return (\n    idx.offset +\n    idx.lineBytes * Math.floor(pos / idx.lineLength) +\n    (pos % idx.lineLength)\n  )\n}\n\nasync function readFAI(fai: GenericFilehandle, opts?: BaseOpts) {\n  const text = await fai.readFile(opts)\n  if (!(text && text.length)) {\n    throw new Error('No data read from FASTA index (FAI) file')\n  }\n\n  let idCounter = 0\n  let currSeq: { name: string; id: number } | undefined\n  const data = text\n    .toString('utf8')\n    .split(/\\r?\\n/)\n    .filter(line => /\\S/.test(line))\n    .map(line => line.split('\\t'))\n    .filter(row => row[0] !== '')\n    .map(row => {\n      if (!currSeq || currSeq.name !== row[0]) {\n        currSeq = { name: row[0], id: idCounter }\n        idCounter += 1\n      }\n\n      return {\n        id: currSeq.id,\n        name: row[0],\n        length: +row[1],\n        start: 0,\n        end: +row[1],\n        offset: +row[2],\n        lineLength: +row[3],\n        lineBytes: +row[4],\n      }\n    })\n\n  return {\n    name: Object.fromEntries(data.map(entry => [entry.name, entry])),\n    id: Object.fromEntries(data.map(entry => [entry.id, entry])),\n  }\n}\n\nexport default class IndexedFasta {\n  fasta: GenericFilehandle\n  fai: GenericFilehandle\n  indexes?: ReturnType<typeof readFAI>\n\n  constructor({\n    fasta,\n    fai,\n    path,\n    faiPath,\n  }: {\n    fasta?: GenericFilehandle\n    fai?: GenericFilehandle\n    path?: string\n    faiPath?: string\n  }) {\n    if (fasta) {\n      this.fasta = fasta\n    } else if (path) {\n      this.fasta = new LocalFile(path)\n    } else {\n      throw new Error('Need to pass filehandle for fasta or path to localfile')\n    }\n\n    if (fai) {\n      this.fai = fai\n    } else if (faiPath) {\n      this.fai = new LocalFile(faiPath)\n    } else if (path) {\n      this.fai = new LocalFile(`${path}.fai`)\n    } else {\n      throw new Error('Need to pass filehandle for  or path to localfile')\n    }\n  }\n\n  async _getIndexes(opts?: BaseOpts) {\n    if (!this.indexes) {\n      this.indexes = readFAI(this.fai, opts)\n    }\n    return this.indexes\n  }\n\n  /**\n   * @returns {array[string]} array of string sequence\n   * names that are present in the index, in which the\n   * array index indicates the sequence ID, and the value\n   * is the sequence name\n   */\n  async getSequenceNames(opts?: BaseOpts) {\n    return Object.keys((await this._getIndexes(opts)).name)\n  }\n\n  /**\n   * @returns {array[string]} array of string sequence\n   * names that are present in the index, in which the\n   * array index indicates the sequence ID, and the value\n   * is the sequence name\n   */\n  async getSequenceSizes(opts?: BaseOpts) {\n    const returnObject = {} as { [key: string]: number }\n    const idx = await this._getIndexes(opts)\n    const vals = Object.values(idx.id)\n    for (let i = 0; i < vals.length; i += 1) {\n      returnObject[vals[i].name] = vals[i].length\n    }\n    return returnObject\n  }\n\n  /**\n   * @returns {array[string]} array of string sequence\n   * names that are present in the index, in which the\n   * array index indicates the sequence ID, and the value\n   * is the sequence name\n   */\n  async getSequenceSize(seqName: string, opts?: BaseOpts) {\n    const idx = await this._getIndexes(opts)\n    return idx.name[seqName]?.length\n  }\n\n  /**\n   *\n   * @param {string} name\n   * @returns {Promise[boolean]} true if the file contains the given reference sequence name\n   */\n  async hasReferenceSequence(name: string, opts?: BaseOpts) {\n    return !!(await this._getIndexes(opts)).name[name]\n  }\n\n  /**\n   *\n   * @param {number} seqId\n   * @param {number} min\n   * @param {number} max\n   */\n  async getResiduesById(\n    seqId: number,\n    min: number,\n    max: number,\n    opts?: BaseOpts,\n  ) {\n    const indexEntry = (await this._getIndexes(opts)).id[seqId]\n    if (!indexEntry) {\n      return undefined\n    }\n    return this._fetchFromIndexEntry(indexEntry, min, max, opts)\n  }\n\n  /**\n   * @param {string} seqName\n   * @param {number} min\n   * @param {number} max\n   */\n  async getResiduesByName(\n    seqName: string,\n    min: number,\n    max: number,\n    opts?: BaseOpts,\n  ) {\n    const indexEntry = (await this._getIndexes(opts)).name[seqName]\n    if (!indexEntry) {\n      return undefined\n    }\n\n    return this._fetchFromIndexEntry(indexEntry, min, max, opts)\n  }\n\n  //alias for getResiduesByName\n  async getSequence(\n    seqName: string,\n    min: number,\n    max: number,\n    opts?: BaseOpts,\n  ) {\n    return this.getResiduesByName(seqName, min, max, opts)\n  }\n\n  async _fetchFromIndexEntry(\n    indexEntry: IndexEntry,\n    min = 0,\n    max: number,\n    opts?: BaseOpts,\n  ) {\n    let end = max\n    if (min < 0) {\n      throw new TypeError('regionStart cannot be less than 0')\n    }\n    if (end === undefined || end > indexEntry.length) {\n      end = indexEntry.length\n    }\n    if (min >= end) {\n      return ''\n    }\n\n    const position = _faiOffset(indexEntry, min)\n    const readlen = _faiOffset(indexEntry, end) - position\n\n    const residues = Buffer.allocUnsafe(readlen)\n    await this.fasta.read(residues, 0, readlen, position, opts)\n    return residues.toString('utf8').replace(/\\s+/g, '')\n  }\n}\n","import { BgzfFilehandle } from '@gmod/bgzf-filehandle'\nimport { GenericFilehandle } from 'generic-filehandle'\nimport IndexedFasta from './indexedFasta'\n\nexport default class BgzipIndexedFasta extends IndexedFasta {\n  constructor({\n    fasta,\n    path,\n    fai,\n    faiPath,\n    gzi,\n    gziPath,\n  }: {\n    fasta?: GenericFilehandle\n    path?: string\n    fai?: GenericFilehandle\n    faiPath?: string\n    gzi?: GenericFilehandle\n    gziPath?: string\n  }) {\n    super({ fasta, path, fai, faiPath })\n    if (fasta && gzi) {\n      this.fasta = new BgzfFilehandle({\n        filehandle: fasta,\n        gziFilehandle: gzi,\n      })\n    } else if (path && gziPath) {\n      this.fasta = new BgzfFilehandle({ path, gziPath })\n    }\n  }\n}\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortcontroller_ponyfill_1 = require(\"./abortcontroller-ponyfill\");\nconst AggregateAbortController_1 = __importDefault(require(\"./AggregateAbortController\"));\nconst AggregateStatusReporter_1 = __importDefault(require(\"./AggregateStatusReporter\"));\nclass AbortablePromiseCache {\n    constructor({ fill, cache, }) {\n        if (typeof fill !== 'function') {\n            throw new TypeError('must pass a fill function');\n        }\n        if (typeof cache !== 'object') {\n            throw new TypeError('must pass a cache object');\n        }\n        if (typeof cache.get !== 'function' ||\n            typeof cache.set !== 'function' ||\n            typeof cache.delete !== 'function') {\n            throw new TypeError('cache must implement get(key), set(key, val), and and delete(key)');\n        }\n        this.cache = cache;\n        this.fillCallback = fill;\n    }\n    static isAbortException(exception) {\n        return (\n        // DOMException\n        exception.name === 'AbortError' ||\n            // standard-ish non-DOM abort exception\n            //@ts-ignore\n            exception.code === 'ERR_ABORTED' ||\n            // stringified DOMException\n            exception.message === 'AbortError: aborted' ||\n            // stringified standard-ish exception\n            exception.message === 'Error: aborted');\n    }\n    evict(key, entry) {\n        if (this.cache.get(key) === entry) {\n            this.cache.delete(key);\n        }\n    }\n    fill(key, data, signal, statusCallback) {\n        const aborter = new AggregateAbortController_1.default();\n        const statusReporter = new AggregateStatusReporter_1.default();\n        statusReporter.addCallback(statusCallback);\n        const newEntry = {\n            aborter: aborter,\n            promise: this.fillCallback(data, aborter.signal, (message) => {\n                statusReporter.callback(message);\n            }),\n            settled: false,\n            statusReporter,\n            get aborted() {\n                return this.aborter.signal.aborted;\n            },\n        };\n        newEntry.aborter.addSignal(signal);\n        // remove the fill from the cache when its abortcontroller fires, if still in there\n        newEntry.aborter.signal.addEventListener('abort', () => {\n            if (!newEntry.settled) {\n                this.evict(key, newEntry);\n            }\n        });\n        // chain off the cached promise to record when it settles\n        newEntry.promise\n            .then(() => {\n            newEntry.settled = true;\n        }, () => {\n            newEntry.settled = true;\n            // if the fill throws an error (including abort) and is still in the cache, remove it\n            this.evict(key, newEntry);\n        })\n            .catch(e => {\n            // this will only be reached if there is some kind of\n            // bad bug in this library\n            console.error(e);\n            throw e;\n        });\n        this.cache.set(key, newEntry);\n    }\n    static checkSinglePromise(promise, signal) {\n        // check just this signal for having been aborted, and abort the\n        // promise if it was, regardless of what happened with the cached\n        // response\n        function checkForSingleAbort() {\n            if (signal && signal.aborted) {\n                throw Object.assign(new Error('aborted'), { code: 'ERR_ABORTED' });\n            }\n        }\n        return promise.then(result => {\n            checkForSingleAbort();\n            return result;\n        }, error => {\n            checkForSingleAbort();\n            throw error;\n        });\n    }\n    has(key) {\n        return this.cache.has(key);\n    }\n    /**\n     * Callback for getting status of the pending async\n     *\n     * @callback statusCallback\n     * @param {any} status, current status string or message object\n     */\n    /**\n     * @param {any} key cache key to use for this request\n     * @param {any} data data passed as the first argument to the fill callback\n     * @param {AbortSignal} [signal] optional AbortSignal object that aborts the request\n     * @param {statusCallback} a callback to get the current status of a pending async operation\n     */\n    get(key, data, signal, statusCallback) {\n        if (!signal && data instanceof abortcontroller_ponyfill_1.AbortSignal) {\n            throw new TypeError('second get argument appears to be an AbortSignal, perhaps you meant to pass `null` for the fill data?');\n        }\n        const cacheEntry = this.cache.get(key);\n        if (cacheEntry) {\n            if (cacheEntry.aborted && !cacheEntry.settled) {\n                // if it's aborted but has not realized it yet, evict it and redispatch\n                this.evict(key, cacheEntry);\n                return this.get(key, data, signal, statusCallback);\n            }\n            if (cacheEntry.settled) {\n                // too late to abort, just return it\n                return cacheEntry.promise;\n            }\n            // request is in-flight, add this signal to its list of signals,\n            // or if there is no signal, the aborter will become non-abortable\n            cacheEntry.aborter.addSignal(signal);\n            cacheEntry.statusReporter.addCallback(statusCallback);\n            return AbortablePromiseCache.checkSinglePromise(cacheEntry.promise, signal);\n        }\n        // if we got here, it is not in the cache. fill.\n        this.fill(key, data, signal, statusCallback);\n        return AbortablePromiseCache.checkSinglePromise(\n        //see https://www.typescriptlang.org/docs/handbook/2/everyday-types.html#non-null-assertion-operator-postfix-\n        //eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        this.cache.get(key).promise, signal);\n    }\n    /**\n     * delete the given entry from the cache. if it exists and its fill request has\n     * not yet settled, the fill will be signaled to abort.\n     *\n     * @param {any} key\n     */\n    delete(key) {\n        const cachedEntry = this.cache.get(key);\n        if (cachedEntry) {\n            if (!cachedEntry.settled) {\n                cachedEntry.aborter.abort();\n            }\n            this.cache.delete(key);\n        }\n    }\n    /**\n     * Clear all requests from the cache. Aborts any that have not settled.\n     * @returns {number} count of entries deleted\n     */\n    clear() {\n        // iterate without needing regenerator-runtime\n        const keyIter = this.cache.keys();\n        let deleteCount = 0;\n        for (let result = keyIter.next(); !result.done; result = keyIter.next()) {\n            this.delete(result.value);\n            deleteCount += 1;\n        }\n        return deleteCount;\n    }\n}\nexports.default = AbortablePromiseCache;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst abortcontroller_ponyfill_1 = require(\"./abortcontroller-ponyfill\");\nclass NullSignal {\n}\n/**\n * aggregates a number of abort signals, will only fire the aggregated\n * abort if all of the input signals have been aborted\n */\nclass AggregateAbortController {\n    constructor() {\n        this.signals = new Set();\n        this.abortController = new abortcontroller_ponyfill_1.AbortController();\n    }\n    /**\n     * @param {AbortSignal} [signal] optional AbortSignal to add. if falsy,\n     *  will be treated as a null-signal, and this abortcontroller will no\n     *  longer be abortable.\n     */\n    //@ts-ignore\n    addSignal(signal = new NullSignal()) {\n        if (this.signal.aborted) {\n            throw new Error('cannot add a signal, already aborted!');\n        }\n        // note that a NullSignal will never fire, so if we\n        // have one this thing will never actually abort\n        this.signals.add(signal);\n        if (signal.aborted) {\n            // handle the abort immediately if it is already aborted\n            // for some reason\n            this.handleAborted(signal);\n        }\n        else if (typeof signal.addEventListener === 'function') {\n            signal.addEventListener('abort', () => {\n                this.handleAborted(signal);\n            });\n        }\n    }\n    handleAborted(signal) {\n        this.signals.delete(signal);\n        if (this.signals.size === 0) {\n            this.abortController.abort();\n        }\n    }\n    get signal() {\n        return this.abortController.signal;\n    }\n    abort() {\n        this.abortController.abort();\n    }\n}\nexports.default = AggregateAbortController;\n","\"use strict\";\nObject.defineProperty(exports, \"__esModule\", { value: true });\nclass AggregateStatusReporter {\n    constructor() {\n        this.callbacks = new Set();\n    }\n    addCallback(callback = () => { }) {\n        this.callbacks.add(callback);\n        callback(this.currentMessage);\n    }\n    callback(message) {\n        this.currentMessage = message;\n        this.callbacks.forEach(elt => {\n            elt(message);\n        });\n    }\n}\nexports.default = AggregateStatusReporter;\n","\"use strict\";\n/* eslint-disable */\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.AbortSignal = exports.AbortController = void 0;\nconst cjs_ponyfill_1 = require(\"abortcontroller-polyfill/dist/cjs-ponyfill\");\nvar getGlobal = function () {\n    // the only reliable means to get the global object is\n    // `Function('return this')()`\n    // However, this causes CSP violations in Chrome apps.\n    if (typeof self !== 'undefined') {\n        return self;\n    }\n    if (typeof window !== 'undefined') {\n        return window;\n    }\n    if (typeof global !== 'undefined') {\n        return global;\n    }\n    throw new Error('unable to locate global object');\n};\n//@ts-ignore\nlet AbortController = typeof getGlobal().AbortController === 'undefined' ? cjs_ponyfill_1.AbortController : getGlobal().AbortController;\nexports.AbortController = AbortController;\n//@ts-ignore\nlet AbortSignal = typeof getGlobal().AbortController === 'undefined' ? cjs_ponyfill_1.AbortSignal : getGlobal().AbortSignal;\nexports.AbortSignal = AbortSignal;\n","\"use strict\";\nvar __importDefault = (this && this.__importDefault) || function (mod) {\n    return (mod && mod.__esModule) ? mod : { \"default\": mod };\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nconst AbortablePromiseCache_1 = __importDefault(require(\"./AbortablePromiseCache\"));\nexports.default = AbortablePromiseCache_1.default;\n"],"names":["async","unzip","inputData","strm","pos","i","chunks","inflator","totalSize","remainingInput","subarray","Inflate","push","Z_SYNC_FLUSH","err","Error","msg","next_in","result","length","avail_in","Uint8Array","offset","set","Buffer","from","e","match","unzipChunkSlice","chunk","minv","maxv","cpos","blockPosition","dpos","dataPosition","cpositions","dpositions","buffer","len","origCpos","GziIndex","constructor","filehandle","path","this","TypeError","_readLongWithOverflow","buf","unsigned","long","slice","greaterThan","Number","MAX_SAFE_INTEGER","lessThan","MIN_SAFE_INTEGER","toNumber","_getIndex","index","_readIndex","allocUnsafe","read","numEntries","entries","Array","bufSize","entryNumber","compressedPosition","uncompressedPosition","getLastBlock","getRelevantBlocksForRead","position","endPosition","relevant","compare","entry","nextEntry","nextUncompressedPosition","Infinity","lowerBound","upperBound","searchPosition","Math","floor","comparison","ceil","BgzFilehandle","gziFilehandle","gziPath","gzi","stat","compressedStat","Object","assign","size","getUncompressedFileSize","blocks","undefined","blksize","bytesRead","readUInt32LE","_readAndUncompressBlock","blockBuffer","nextCompressedPosition","next","blockCompressedLength","blockPositions","destinationOffset","blockNum","uncompressedBuffer","sourceOffset","sourceEnd","min","copy","_faiOffset","idx","lineBytes","lineLength","IndexedFasta","fasta","fai","faiPath","_getIndexes","opts","indexes","text","readFile","currSeq","idCounter","data","toString","split","filter","line","test","map","row","name","id","start","end","fromEntries","readFAI","getSequenceNames","keys","getSequenceSizes","returnObject","vals","values","getSequenceSize","seqName","hasReferenceSequence","getResiduesById","seqId","max","indexEntry","_fetchFromIndexEntry","getResiduesByName","getSequence","readlen","residues","replace","BgzipIndexedFasta","super","__importDefault","mod","__esModule","defineProperty","exports","value","abortcontroller_ponyfill_1","AggregateAbortController_1","AggregateStatusReporter_1","AbortablePromiseCache","fill","cache","get","delete","fillCallback","isAbortException","exception","code","message","evict","key","signal","statusCallback","aborter","default","statusReporter","addCallback","newEntry","promise","callback","settled","aborted","addSignal","addEventListener","then","catch","console","error","checkSinglePromise","checkForSingleAbort","has","AbortSignal","cacheEntry","cachedEntry","abort","clear","keyIter","deleteCount","done","NullSignal","signals","Set","abortController","AbortController","add","handleAborted","callbacks","currentMessage","forEach","elt","cjs_ponyfill_1","getGlobal","self","window","g","AbortablePromiseCache_1"],"sourceRoot":""}